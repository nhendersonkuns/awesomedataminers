{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id=\"top\"></a>\n",
    "## Task 2 - Housing Loan\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "### Part I\n",
    "* <a href=\"#tsk2_bu_understanding\">Business Understanding</a>\n",
    "\n",
    "* <a href=\"#tsk2_dataprepI\">Data Prep Part I for Task 2</a>\n",
    "    * <a href=\"#tsk2_dataprepviewdata\">Analyze Data</a>\n",
    "    * <a href=\"#tsk2_datapreptarget\">Set Target Variable</a>\n",
    "    * <a href=\"#TrainingSet_CategVarSetUp\">Perform One Hot Encoding for categorical variables</a>\n",
    "    * <a href=\"#TrainingSetClassPredVar\">Seperate Class and Predictor Variables</a>\n",
    "    * <a href=\"#TrainingSetFeatElim\">Feature Elimination</a>\n",
    "        * <a href=\"#FEUsingLassoLogisticRegression\">Feature Elimination Using Lasso Logistic Regression</a>\n",
    "        * <a href=\"#FEUsingDomainKnowledge\">Feature Elimination based on Domain knowledge</a>\n",
    "        * <a href=\"#FEDifferentMethods\">Feature Elimination using 6 different methods</a>\n",
    "* <a href=\"#SummaryObjDataPrep1\">Objective Summary</a>\n",
    "\n",
    "### Part II\n",
    "* <a href=\"#tsk2_dataprepII\">Data Prep Part II for Task 2</a>\n",
    "    * <a href=\"#tsk2_dataprepII\">View Data</a>\n",
    "    * <a href=\"#tsk2_predictordesc\">Predictor Descriptions</a>\n",
    "    * <a href=\"#tsk2_SummaryObjDataPrepII\">Summary Objective</a>\n",
    "* <a href=\"#tsk2_ModelEval1\">Model and Evaluation 1</a>\n",
    "* <a href=\"#tsk2_ModelEval2\">Model and Evaluation 2</a>\n",
    "    * <a href=\"#tsk2_LRMetricsKfold\">Logistic Regression K Fold Metrics</a>\n",
    "    * <a href=\"#tsk2_LRMetricsKShuffle\">Logistic Regression Shuffle Split Metrics</a>\n",
    "    * <a href=\"#tsk2_ModelEval2Summary\">Model 2 Summary</a>\n",
    "* <a href=\"#tsk2_ModelEval3\">Model and Evaluation 3</a>\n",
    "    * <a href=\"#tsk2_ModelEval3\">Data Prep</a>\n",
    "    * <a href=\"#tsk2_ModelEval3Simple_LRFit\">Task 2 Model 1 : Simple Logistic Regression Fit</a>\n",
    "        * <a href=\"#tsk2_ModelEval3Simple_LRPoly\">Polynomial Logistic Regression of degree 2</a>\n",
    "        * <a href=\"#tsk2_ModelEval3Simple_LRFTune\">Tuning the Model</a>\n",
    "            * <a href=\"#tsk2_ModelEval3Simple_LRFTune\">GridSearch on Simple LR</a>\n",
    "            * <a href=\"#tsk2_ModelEval3GSPoly_LRFTune\">GridSearch on Poly LR</a>\n",
    "        * <a href=\"#tsk2_ModelEval3Simple_LRFBestParam\">Task 2 Model 1 Summary</a>\n",
    "    * <a href=\"#tsk2_ModelEval4_SimpleRF\">Task 2 Model 2 : Simple Random Forest Model Fit</a>\n",
    "        * <a href=\"#tsk2_ModelEval4_RFGid\">Tuning the Model</a>\n",
    "        * <a href=\"#tsk2_ModelEval4_RFGidSearch\">Grid Search</a>\n",
    "        * <a href=\"#tsk2_ModelEval4_RFGidSearchMetrics\">Grid Search Metrics</a>\n",
    "            * <a href=\"#tsk2_ModelEval4_RFSubGrids\">Create Sub Grids</a>\n",
    "            * <a href=\"#tsk2_ModelEval4_RFFittingModels\">Fitting the Sub Grid Models</a>\n",
    "        * <a href=\"#tsk2_ModelEval4_EvalSummary\">Task 2 Model 2 Summary</a>\n",
    "    * <a href=\"#tsk2_ModelEval3_XGBoost\">Task 2 Model 3 : XGBoost</a>\n",
    "        * <a href=\"#tsk2_ModelEval3_XGBGid\">Tunning the Model</a>\n",
    "            * <a href=\"#tsk2_ModelEval3_XGBGidSearch\">Grid Search Level 1</a>\n",
    "            * <a href=\"#tsk2_ModelEval3_XGBGidSearch2\">Grid Search Level 2</a>\n",
    "            * <a href=\"#tsk2_ModelEval3_XGBGidSearch3\">Grid Search Level Final</a>\n",
    "        * <a href=\"#tsk2_ModelEval3_EvalSummary\">Task 2 Model 3 Summary</a>\n",
    "* <a href=\"#tsk2_ModelEval4\">Model and Evaluation 4</a>\n",
    "* <a href=\"#tsk2_ModelEval5\">Model and Evaluation 5</a>\n",
    "* <a href=\"#tsk2_Deployment\">Model Deployment</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id=\"tsk2_bu_understanding\"></a>\n",
    "### Business Understanding (2nd Variable)\n",
    "\n",
    "The team decided that the variable **Housing** would be of interest to the banks as this could be an avenue for additional revenue for the industry.  Individuals and families that own homes could be swayed into refinancing homes for a lower interest rate or need other loans to pay for home improvements.  These transactions, though benefiting the home owner in the short term, in the long run banks do benefit additionally with fees and service transactions that must be paid.\n",
    "\n",
    "The Housing variable is a binary response that is balanced in our sampled data set (_the population of the bank clients that have a home loan are unknown_).  The variable represents if the client has or does not have a home loan.\n",
    "\n",
    "From the figure 1 we can see several trends happening during the time of the dataset (ref: https://tradingeconomics.com/portugal):\n",
    "- Household savings increasing\n",
    "- Bank lending decreasing\n",
    "- Average wage increasing\n",
    "- Consumer spending decreasing\n",
    "\n",
    "**_Figure 1:_**\n",
    "\n",
    "![alt text](https://github.com/nhendersonkuns/awesomedataminers/raw/master/ReferenceMaterial/HousingReasons.PNG \"Key Indicators\")\n",
    "\n",
    "_During the time of the marketing campaign, a global recession occurred (figure 2).  We inferred that to prepare for the possiblity of upcoming hardships, many individuals/families would have attemped to save more of their disposable income.  The above charts yields us to that inference.  The banks could use this data to direct resources in an attempt to help these home owners refinance and save additional disposable income.  This helps out the customers in the short term and helps out the bank in the long term now that they have gained customers and revenue from interest payments._ \n",
    "\n",
    "**_Figure 2:_**\n",
    "![alt text](https://github.com/nhendersonkuns/awesomedataminers/raw/master/ReferenceMaterial/StockMarketCompare.PNG \"US vs Portugal Stock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_dataprepI\"></a>\n",
    "## Data Preparation Part 1 for Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_dataprepmodules\"></a>\n",
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime \n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# To display plots inside the iPython Notebook itself\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_dataprepviewdata\"></a>\n",
    "### Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n",
      "\n",
      "58;\"management\";\"married\";\"tertiary\";\"no\";2143;\"yes\";\"no\";\"unknown\";5;\"may\";261;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "44;\"technician\";\"single\";\"secondary\";\"no\";29;\"yes\";\"no\";\"unknown\";5;\"may\";151;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "33;\"entrepreneur\";\"married\";\"secondary\";\"no\";2;\"yes\";\"yes\";\"unknown\";5;\"may\";76;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "47;\"blue-collar\";\"married\";\"unknown\";\"no\";1506;\"yes\";\"no\";\"unknown\";5;\"may\";92;1;-1;0;\"unknown\";\"no\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>Subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>231</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>447</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "5   35    management  married   tertiary      no      231     yes   no   \n",
       "6   28    management   single   tertiary      no      447     yes  yes   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome Subscribed  \n",
       "0  unknown    5   may       261         1     -1         0  unknown         no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown         no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown         no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown         no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown         no  \n",
       "5  unknown    5   may       139         1     -1         0  unknown         no  \n",
       "6  unknown    5   may       217         1     -1         0  unknown         no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To verify how data is orgainzed in file(to find the delimiter) and then\n",
    "# use corresponding function to open the file. eg\n",
    "# data could be in .csv. .tsv, excel format etc.\n",
    "pathOfDataFile = \"data/bank-full.csv\"\n",
    "firstFewLines = list()\n",
    "noOfLinesToView = 5\n",
    "\n",
    "with open(pathOfDataFile) as dataFile:\n",
    "    firstFewLines = [next(dataFile) for i in range(noOfLinesToView)]\n",
    "    for line in firstFewLines:\n",
    "        print(line)\n",
    "\n",
    "# Import the semi-colon delimited data file into pandas dataFrame\n",
    "bankPromo_df = pd.read_csv(pathOfDataFile, sep = \";\")\n",
    "\n",
    "# Rename the Target/Final Outcome column from \"y\" to \"Subscribed\" as based on data description.\n",
    "bankPromo_df = bankPromo_df.rename(columns={\"y\":\"Subscribed\"})\n",
    "\n",
    "bankPromo_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_dataprepnulls\"></a>\n",
    "#### Validate Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           False\n",
       "job           False\n",
       "marital       False\n",
       "education     False\n",
       "default       False\n",
       "balance       False\n",
       "housing       False\n",
       "loan          False\n",
       "contact       False\n",
       "day           False\n",
       "month         False\n",
       "duration      False\n",
       "campaign      False\n",
       "pdays         False\n",
       "previous      False\n",
       "poutcome      False\n",
       "Subscribed    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values in data Frame\n",
    "bankPromo_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_As all the missing/unknown values in the dataset have been accounted already. Our dataset contains no missing values_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_dataprepdups\"></a>\n",
    "#### Identify duplicate entires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find duplicated rows in data Frame\n",
    "bankPromo_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_There are no duplicate values for any observations/rows in our data set._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_datapreptarget\"></a>\n",
    "### Set Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get list of categorical variables , keeping 'Housing' as target/response variable for Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      "age           45211 non-null int64\n",
      "job           45211 non-null object\n",
      "marital       45211 non-null object\n",
      "education     45211 non-null object\n",
      "default       45211 non-null object\n",
      "balance       45211 non-null int64\n",
      "loan          45211 non-null object\n",
      "contact       45211 non-null object\n",
      "day           45211 non-null int64\n",
      "month         45211 non-null object\n",
      "duration      45211 non-null int64\n",
      "campaign      45211 non-null int64\n",
      "pdays         45211 non-null int64\n",
      "previous      45211 non-null int64\n",
      "poutcome      45211 non-null object\n",
      "Subscribed    45211 non-null object\n",
      "Target        45211 non-null int64\n",
      "dtypes: int64(8), object(9)\n",
      "memory usage: 5.9+ MB\n",
      "['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous', 'Target']\n",
      "['job', 'marital', 'education', 'default', 'loan', 'contact', 'month', 'poutcome', 'Subscribed']\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of original data frame\n",
    "bankPromoModel_hsng_Df = bankPromo_df.copy()\n",
    "bankPromoModel_hsng_Df['Target'] = bankPromoModel_hsng_Df['housing'].apply(lambda resp : 1 if resp == \"yes\" else 0)\n",
    "bankPromoModel_hsng_Df['Target'] = bankPromoModel_hsng_Df['Target'].astype(np.int)\n",
    "\n",
    "# Delete the original 'housing' column\n",
    "del bankPromoModel_hsng_Df['housing']\n",
    "\n",
    "# List final variables of the new dataset\n",
    "bankPromoModel_hsng_Df.info()\n",
    "\n",
    "# Get the unique values(Levels) for categorical variables.\n",
    "# List to hold names of categorical variables\n",
    "categoricalVars = list()\n",
    "# List to hold names of numerical variables\n",
    "numericalVars = list()\n",
    "\n",
    "for colName in bankPromoModel_hsng_Df.columns:\n",
    "    if bankPromoModel_hsng_Df[colName].dtype == np.int64:\n",
    "        numericalVars.append(colName)\n",
    "    elif bankPromoModel_hsng_Df[colName].dtype == np.object:\n",
    "        categoricalVars.append(colName)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# Remove Target column from final categorical Var list\n",
    "#categoricalVars.remove('housing')\n",
    "\n",
    "print(numericalVars)\n",
    "print(categoricalVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"TrainingSet_CategVarSetUp\"></a>\n",
    "       \n",
    "### Perform One Hot Encoding for categorical variables in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset info\n",
      "=====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 43 columns):\n",
      "age                    45211 non-null int64\n",
      "balance                45211 non-null int64\n",
      "day                    45211 non-null int64\n",
      "duration               45211 non-null int64\n",
      "campaign               45211 non-null int64\n",
      "pdays                  45211 non-null int64\n",
      "previous               45211 non-null int64\n",
      "Target                 45211 non-null int64\n",
      "job_blue-collar        45211 non-null uint8\n",
      "job_entrepreneur       45211 non-null uint8\n",
      "job_housemaid          45211 non-null uint8\n",
      "job_management         45211 non-null uint8\n",
      "job_retired            45211 non-null uint8\n",
      "job_self-employed      45211 non-null uint8\n",
      "job_services           45211 non-null uint8\n",
      "job_student            45211 non-null uint8\n",
      "job_technician         45211 non-null uint8\n",
      "job_unemployed         45211 non-null uint8\n",
      "job_unknown            45211 non-null uint8\n",
      "marital_married        45211 non-null uint8\n",
      "marital_single         45211 non-null uint8\n",
      "education_secondary    45211 non-null uint8\n",
      "education_tertiary     45211 non-null uint8\n",
      "education_unknown      45211 non-null uint8\n",
      "default_yes            45211 non-null uint8\n",
      "loan_yes               45211 non-null uint8\n",
      "contact_telephone      45211 non-null uint8\n",
      "contact_unknown        45211 non-null uint8\n",
      "month_aug              45211 non-null uint8\n",
      "month_dec              45211 non-null uint8\n",
      "month_feb              45211 non-null uint8\n",
      "month_jan              45211 non-null uint8\n",
      "month_jul              45211 non-null uint8\n",
      "month_jun              45211 non-null uint8\n",
      "month_mar              45211 non-null uint8\n",
      "month_may              45211 non-null uint8\n",
      "month_nov              45211 non-null uint8\n",
      "month_oct              45211 non-null uint8\n",
      "month_sep              45211 non-null uint8\n",
      "poutcome_other         45211 non-null uint8\n",
      "poutcome_success       45211 non-null uint8\n",
      "poutcome_unknown       45211 non-null uint8\n",
      "Subscribed_yes         45211 non-null uint8\n",
      "dtypes: int64(8), uint8(35)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "## Training Dataset\n",
    "###################\n",
    "# Convert all categorical variables to corresponding indicator variables\n",
    "for categoricalVar in categoricalVars:\n",
    "    tmpDf = pd.DataFrame()\n",
    "    # Remove 1st class level to avoid multicollinearity\n",
    "    tmpDf = pd.get_dummies(bankPromoModel_hsng_Df[categoricalVar], prefix=categoricalVar, drop_first=True)\n",
    "    bankPromoModel_hsng_Df = pd.concat((bankPromoModel_hsng_Df, tmpDf), axis=1)\n",
    "\n",
    "# Now remove the original categorical vars since indicator variables are created from them.\n",
    "bankPromoModel_hsng_Df.drop(categoricalVars, inplace=True, axis=1)\n",
    "print(\"Training dataset info\")\n",
    "print(\"=====================\")\n",
    "bankPromoModel_hsng_Df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id=\"top\"></a>\n",
    "<a id=\"TrainingSetClassPredVar\"></a>\n",
    "       \n",
    "#### Seperate Class and Predictor Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seperate the class and predictor variables\n",
    "if 'Target' in bankPromoModel_hsng_Df:\n",
    "    y = bankPromoModel_hsng_Df['Target'].values # get the labels we want\n",
    "    del bankPromoModel_hsng_Df['Target']        # get rid of the class label\n",
    "    X = bankPromoModel_hsng_Df.values           # use everything else to predict!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"#TrainingSetFeatElim\"></a>\n",
    "\n",
    "### Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"FEUsingLassoLogisticRegression\"></a>\n",
    "\n",
    "### Feature Elimination Using Lasso Logistic Regression\n",
    "\n",
    "Featuring the same dataset as Task1 , it does not have a very high dimensionality , an attempt is made to eliminate any features that may not be useful to our task of classification of the response variable. A simple Logistic Regression model is run to analyze any features that can be eliminated.\n",
    "From our EDA phase, we know that dataset hosts an almost balanced set for response variable(\"housing\") classifiers - 56% for Yes and 44% for No. So for executing a simple model, class_weight as None is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month_aug has weight of -0.8218055880934713\n",
      "month_jun has weight of -0.5133078366224679\n",
      "age has weight of -0.34770575197344655\n",
      "month_jul has weight of -0.33219653576913705\n",
      "month_feb has weight of -0.30401987123143503\n",
      "job_student has weight of -0.2298849457383366\n",
      "month_jan has weight of -0.22251032200338852\n",
      "month_sep has weight of -0.21537644820959612\n",
      "month_oct has weight of -0.21508786998788285\n",
      "Subscribed_yes has weight of -0.21214732837628966\n",
      "marital_single has weight of -0.20485834964766605\n",
      "job_retired has weight of -0.20184179660375864\n",
      "job_unknown has weight of -0.17482566966737745\n",
      "month_mar has weight of -0.16929127133360752\n",
      "month_nov has weight of -0.1548033384929472\n",
      "month_dec has weight of -0.13777989156208167\n",
      "poutcome_success has weight of -0.12940030098315464\n",
      "day has weight of -0.11748156842113988\n",
      "job_housemaid has weight of -0.10266310732500522\n",
      "job_unemployed has weight of -0.0914933371853685\n",
      "contact_telephone has weight of -0.06990775131880754\n",
      "education_unknown has weight of -0.06908889225349335\n",
      "balance has weight of -0.06160846607376792\n",
      "job_self-employed has weight of -0.05478816511057268\n",
      "default_yes has weight of -0.03866118123443981\n",
      "poutcome_other has weight of -0.03355139251796191\n",
      "job_management has weight of -0.022941418672475247\n",
      "education_tertiary has weight of -0.017756816488902896\n",
      "job_entrepreneur has weight of -0.006165283082501696\n",
      "poutcome_unknown has weight of 0.0\n",
      "marital_married has weight of 0.0041355680086494935\n",
      "loan_yes has weight of 0.01581283932897791\n",
      "job_technician has weight of 0.016666225844844076\n",
      "job_services has weight of 0.02849243722019241\n",
      "education_secondary has weight of 0.03800683810887228\n",
      "previous has weight of 0.04202665532912485\n",
      "duration has weight of 0.07694250335968696\n",
      "campaign has weight of 0.11315624060102945\n",
      "job_blue-collar has weight of 0.12915086527664046\n",
      "contact_unknown has weight of 0.20524849208746798\n",
      "pdays has weight of 0.3212502833060009\n",
      "month_may has weight of 0.34290313815923523\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel_hsng = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', C=1.0,\\\n",
    "                                                                   class_weight=None, random_state=999, \\\n",
    "                                                                   solver='liblinear'))\n",
    "\n",
    "# Fit the whole training dataset now, since validation would be done on additional dataset\n",
    "logisticModel_hsng.fit(X,y) \n",
    "\n",
    "classifier_model = logisticModel_hsng.named_steps['logisticregression']\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(classifier_model.coef_.T, bankPromoModel_hsng_Df.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0])\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(20,9))\n",
    "weights = pd.Series(classifier_model.coef_[0],index=bankPromoModel_hsng_Df.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Based on the magnitude of the coefficients in above plot features- Month_Aug, Month_Jun, Age, Month_May, Month_Jul and PDays are among the most important features.**\n",
    "\n",
    "As identified during the EDA in Lab 1, the clients could be contacted over a few months, but each of the months listed corresponds to the last month the client was contacted. The months that affect the housing model the most are August, June, May and July. **_It is necessary to note the difference between the housing and the subscribe models - the subscribe model does not weight any months with a high coefficient until the fifth variable. Also, most of the months in the housing model have negative coeffecients where the subscribe model are equally distributed between the months._**\n",
    "\n",
    "The **age** of the client, which is the first non-month feature, is in the top 6. The age of prospective clients for home loans sounds as if that feature would be significant, _for example a 30 year old person is more likely to have a home loan as compared to an 18 year old._\n",
    "\n",
    "**Pdays** is the last feature we will mention as significant (we were going to only mention the top 5 but continued until the next non-month attribute). Pdays is also the first non-month attribute to have a positive coefficient with Month_May being the only other feature mentioned here. Pdays is the number of days of contact between the current marketing campaign and a previous campaign. From the EDA in Lab 1, we discovered that 80% of the clients in this campaign were new to marketing campaigns from the bank. The right skewness of the data for this feature could have affected the singifance into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussing the least important features** from results of Lasso Logistic Model with degree = 1 that following features ( with coeff = 0 ) can be eliminated. Next, we will explore them one by one :\n",
    "    \n",
    "    poutcome_unknown has weight of 0.0\n",
    "    \n",
    "Only 1 feature shows a 0.0 coeff and is a level of categorical variable. **Hence this cannot be eliminated**. Next attempt was made to look at this model with different methods used for feature elimination to see if the results were different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"FEUsingDomainKnowledge\"></a>\n",
    "\n",
    "### Feature Elimination based on Domain knowledge\n",
    "\n",
    "**Delete any features that do not relate to the response variable based on domain knowledge**\n",
    "\n",
    "BankPromo dataset contains \n",
    "\n",
    "i) bank client data like age, balance, education, job , marital status , any loans - housing/personal , if they have defaulted  \n",
    "\n",
    "ii) information regarding last contact  in current campaign - contact type, day/month when last contacted, duration of last call \n",
    "\n",
    "iii) other attributes like number of times contacted during current campaign ,number of days since last contact, number of contacts made in last campaign, outcome from previous campaign , outcome from current campagin i.e. Subscribed or not  \n",
    "\n",
    "\n",
    "From business use case perspective, any information regarding Term deposit subscription campaign may have no effect on the client data but vice-versa may not be true. It will be interesting to find what features from the campaign information should be considered to predict if a customer has a housing loan or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"FEDifferentMethods\"></a>\n",
    "       \n",
    "### Feature Elimination using different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fs info\n",
      "==========\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 42 columns):\n",
      "age                    45211 non-null int64\n",
      "balance                45211 non-null int64\n",
      "day                    45211 non-null int64\n",
      "duration               45211 non-null int64\n",
      "campaign               45211 non-null int64\n",
      "pdays                  45211 non-null int64\n",
      "previous               45211 non-null int64\n",
      "job_blue-collar        45211 non-null uint8\n",
      "job_entrepreneur       45211 non-null uint8\n",
      "job_housemaid          45211 non-null uint8\n",
      "job_management         45211 non-null uint8\n",
      "job_retired            45211 non-null uint8\n",
      "job_self-employed      45211 non-null uint8\n",
      "job_services           45211 non-null uint8\n",
      "job_student            45211 non-null uint8\n",
      "job_technician         45211 non-null uint8\n",
      "job_unemployed         45211 non-null uint8\n",
      "job_unknown            45211 non-null uint8\n",
      "marital_married        45211 non-null uint8\n",
      "marital_single         45211 non-null uint8\n",
      "education_secondary    45211 non-null uint8\n",
      "education_tertiary     45211 non-null uint8\n",
      "education_unknown      45211 non-null uint8\n",
      "default_yes            45211 non-null uint8\n",
      "loan_yes               45211 non-null uint8\n",
      "contact_telephone      45211 non-null uint8\n",
      "contact_unknown        45211 non-null uint8\n",
      "month_aug              45211 non-null uint8\n",
      "month_dec              45211 non-null uint8\n",
      "month_feb              45211 non-null uint8\n",
      "month_jan              45211 non-null uint8\n",
      "month_jul              45211 non-null uint8\n",
      "month_jun              45211 non-null uint8\n",
      "month_mar              45211 non-null uint8\n",
      "month_may              45211 non-null uint8\n",
      "month_nov              45211 non-null uint8\n",
      "month_oct              45211 non-null uint8\n",
      "month_sep              45211 non-null uint8\n",
      "poutcome_other         45211 non-null uint8\n",
      "poutcome_success       45211 non-null uint8\n",
      "poutcome_unknown       45211 non-null uint8\n",
      "Subscribed_yes         45211 non-null uint8\n",
      "dtypes: int64(7), uint8(35)\n",
      "memory usage: 3.9 MB\n",
      "y_fs info\n",
      "==========\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "# gather numerical variables for LDA\n",
    "\n",
    "X_fs = bankPromoModel_hsng_Df.copy()\n",
    "y_fs = y\n",
    "\n",
    "print(\"X_fs info\")\n",
    "print(\"==========\")\n",
    "X_fs.info()\n",
    "\n",
    "print(\"y_fs info\")\n",
    "print(\"==========\")\n",
    "print(y_fs.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Sq Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 selected features\n",
      "                      0\n",
      "0       job_blue-collar\n",
      "1         job_housemaid\n",
      "2           job_retired\n",
      "3          job_services\n",
      "4           job_student\n",
      "5           job_unknown\n",
      "6   education_secondary\n",
      "7    education_tertiary\n",
      "8     contact_telephone\n",
      "9       contact_unknown\n",
      "10            month_aug\n",
      "11            month_jun\n",
      "12            month_mar\n",
      "13            month_may\n",
      "14            month_oct\n",
      "15            month_sep\n",
      "16     poutcome_success\n",
      "17       Subscribed_yes\n"
     ]
    }
   ],
   "source": [
    "# Chi-Sq test for feature selection amongst categorical variables\n",
    "# below code referred from http://www.insightsbot.com/blog/2AeuRL/chi-square-feature-selection-in-python\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "class ChiSquare:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.p = None #P-Value\n",
    "        self.chi2 = None #Chi Test Statistic\n",
    "        self.dof = None\n",
    "        \n",
    "        self.dfTabular = None\n",
    "        self.dfExpected = None\n",
    "        \n",
    "    def TestIndependence(self,colX,colY, alpha=0.05):\n",
    "        X = self.df[colX].astype(str)\n",
    "        Y = self.df[colY].astype(str)\n",
    "        \n",
    "        self.dfObserved = pd.crosstab(Y,X) \n",
    "        chi2, p, dof, expected = stats.chi2_contingency(self.dfObserved.values)\n",
    "        self.p = p\n",
    "        self.chi2 = chi2\n",
    "        self.dof = dof \n",
    "        \n",
    "        self.dfExpected = pd.DataFrame(expected, columns=self.dfObserved.columns, index = self.dfObserved.index)\n",
    "        \n",
    "        self._print_chisquare_result(colX, alpha)\n",
    "    \n",
    "    def _print_chisquare_result(self, colX, alpha):\n",
    "        result = \"\"\n",
    "        if self.p<alpha:\n",
    "            result=\"{0} is IMPORTANT for Prediction\".format(colX)\n",
    "        else:\n",
    "            result=\"{0} is NOT an important predictor. (Discard {0} from model)\".format(colX)\n",
    "\n",
    "        print(result)\n",
    "\n",
    "        \n",
    "# Chi-sq test\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_norm = MinMaxScaler().fit_transform(X_fs)\n",
    "chi_selector = SelectKBest(chi2, k=18)\n",
    "chi_selector.fit(X_norm, y_fs)\n",
    "\n",
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = X_fs.loc[:,chi_support].columns.tolist()\n",
    "print(str(len(chi_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(chi_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 selected features\n",
      "                      0\n",
      "0           job_unknown\n",
      "1             month_sep\n",
      "2         job_housemaid\n",
      "3     contact_telephone\n",
      "4           job_student\n",
      "5             month_oct\n",
      "6      poutcome_success\n",
      "7    education_tertiary\n",
      "8   education_secondary\n",
      "9             month_jun\n",
      "10                pdays\n",
      "11       Subscribed_yes\n",
      "12          job_retired\n",
      "13      job_blue-collar\n",
      "14                  age\n",
      "15      contact_unknown\n",
      "16            month_aug\n",
      "17            month_may\n"
     ]
    }
   ],
   "source": [
    "# Pearson Correlation\n",
    "feature_name = X_fs.columns.tolist()\n",
    "\n",
    "def cor_selector(X, y):\n",
    "    cor_list = []\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-18:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "\n",
    "cor_support, cor_feature = cor_selector(X_fs, y_fs)\n",
    "print(str(len(cor_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame( cor_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Fitting Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 22 features.\n",
      "18 selected features\n",
      "                   0\n",
      "0                age\n",
      "1            balance\n",
      "2           duration\n",
      "3           campaign\n",
      "4              pdays\n",
      "5        job_retired\n",
      "6        job_student\n",
      "7        job_unknown\n",
      "8          month_aug\n",
      "9          month_dec\n",
      "10         month_feb\n",
      "11         month_jan\n",
      "12         month_mar\n",
      "13         month_may\n",
      "14         month_oct\n",
      "15         month_sep\n",
      "16  poutcome_success\n",
      "17    Subscribed_yes\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=18, step=10, verbose=5)\n",
    "rfe_selector.fit(X_norm, y_fs)\n",
    "\n",
    "\n",
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = X_fs.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(rfe_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 selected features\n",
      "              0\n",
      "0           age\n",
      "1       balance\n",
      "2      duration\n",
      "3      campaign\n",
      "4         pdays\n",
      "5   job_retired\n",
      "6   job_student\n",
      "7   job_unknown\n",
      "8     month_aug\n",
      "9     month_dec\n",
      "10    month_feb\n",
      "11    month_jan\n",
      "12    month_jul\n",
      "13    month_jun\n",
      "14    month_mar\n",
      "15    month_oct\n",
      "16    month_sep\n"
     ]
    }
   ],
   "source": [
    "## Embed\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\"), '1.25*median',max_features=18)\n",
    "embeded_lr_selector.fit(X_norm, y_fs)\n",
    "\n",
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X_fs.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(embeded_lr_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 selected features\n",
      "                      0\n",
      "0                   age\n",
      "1               balance\n",
      "2                   day\n",
      "3              duration\n",
      "4              campaign\n",
      "5                 pdays\n",
      "6              previous\n",
      "7       job_blue-collar\n",
      "8       marital_married\n",
      "9   education_secondary\n",
      "10             loan_yes\n",
      "11      contact_unknown\n",
      "12            month_aug\n",
      "13            month_jul\n",
      "14            month_jun\n",
      "15            month_may\n",
      "16       Subscribed_yes\n"
     ]
    }
   ],
   "source": [
    "## Random forest\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), threshold='1.25*median', max_features=42)\n",
    "embeded_rf_selector.fit(X_fs, y_fs)\n",
    "\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X_fs.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 selected features\n",
      "                     0\n",
      "0                  age\n",
      "1              balance\n",
      "2                  day\n",
      "3             duration\n",
      "4             campaign\n",
      "5                pdays\n",
      "6             previous\n",
      "7      job_blue-collar\n",
      "8       job_technician\n",
      "9       marital_single\n",
      "10  education_tertiary\n",
      "11            loan_yes\n",
      "12     contact_unknown\n",
      "13           month_jul\n",
      "14           month_jun\n",
      "15      Subscribed_yes\n"
     ]
    }
   ],
   "source": [
    "## LightGBM\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "\n",
    "embeded_lgb_selector = SelectFromModel(lgbc, threshold='1.25*median',max_features=18)\n",
    "embeded_lgb_selector.fit(X_fs, y_fs)\n",
    "\n",
    "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
    "embeded_lgb_feature = X_fs.loc[:,embeded_lgb_support].columns.tolist()\n",
    "print(str(len(embeded_lgb_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(embeded_lgb_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the variable importance through above methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Chi-2</th>\n",
       "      <th>RFE</th>\n",
       "      <th>Logistics</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pdays</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month_jun</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>month_aug</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subscribed_yes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month_sep</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>month_oct</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>month_may</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job_unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>job_student</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>job_retired</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>job_blue-collar</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>duration</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>contact_unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>campaign</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>balance</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>poutcome_success</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>month_mar</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>month_jul</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>education_tertiary</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>education_secondary</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>previous</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>month_jan</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>month_feb</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>month_dec</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>loan_yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>job_housemaid</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>day</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>contact_telephone</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>marital_single</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>marital_married</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>job_technician</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>job_services</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>poutcome_unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>poutcome_other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>month_nov</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>job_unemployed</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>job_self-employed</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>job_management</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>job_entrepreneur</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>education_unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>default_yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  Pearson  Chi-2    RFE  Logistics  Random Forest  \\\n",
       "1                 pdays     True  False   True       True           True   \n",
       "2             month_jun     True   True  False       True           True   \n",
       "3             month_aug     True   True   True       True           True   \n",
       "4                   age     True  False   True       True           True   \n",
       "5        Subscribed_yes     True   True   True      False           True   \n",
       "6             month_sep     True   True   True       True          False   \n",
       "7             month_oct     True   True   True       True          False   \n",
       "8             month_may     True   True   True      False           True   \n",
       "9           job_unknown     True   True   True       True          False   \n",
       "10          job_student     True   True   True       True          False   \n",
       "11          job_retired     True   True   True       True          False   \n",
       "12      job_blue-collar     True   True  False      False           True   \n",
       "13             duration    False  False   True       True           True   \n",
       "14      contact_unknown     True   True  False      False           True   \n",
       "15             campaign    False  False   True       True           True   \n",
       "16              balance    False  False   True       True           True   \n",
       "17     poutcome_success     True   True   True      False          False   \n",
       "18            month_mar    False   True   True       True          False   \n",
       "19            month_jul    False  False  False       True           True   \n",
       "20   education_tertiary     True   True  False      False          False   \n",
       "21  education_secondary     True   True  False      False           True   \n",
       "22             previous    False  False  False      False           True   \n",
       "23            month_jan    False  False   True       True          False   \n",
       "24            month_feb    False  False   True       True          False   \n",
       "25            month_dec    False  False   True       True          False   \n",
       "26             loan_yes    False  False  False      False           True   \n",
       "27        job_housemaid     True   True  False      False          False   \n",
       "28                  day    False  False  False      False           True   \n",
       "29    contact_telephone     True   True  False      False          False   \n",
       "30       marital_single    False  False  False      False          False   \n",
       "31      marital_married    False  False  False      False           True   \n",
       "32       job_technician    False  False  False      False          False   \n",
       "33         job_services    False   True  False      False          False   \n",
       "34     poutcome_unknown    False  False  False      False          False   \n",
       "35       poutcome_other    False  False  False      False          False   \n",
       "36            month_nov    False  False  False      False          False   \n",
       "37       job_unemployed    False  False  False      False          False   \n",
       "38    job_self-employed    False  False  False      False          False   \n",
       "39       job_management    False  False  False      False          False   \n",
       "40     job_entrepreneur    False  False  False      False          False   \n",
       "41    education_unknown    False  False  False      False          False   \n",
       "42          default_yes    False  False  False      False          False   \n",
       "\n",
       "    LightGBM  Total  \n",
       "1       True      5  \n",
       "2       True      5  \n",
       "3      False      5  \n",
       "4       True      5  \n",
       "5       True      5  \n",
       "6      False      4  \n",
       "7      False      4  \n",
       "8      False      4  \n",
       "9      False      4  \n",
       "10     False      4  \n",
       "11     False      4  \n",
       "12      True      4  \n",
       "13      True      4  \n",
       "14      True      4  \n",
       "15      True      4  \n",
       "16      True      4  \n",
       "17     False      3  \n",
       "18     False      3  \n",
       "19      True      3  \n",
       "20      True      3  \n",
       "21     False      3  \n",
       "22      True      2  \n",
       "23     False      2  \n",
       "24     False      2  \n",
       "25     False      2  \n",
       "26      True      2  \n",
       "27     False      2  \n",
       "28      True      2  \n",
       "29     False      2  \n",
       "30      True      1  \n",
       "31     False      1  \n",
       "32      True      1  \n",
       "33     False      1  \n",
       "34     False      0  \n",
       "35     False      0  \n",
       "36     False      0  \n",
       "37     False      0  \n",
       "38     False      0  \n",
       "39     False      0  \n",
       "40     False      0  \n",
       "41     False      0  \n",
       "42     False      0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Summary\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "# put all selection together\n",
    "feature_selection_df = pd.DataFrame({'Feature':feature_name, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'Logistics':embeded_lr_support,\n",
    "                                    'Random Forest':embeded_rf_support, 'LightGBM':embeded_lgb_support})\n",
    "# count the selected times for each feature\n",
    "feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
    "# display the top 100\n",
    "feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
    "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
    "feature_selection_df.head(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen through the various methods deployed, the features that show least or no importance from all methods are :\n",
    " \n",
    "poutcome_unknown\n",
    "poutcome_other\n",
    "month_nov\n",
    "job_unemployed\n",
    "job_self-employed\n",
    "job_management\n",
    "job_entrepreneur\n",
    "education_unknown\n",
    "default_yes\n",
    "\n",
    "**All features except default_yes are one of multiple levels of a categorical variable. Removing default did not yield better results and this not being a high-dimensional dataset, decision is made to proceed with all features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"SummaryObjDataPrep1\"></a>\n",
    "### Summary and Objectives tracking for section: Data Preparation Part 1\n",
    "\n",
    "Define and prepare your class variables.\n",
    "// \"housing\" variable is identified and prepared as class variable.\n",
    "\n",
    "Use proper variable representations (int, float, one-hot, etc.).\n",
    "// As can be seen from above code, all the numericals variables have been appropriatly represented in the dataset and all categorical variables have been encoded using one-hot encoding.\n",
    "\n",
    "Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc.\n",
    "// Scaling of the variables would be later performed before model preparation using pipeline which would first scale the variables before fitting them to model. Since, our data is not that high dimensional in feature space, hence no dimensionality reduction technique was performed. Rest all pre-processing was performed.\n",
    "\n",
    "Remove variables that are not needed/useful for the analysis.\n",
    "// No feature was deemed as non-important enough to be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_dataprepII\"></a>\n",
    "\n",
    "## Data Preparation Part 2 for Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>Subscribed_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.936210</td>\n",
       "      <td>1362.272058</td>\n",
       "      <td>15.806419</td>\n",
       "      <td>258.163080</td>\n",
       "      <td>2.763841</td>\n",
       "      <td>40.197828</td>\n",
       "      <td>0.580323</td>\n",
       "      <td>0.215257</td>\n",
       "      <td>0.032890</td>\n",
       "      <td>0.027427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118135</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>0.304483</td>\n",
       "      <td>0.087810</td>\n",
       "      <td>0.016323</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.033421</td>\n",
       "      <td>0.817478</td>\n",
       "      <td>0.116985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.618762</td>\n",
       "      <td>3044.765829</td>\n",
       "      <td>8.322476</td>\n",
       "      <td>257.527812</td>\n",
       "      <td>3.098021</td>\n",
       "      <td>100.128746</td>\n",
       "      <td>2.303441</td>\n",
       "      <td>0.411005</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>0.163326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322771</td>\n",
       "      <td>0.102174</td>\n",
       "      <td>0.460193</td>\n",
       "      <td>0.283022</td>\n",
       "      <td>0.126718</td>\n",
       "      <td>0.112441</td>\n",
       "      <td>0.197592</td>\n",
       "      <td>0.179735</td>\n",
       "      <td>0.386278</td>\n",
       "      <td>0.321406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        balance           day      duration      campaign  \\\n",
       "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
       "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
       "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
       "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
       "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
       "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
       "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
       "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
       "\n",
       "              pdays      previous  job_blue-collar  job_entrepreneur  \\\n",
       "count  45211.000000  45211.000000     45211.000000      45211.000000   \n",
       "mean      40.197828      0.580323         0.215257          0.032890   \n",
       "std      100.128746      2.303441         0.411005          0.178351   \n",
       "min       -1.000000      0.000000         0.000000          0.000000   \n",
       "25%       -1.000000      0.000000         0.000000          0.000000   \n",
       "50%       -1.000000      0.000000         0.000000          0.000000   \n",
       "75%       -1.000000      0.000000         0.000000          0.000000   \n",
       "max      871.000000    275.000000         1.000000          1.000000   \n",
       "\n",
       "       job_housemaid  ...     month_jun     month_mar     month_may  \\\n",
       "count   45211.000000  ...  45211.000000  45211.000000  45211.000000   \n",
       "mean        0.027427  ...      0.118135      0.010551      0.304483   \n",
       "std         0.163326  ...      0.322771      0.102174      0.460193   \n",
       "min         0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%         0.000000  ...      0.000000      0.000000      0.000000   \n",
       "50%         0.000000  ...      0.000000      0.000000      0.000000   \n",
       "75%         0.000000  ...      0.000000      0.000000      1.000000   \n",
       "max         1.000000  ...      1.000000      1.000000      1.000000   \n",
       "\n",
       "          month_nov     month_oct     month_sep  poutcome_other  \\\n",
       "count  45211.000000  45211.000000  45211.000000    45211.000000   \n",
       "mean       0.087810      0.016323      0.012807        0.040698   \n",
       "std        0.283022      0.126718      0.112441        0.197592   \n",
       "min        0.000000      0.000000      0.000000        0.000000   \n",
       "25%        0.000000      0.000000      0.000000        0.000000   \n",
       "50%        0.000000      0.000000      0.000000        0.000000   \n",
       "75%        0.000000      0.000000      0.000000        0.000000   \n",
       "max        1.000000      1.000000      1.000000        1.000000   \n",
       "\n",
       "       poutcome_success  poutcome_unknown  Subscribed_yes  \n",
       "count      45211.000000      45211.000000    45211.000000  \n",
       "mean           0.033421          0.817478        0.116985  \n",
       "std            0.179735          0.386278        0.321406  \n",
       "min            0.000000          0.000000        0.000000  \n",
       "25%            0.000000          1.000000        0.000000  \n",
       "50%            0.000000          1.000000        0.000000  \n",
       "75%            0.000000          1.000000        0.000000  \n",
       "max            1.000000          1.000000        1.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankPromoModel_hsng_Df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 42 columns):\n",
      "age                    45211 non-null int64\n",
      "balance                45211 non-null int64\n",
      "day                    45211 non-null int64\n",
      "duration               45211 non-null int64\n",
      "campaign               45211 non-null int64\n",
      "pdays                  45211 non-null int64\n",
      "previous               45211 non-null int64\n",
      "job_blue-collar        45211 non-null uint8\n",
      "job_entrepreneur       45211 non-null uint8\n",
      "job_housemaid          45211 non-null uint8\n",
      "job_management         45211 non-null uint8\n",
      "job_retired            45211 non-null uint8\n",
      "job_self-employed      45211 non-null uint8\n",
      "job_services           45211 non-null uint8\n",
      "job_student            45211 non-null uint8\n",
      "job_technician         45211 non-null uint8\n",
      "job_unemployed         45211 non-null uint8\n",
      "job_unknown            45211 non-null uint8\n",
      "marital_married        45211 non-null uint8\n",
      "marital_single         45211 non-null uint8\n",
      "education_secondary    45211 non-null uint8\n",
      "education_tertiary     45211 non-null uint8\n",
      "education_unknown      45211 non-null uint8\n",
      "default_yes            45211 non-null uint8\n",
      "loan_yes               45211 non-null uint8\n",
      "contact_telephone      45211 non-null uint8\n",
      "contact_unknown        45211 non-null uint8\n",
      "month_aug              45211 non-null uint8\n",
      "month_dec              45211 non-null uint8\n",
      "month_feb              45211 non-null uint8\n",
      "month_jan              45211 non-null uint8\n",
      "month_jul              45211 non-null uint8\n",
      "month_jun              45211 non-null uint8\n",
      "month_mar              45211 non-null uint8\n",
      "month_may              45211 non-null uint8\n",
      "month_nov              45211 non-null uint8\n",
      "month_oct              45211 non-null uint8\n",
      "month_sep              45211 non-null uint8\n",
      "poutcome_other         45211 non-null uint8\n",
      "poutcome_success       45211 non-null uint8\n",
      "poutcome_unknown       45211 non-null uint8\n",
      "Subscribed_yes         45211 non-null uint8\n",
      "dtypes: int64(7), uint8(35)\n",
      "memory usage: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "bankPromoModel_hsng_Df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_predictordesc\"></a>\n",
    "### Variable Descriptions\n",
    "\n",
    "**So we would use above 42 predictors to create and validate our models; and variable \"Housing\" has been renamed to Target variable and would be used as class label.** The description of these variables is as:\n",
    "\n",
    "- **Age**  Age is a numeric variable that ranges from ages 18-95 years.  \n",
    "- **Job**  Job type is a categorical variable that entered the client into types of occupations.  The choices were: admin., unknown, unemployed, management, housemaid, entrepreneur, student, blue-collar, self-employed, retired, technician and services.  \n",
    "- **Marital**  Marital status is a categorical variable that describes if the client is married, divorced or single.  For widowed clients, the bank has selected the divorced selection.\n",
    "- **Education**  Education represents the clients highest level of education.  The categorical variable has the following selections:  unknown, primary, secondary or tertiary.  Primary level is equivalent to the US elementary and middle school grades.  Secondary is similar to the US high school, but is split between more professional teachings versus vocations.  Tertiary level represents all level of higher education from special licenses, bachelors to post doctorate school (https://www.scholaro.com/pro/Countries/Portugal/Education-System).\n",
    "- **Default**  Default represents if the client has defaulted in their credit history as a binary variable denoted with yes for default or no for no default.\n",
    "- **Balance**  Balance is a numeric variable which signifies the yearly average balance in Euros.\n",
    "- **Housing**  Housing is a binary variable which represents if the client has a home loan or not.  The selections are yes or no.\n",
    "- **Loan**  Loan is similar to the housing variable except it represents if the client has a personal loan.\n",
    "- **Contact**  Contact is a categorical variable describing the method of telecommunication between the bank and the client.  The selections are:  unknown, telephone or cellular.\n",
    "- **Day**  Day is a numeric variable that represents the day of the month of the last contact.\n",
    "- **Month**  Month is represented as a categorical variable where each month is denoted by the first three letters.  Every month of the year is represented.  The month corresponds to the last contact made with the client.\n",
    "- **Duration**  Duration is the amount of time (a numeric variable) in seconds that the last contact with the client lasted.  This attribute is not the total time the clients were interviewed.     \n",
    "- **Campaign**  Campaign is a numeric variable which represents the number of times the bank has contacted, using any method of communication, the client during this particular marketing campaign.\n",
    "- **Previous**  Previous is a numeric variable that identifies the number of times a client has been involved with a marketing campaign with this bank prior to the current campaign. \n",
    "- **pOutcome**  pOutcome represents the outcome of a previous marketing campaign.  The categorical variable is identified by:  unknown, other, failure or success.  Each client that has not participated in a previous marketing campaign has been marked as unknown for pOutcome.\n",
    "- **pdays** - pdays represents the number of days since the last contact in a previous campaign. This feature has seen to be correlated to pOutcome in the analysis for Task1.\n",
    "- **Subscribed**  Y signifies yes if the customer accepted a term deposit during the current marketing campaign.  The binary variable is defined as yes or no.  In the remaining portions of the report, this variable is denoted as subscribed with the results remaining as yes or no. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_SummaryObjDataPrepII\"></a>\n",
    "### Summary and Objectives tracking for section: Data Preparation Part 2\n",
    "\n",
    "Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "// The final dataset that is to be used for classification in Task 2 has been described as above. No new variables were created for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval1\"></a>\n",
    "## Modeling and Evaluation 1 - Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this task, we are predicting whether a bank client has a housing loan. 56% of the clients in this data set have housing loan and the remaining 44% do not, which dataset is closely balanced for this task. We used **accuracy** to evaluate the model performance and select the model parameters.\n",
    "\n",
    "- From a business standpoint, it is equally important to know who has a loan or not. Banks could offer additional promotions regarding home refinancing for customers who have housing loans. Similarly, if the bank wants to attract new home owners, they can contact people who do not have housing loans. **Correct prediction is more important for this model and accuracy is chosen as a primary metric to evaluate the models.**\n",
    "\n",
    "- **This will be followed by AuC scores**, as accuracy is calculated at a threshold value of 0.5. In real life, the probability of the population having a housing loan is not 50-50. This data set was collected at time of economic recession, so it is likely that prior probabilities of people having housing loan were not at 50-50 level. (reference: https://tradingeconomics.com/portugal/home-ownership-rate shows in 2010 the home ownership rate was ~75%, no 2008-2009 data was found) . **Hence, AuC score (in conjunction to ROC curve) score which basically provides accuracies at different threshold values, would overall provide a better measure of model performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval2\"></a>\n",
    "## Modeling and Evaluation 2 - Task 2\n",
    "For task 2, we are using 10-fold cross validation method to split the training set. As shown, we also have a separate data set from UCI Machine Learning website for prediction and test. There are 45,211 instances in the training set and 4,521 in the holdout test dataset. Dataset for task2 is almost balanced (_ also assumed to be \"balanced\" for our model evaluations_),so a standard K-Fold cross validation would be appropriate for dividing our dataset into training and test sets. So next we would explore **Random 10-fold and 10-fold Shuffle Split** as possible Cross validation techniques for dividing our dataset into training and testing splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_LRMetricsKfold\"></a>\n",
    "### LR Metrics Standard K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=999, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "# Training and Test Split\n",
    "# Since housing is a balanced dataset ( with 56% yes and 44% No , we will use simple KFold cv objects)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "      \n",
    "# To use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 10\n",
    "kfold_cv_object = KFold(n_splits=num_cv_iterations , shuffle = False , random_state=999)\n",
    "#n_splits=num_cv_iterations,test_size  = 0.2, random_state=999\n",
    "                         \n",
    "print(kfold_cv_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3350</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.944613</td>\n",
       "      <td>0.744731</td>\n",
       "      <td>0.574598</td>\n",
       "      <td>0.816525</td>\n",
       "      <td>0.895179</td>\n",
       "      <td>0.735653</td>\n",
       "      <td>0.897026</td>\n",
       "      <td>0.745085</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>0.744378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.853853</td>\n",
       "      <td>0.751690</td>\n",
       "      <td>0.585186</td>\n",
       "      <td>0.824778</td>\n",
       "      <td>0.752931</td>\n",
       "      <td>0.745441</td>\n",
       "      <td>0.908155</td>\n",
       "      <td>0.759814</td>\n",
       "      <td>0.805679</td>\n",
       "      <td>0.743738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3075</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.500095</td>\n",
       "      <td>0.809572</td>\n",
       "      <td>0.627757</td>\n",
       "      <td>0.842206</td>\n",
       "      <td>0.418491</td>\n",
       "      <td>0.771369</td>\n",
       "      <td>0.343252</td>\n",
       "      <td>0.786251</td>\n",
       "      <td>0.920868</td>\n",
       "      <td>0.834318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3375</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.088985</td>\n",
       "      <td>0.800586</td>\n",
       "      <td>0.538851</td>\n",
       "      <td>0.849564</td>\n",
       "      <td>0.438399</td>\n",
       "      <td>0.779258</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.802225</td>\n",
       "      <td>0.048381</td>\n",
       "      <td>0.798954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2100</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.245696</td>\n",
       "      <td>0.792306</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.786773</td>\n",
       "      <td>0.748169</td>\n",
       "      <td>0.581481</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.155754</td>\n",
       "      <td>0.810256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2400</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.590136</td>\n",
       "      <td>0.786064</td>\n",
       "      <td>0.761794</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.685689</td>\n",
       "      <td>0.757483</td>\n",
       "      <td>0.719409</td>\n",
       "      <td>0.786815</td>\n",
       "      <td>0.500244</td>\n",
       "      <td>0.785315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2900</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.455639</td>\n",
       "      <td>0.792442</td>\n",
       "      <td>0.696512</td>\n",
       "      <td>0.838221</td>\n",
       "      <td>0.629507</td>\n",
       "      <td>0.761637</td>\n",
       "      <td>0.705231</td>\n",
       "      <td>0.781817</td>\n",
       "      <td>0.336534</td>\n",
       "      <td>0.803358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.2800</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.878076</td>\n",
       "      <td>0.754189</td>\n",
       "      <td>0.772711</td>\n",
       "      <td>0.822239</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>0.742910</td>\n",
       "      <td>0.891286</td>\n",
       "      <td>0.762158</td>\n",
       "      <td>0.865252</td>\n",
       "      <td>0.746384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.900643</td>\n",
       "      <td>0.760999</td>\n",
       "      <td>0.843792</td>\n",
       "      <td>0.821425</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.857376</td>\n",
       "      <td>0.755513</td>\n",
       "      <td>0.948509</td>\n",
       "      <td>0.766564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.377330</td>\n",
       "      <td>0.800729</td>\n",
       "      <td>0.646786</td>\n",
       "      <td>0.829804</td>\n",
       "      <td>0.630613</td>\n",
       "      <td>0.758270</td>\n",
       "      <td>0.292317</td>\n",
       "      <td>0.784798</td>\n",
       "      <td>0.532072</td>\n",
       "      <td>0.817321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0    1.3350      0.0325       0.944613        0.744731  0.574598   0.816525   \n",
       "1    1.3625      0.0500       0.853853        0.751690  0.585186   0.824778   \n",
       "2    1.3075      0.0525       0.500095        0.809572  0.627757   0.842206   \n",
       "3    1.3375      0.0400       0.088985        0.800586  0.538851   0.849564   \n",
       "4    1.2100      0.0400       0.245696        0.792306  0.669041   0.821918   \n",
       "5    1.2400      0.0400       0.590136        0.786064  0.761794   0.834171   \n",
       "6    1.2900      0.0300       0.455639        0.792442  0.696512   0.838221   \n",
       "7    2.2800      0.0400       0.878076        0.754189  0.772711   0.822239   \n",
       "8    0.8900      0.0400       0.900643        0.760999  0.843792   0.821425   \n",
       "9    0.9500      0.0300       0.377330        0.800729  0.646786   0.829804   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.895179        0.735653        0.897026         0.745085   \n",
       "1       0.752931        0.745441        0.908155         0.759814   \n",
       "2       0.418491        0.771369        0.343252         0.786251   \n",
       "3       0.438399        0.779258        0.553571         0.802225   \n",
       "4       0.786773        0.748169        0.581481         0.775134   \n",
       "5       0.685689        0.757483        0.719409         0.786815   \n",
       "6       0.629507        0.761637        0.705231         0.781817   \n",
       "7       0.807122        0.742910        0.891286         0.762158   \n",
       "8       0.846273        0.741927        0.857376         0.755513   \n",
       "9       0.630613        0.758270        0.292317         0.784798   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.997532      0.744378  \n",
       "1     0.805679      0.743738  \n",
       "2     0.920868      0.834318  \n",
       "3     0.048381      0.798954  \n",
       "4     0.155754      0.810256  \n",
       "5     0.500244      0.785315  \n",
       "6     0.336534      0.803358  \n",
       "7     0.865252      0.746384  \n",
       "8     0.948509      0.766564  \n",
       "9     0.532072      0.817321  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           1.320250\n",
       "score_time         0.039500\n",
       "test_F1_Score      0.583507\n",
       "train_F1_Score     0.779331\n",
       "test_AUC           0.671703\n",
       "train_AUC          0.830085\n",
       "test_Accuracy      0.689098\n",
       "train_Accuracy     0.754212\n",
       "test_Precision     0.674911\n",
       "train_Precision    0.773961\n",
       "test_Recall        0.611083\n",
       "train_Recall       0.785059\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.779331</td>\n",
       "      <td>0.830085</td>\n",
       "      <td>0.754212</td>\n",
       "      <td>0.773961</td>\n",
       "      <td>0.785059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.779331   0.830085        0.754212         0.773961      0.785059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583507</td>\n",
       "      <td>0.671703</td>\n",
       "      <td>0.689098</td>\n",
       "      <td>0.674911</td>\n",
       "      <td>0.611083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.583507  0.671703       0.689098        0.674911     0.611083"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from sklearn import metrics as mt\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel = make_pipeline(StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores = cross_validate(logisticModel , X, y=y , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores))\n",
    "display(pd.DataFrame(scores).mean())\n",
    "end = datetime.now()\n",
    "\n",
    "print()\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb3929e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(scores)[testCol].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_LRMetricsKShuffle\"></a>\n",
    "### LR Metrics Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=10, random_state=999, test_size=0.1, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "# To use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 10\n",
    "shuffle_cv_object = ShuffleSplit(n_splits=num_cv_iterations, test_size = 0.1, random_state=999)\n",
    "                         \n",
    "print(shuffle_cv_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3850</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.775268</td>\n",
       "      <td>0.778855</td>\n",
       "      <td>0.827496</td>\n",
       "      <td>0.829789</td>\n",
       "      <td>0.749226</td>\n",
       "      <td>0.752316</td>\n",
       "      <td>0.772817</td>\n",
       "      <td>0.773054</td>\n",
       "      <td>0.777734</td>\n",
       "      <td>0.784745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4325</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.788132</td>\n",
       "      <td>0.777900</td>\n",
       "      <td>0.835867</td>\n",
       "      <td>0.828970</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.783452</td>\n",
       "      <td>0.771810</td>\n",
       "      <td>0.792869</td>\n",
       "      <td>0.784086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4050</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.781732</td>\n",
       "      <td>0.778234</td>\n",
       "      <td>0.838677</td>\n",
       "      <td>0.828603</td>\n",
       "      <td>0.755860</td>\n",
       "      <td>0.751505</td>\n",
       "      <td>0.779882</td>\n",
       "      <td>0.771818</td>\n",
       "      <td>0.783591</td>\n",
       "      <td>0.784757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3675</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.782011</td>\n",
       "      <td>0.778980</td>\n",
       "      <td>0.833092</td>\n",
       "      <td>0.829253</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.767836</td>\n",
       "      <td>0.772082</td>\n",
       "      <td>0.796719</td>\n",
       "      <td>0.786002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.787298</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.838794</td>\n",
       "      <td>0.828522</td>\n",
       "      <td>0.764485</td>\n",
       "      <td>0.750399</td>\n",
       "      <td>0.781833</td>\n",
       "      <td>0.770795</td>\n",
       "      <td>0.792840</td>\n",
       "      <td>0.784888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.3600</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>0.777182</td>\n",
       "      <td>0.831703</td>\n",
       "      <td>0.829384</td>\n",
       "      <td>0.756966</td>\n",
       "      <td>0.750694</td>\n",
       "      <td>0.785601</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.779093</td>\n",
       "      <td>0.782961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.3500</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.774514</td>\n",
       "      <td>0.778807</td>\n",
       "      <td>0.824350</td>\n",
       "      <td>0.830311</td>\n",
       "      <td>0.748784</td>\n",
       "      <td>0.751702</td>\n",
       "      <td>0.763302</td>\n",
       "      <td>0.772398</td>\n",
       "      <td>0.786060</td>\n",
       "      <td>0.785323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.3800</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.784175</td>\n",
       "      <td>0.778494</td>\n",
       "      <td>0.830247</td>\n",
       "      <td>0.829594</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>0.751628</td>\n",
       "      <td>0.776270</td>\n",
       "      <td>0.771426</td>\n",
       "      <td>0.792244</td>\n",
       "      <td>0.785692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.768526</td>\n",
       "      <td>0.779463</td>\n",
       "      <td>0.823310</td>\n",
       "      <td>0.830286</td>\n",
       "      <td>0.743034</td>\n",
       "      <td>0.752759</td>\n",
       "      <td>0.761247</td>\n",
       "      <td>0.773899</td>\n",
       "      <td>0.775945</td>\n",
       "      <td>0.785109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.771485</td>\n",
       "      <td>0.779363</td>\n",
       "      <td>0.821751</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.752587</td>\n",
       "      <td>0.762128</td>\n",
       "      <td>0.773346</td>\n",
       "      <td>0.781075</td>\n",
       "      <td>0.785474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0    1.3850        0.03       0.775268        0.778855  0.827496   0.829789   \n",
       "1    1.4325        0.03       0.788132        0.777900  0.835867   0.828970   \n",
       "2    1.4050        0.03       0.781732        0.778234  0.838677   0.828603   \n",
       "3    1.3675        0.03       0.782011        0.778980  0.833092   0.829253   \n",
       "4    1.4000        0.04       0.787298        0.777778  0.838794   0.828522   \n",
       "5    1.3600        0.04       0.782333        0.777182  0.831703   0.829384   \n",
       "6    1.3500        0.03       0.774514        0.778807  0.824350   0.830311   \n",
       "7    1.3800        0.04       0.784175        0.778494  0.830247   0.829594   \n",
       "8    0.5900        0.02       0.768526        0.779463  0.823310   0.830286   \n",
       "9    0.5800        0.02       0.771485        0.779363  0.821751   0.830527   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.749226        0.752316        0.772817         0.773054   \n",
       "1       0.764706        0.750940        0.783452         0.771810   \n",
       "2       0.755860        0.751505        0.779882         0.771818   \n",
       "3       0.754533        0.751923        0.767836         0.772082   \n",
       "4       0.764485        0.750399        0.781833         0.770795   \n",
       "5       0.756966        0.750694        0.785601         0.771488   \n",
       "6       0.748784        0.751702        0.763302         0.772398   \n",
       "7       0.756303        0.751628        0.776270         0.771426   \n",
       "8       0.743034        0.752759        0.761247         0.773899   \n",
       "9       0.744803        0.752587        0.762128         0.773346   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.777734      0.784745  \n",
       "1     0.792869      0.784086  \n",
       "2     0.783591      0.784757  \n",
       "3     0.796719      0.786002  \n",
       "4     0.792840      0.784888  \n",
       "5     0.779093      0.782961  \n",
       "6     0.786060      0.785323  \n",
       "7     0.792244      0.785692  \n",
       "8     0.775945      0.785109  \n",
       "9     0.781075      0.785474  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           1.225000\n",
       "score_time         0.031000\n",
       "test_F1_Score      0.779547\n",
       "train_F1_Score     0.778506\n",
       "test_AUC           0.830529\n",
       "train_AUC          0.829524\n",
       "test_Accuracy      0.753870\n",
       "train_Accuracy     0.751645\n",
       "test_Precision     0.773437\n",
       "train_Precision    0.772212\n",
       "test_Recall        0.785817\n",
       "train_Recall       0.784904\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.778506</td>\n",
       "      <td>0.829524</td>\n",
       "      <td>0.751645</td>\n",
       "      <td>0.772212</td>\n",
       "      <td>0.784904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.778506   0.829524        0.751645         0.772212      0.784904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.779547</td>\n",
       "      <td>0.830529</td>\n",
       "      <td>0.75387</td>\n",
       "      <td>0.773437</td>\n",
       "      <td>0.785817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.779547  0.830529        0.75387        0.773437     0.785817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from sklearn import metrics as mt\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "\n",
    "logisticModel = make_pipeline(StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores = cross_validate(logisticModel , X, y=y , cv = shuffle_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores))\n",
    "display(pd.DataFrame(scores).mean())\n",
    "end = datetime.now()\n",
    "\n",
    "\n",
    "print()\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb424668>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(scores)[testCol].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval2Summary\"></a>\n",
    "### Model 2 Summary\n",
    "**Standard K-fold was chosen for this mode.** Reasons for using k-fold for splitting the data versus Shuffle split\n",
    "   Based on the visualization, there are no outliers in standard K-fold\n",
    "\tShuffleSplit will randomly sample the entire dataset during each iteration to generate a training set and a test set. Since we are sampling from the entire dataset during each iteration, values selected during one iteration, could be selected again during another iteration. Whereas in K-fold the test data is different in each fold. This generalizes the model for prediction on future datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval3\"></a>\n",
    "## Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting ready Additional Test Dataset(with 10% instances) for final model fitting and evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      "age           4521 non-null int64\n",
      "job           4521 non-null object\n",
      "marital       4521 non-null object\n",
      "education     4521 non-null object\n",
      "default       4521 non-null object\n",
      "balance       4521 non-null int64\n",
      "loan          4521 non-null object\n",
      "contact       4521 non-null object\n",
      "day           4521 non-null int64\n",
      "month         4521 non-null object\n",
      "duration      4521 non-null int64\n",
      "campaign      4521 non-null int64\n",
      "pdays         4521 non-null int64\n",
      "previous      4521 non-null int64\n",
      "poutcome      4521 non-null object\n",
      "Subscribed    4521 non-null object\n",
      "Target        4521 non-null int32\n",
      "dtypes: int32(1), int64(7), object(9)\n",
      "memory usage: 582.9+ KB\n"
     ]
    }
   ],
   "source": [
    "pathOfAdditionalDataFile = \"data/bank.csv\"\n",
    "\n",
    "# Import the semi-colon delimited data file into pandas dataFrame\n",
    "bankPromoAdditional_h_df = pd.read_csv(pathOfAdditionalDataFile, sep = \";\")\n",
    "\n",
    "# Rename the Target/Final Outcome column from \"y\" to \"Subscribed\" as based on data description.\n",
    "bankPromoAdditional_h_df = bankPromoAdditional_h_df.rename(columns={\"y\":\"Subscribed\"})\n",
    "\n",
    "bankPromoAdditional_h_df['Target'] = bankPromoAdditional_h_df['housing'].apply(lambda resp : 1 if resp == \"yes\" else 0)\n",
    "bankPromoAdditional_h_df['Target'] = bankPromoAdditional_h_df['Target'].astype(np.int)\n",
    "# Delete the original 'housing' column\n",
    "del bankPromoAdditional_h_df['housing']\n",
    "\n",
    "bankPromoAdditional_h_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Target Variable in Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset info\n",
      "=====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 42 columns):\n",
      "age                    4521 non-null int64\n",
      "balance                4521 non-null int64\n",
      "day                    4521 non-null int64\n",
      "duration               4521 non-null int64\n",
      "campaign               4521 non-null int64\n",
      "pdays                  4521 non-null int64\n",
      "previous               4521 non-null int64\n",
      "job_blue-collar        4521 non-null uint8\n",
      "job_entrepreneur       4521 non-null uint8\n",
      "job_housemaid          4521 non-null uint8\n",
      "job_management         4521 non-null uint8\n",
      "job_retired            4521 non-null uint8\n",
      "job_self-employed      4521 non-null uint8\n",
      "job_services           4521 non-null uint8\n",
      "job_student            4521 non-null uint8\n",
      "job_technician         4521 non-null uint8\n",
      "job_unemployed         4521 non-null uint8\n",
      "job_unknown            4521 non-null uint8\n",
      "marital_married        4521 non-null uint8\n",
      "marital_single         4521 non-null uint8\n",
      "education_secondary    4521 non-null uint8\n",
      "education_tertiary     4521 non-null uint8\n",
      "education_unknown      4521 non-null uint8\n",
      "default_yes            4521 non-null uint8\n",
      "loan_yes               4521 non-null uint8\n",
      "contact_telephone      4521 non-null uint8\n",
      "contact_unknown        4521 non-null uint8\n",
      "month_aug              4521 non-null uint8\n",
      "month_dec              4521 non-null uint8\n",
      "month_feb              4521 non-null uint8\n",
      "month_jan              4521 non-null uint8\n",
      "month_jul              4521 non-null uint8\n",
      "month_jun              4521 non-null uint8\n",
      "month_mar              4521 non-null uint8\n",
      "month_may              4521 non-null uint8\n",
      "month_nov              4521 non-null uint8\n",
      "month_oct              4521 non-null uint8\n",
      "month_sep              4521 non-null uint8\n",
      "poutcome_other         4521 non-null uint8\n",
      "poutcome_success       4521 non-null uint8\n",
      "poutcome_unknown       4521 non-null uint8\n",
      "Subscribed_yes         4521 non-null uint8\n",
      "dtypes: int64(7), uint8(35)\n",
      "memory usage: 401.8 KB\n"
     ]
    }
   ],
   "source": [
    "## Test Dataset\n",
    "###################\n",
    "# Covert all categorical variables to corresponding indicator variables\n",
    "for categoricalVar in categoricalVars:\n",
    "    tmpDf = pd.DataFrame()\n",
    "    # Remove 1st class level to avoid multicollinearity\n",
    "    tmpDf = pd.get_dummies(bankPromoAdditional_h_df[categoricalVar], prefix=categoricalVar, drop_first=True)\n",
    "    bankPromoAdditional_h_df = pd.concat((bankPromoAdditional_h_df, tmpDf), axis=1)\n",
    "\n",
    "# Now remove the original categorical vars since indicator variables are created from them.\n",
    "bankPromoAdditional_h_df.drop(categoricalVars, inplace=True, axis=1)\n",
    "\n",
    "if 'Target' in bankPromoAdditional_h_df:\n",
    "    y_Final = bankPromoAdditional_h_df['Target'].values # get the labels we want\n",
    "    del bankPromoAdditional_h_df['Target']        # get rid of the class label\n",
    "    X_Final = bankPromoAdditional_h_df.values\n",
    "\n",
    "print(\"Test dataset info\")\n",
    "print(\"=====================\")\n",
    "bankPromoAdditional_h_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval3Simple_LRFit\"></a>\n",
    "### Create Model\n",
    "### Model 1 : Simple Logistic Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time taken for Logistic Regression with Kfold cv object\n",
      "0:00:05.423182\n",
      "\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.779318</td>\n",
       "      <td>0.830085</td>\n",
       "      <td>0.754199</td>\n",
       "      <td>0.773957</td>\n",
       "      <td>0.785038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.779318   0.830085        0.754199         0.773957      0.785038"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583509</td>\n",
       "      <td>0.671702</td>\n",
       "      <td>0.689098</td>\n",
       "      <td>0.675076</td>\n",
       "      <td>0.611083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.583509  0.671702       0.689098        0.675076     0.611083"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944613</td>\n",
       "      <td>0.574595</td>\n",
       "      <td>0.895179</td>\n",
       "      <td>0.897026</td>\n",
       "      <td>0.997532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.853853</td>\n",
       "      <td>0.585188</td>\n",
       "      <td>0.752931</td>\n",
       "      <td>0.908155</td>\n",
       "      <td>0.805679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500095</td>\n",
       "      <td>0.627755</td>\n",
       "      <td>0.418491</td>\n",
       "      <td>0.343252</td>\n",
       "      <td>0.920868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088985</td>\n",
       "      <td>0.538850</td>\n",
       "      <td>0.438399</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.048381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.245889</td>\n",
       "      <td>0.669035</td>\n",
       "      <td>0.786994</td>\n",
       "      <td>0.583643</td>\n",
       "      <td>0.155754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.589965</td>\n",
       "      <td>0.761793</td>\n",
       "      <td>0.685468</td>\n",
       "      <td>0.718904</td>\n",
       "      <td>0.500244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.455639</td>\n",
       "      <td>0.696505</td>\n",
       "      <td>0.629507</td>\n",
       "      <td>0.705231</td>\n",
       "      <td>0.336534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.878076</td>\n",
       "      <td>0.772716</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>0.891286</td>\n",
       "      <td>0.865252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.900643</td>\n",
       "      <td>0.843795</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.857376</td>\n",
       "      <td>0.948509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.377330</td>\n",
       "      <td>0.646789</td>\n",
       "      <td>0.630613</td>\n",
       "      <td>0.292317</td>\n",
       "      <td>0.532072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.944613  0.574595       0.895179        0.897026     0.997532\n",
       "1       0.853853  0.585188       0.752931        0.908155     0.805679\n",
       "2       0.500095  0.627755       0.418491        0.343252     0.920868\n",
       "3       0.088985  0.538850       0.438399        0.553571     0.048381\n",
       "4       0.245889  0.669035       0.786994        0.583643     0.155754\n",
       "5       0.589965  0.761793       0.685468        0.718904     0.500244\n",
       "6       0.455639  0.696505       0.629507        0.705231     0.336534\n",
       "7       0.878076  0.772716       0.807122        0.891286     0.865252\n",
       "8       0.900643  0.843795       0.846273        0.857376     0.948509\n",
       "9       0.377330  0.646789       0.630613        0.292317     0.532072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from sklearn import metrics as mt\n",
    "import warnings\n",
    "from datetime import datetime \n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel = make_pipeline(StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores_kfold = cross_validate(logisticModel , X, y=y , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "#display(pd.DataFrame(scores_kfold))\n",
    "#display(pd.DataFrame(scores_kfold).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Kfold cv object\")\n",
    "print(end-start)\n",
    "print()\n",
    "\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_kfold)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_kfold)[testCol].mean()).T)\n",
    "\n",
    "slrInitialModelCVTestResults = pd.DataFrame(scores_kfold)[testCol].copy()\n",
    "slrInitialModelCVTestResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval3Simple_LRPoly\"></a>\n",
    "### Polynomial Logistic Regression of degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>305.752405</td>\n",
       "      <td>1.271256</td>\n",
       "      <td>0.945170</td>\n",
       "      <td>0.785228</td>\n",
       "      <td>0.601827</td>\n",
       "      <td>0.855696</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.776746</td>\n",
       "      <td>0.896239</td>\n",
       "      <td>0.782637</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.787836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305.543621</td>\n",
       "      <td>1.121057</td>\n",
       "      <td>0.819712</td>\n",
       "      <td>0.787692</td>\n",
       "      <td>0.592217</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.706260</td>\n",
       "      <td>0.781593</td>\n",
       "      <td>0.910434</td>\n",
       "      <td>0.793397</td>\n",
       "      <td>0.745432</td>\n",
       "      <td>0.782068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318.417222</td>\n",
       "      <td>1.204314</td>\n",
       "      <td>0.496214</td>\n",
       "      <td>0.832336</td>\n",
       "      <td>0.632933</td>\n",
       "      <td>0.871196</td>\n",
       "      <td>0.440832</td>\n",
       "      <td>0.800909</td>\n",
       "      <td>0.346797</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>0.871849</td>\n",
       "      <td>0.848367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>286.996691</td>\n",
       "      <td>1.084677</td>\n",
       "      <td>0.464924</td>\n",
       "      <td>0.822268</td>\n",
       "      <td>0.631688</td>\n",
       "      <td>0.875660</td>\n",
       "      <td>0.542800</td>\n",
       "      <td>0.802900</td>\n",
       "      <td>0.690769</td>\n",
       "      <td>0.822450</td>\n",
       "      <td>0.350371</td>\n",
       "      <td>0.822085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>327.936614</td>\n",
       "      <td>1.046848</td>\n",
       "      <td>0.348553</td>\n",
       "      <td>0.825839</td>\n",
       "      <td>0.676358</td>\n",
       "      <td>0.860434</td>\n",
       "      <td>0.775935</td>\n",
       "      <td>0.788105</td>\n",
       "      <td>0.495430</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.268849</td>\n",
       "      <td>0.847442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>316.047406</td>\n",
       "      <td>1.094571</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.820834</td>\n",
       "      <td>0.759848</td>\n",
       "      <td>0.869019</td>\n",
       "      <td>0.686574</td>\n",
       "      <td>0.795159</td>\n",
       "      <td>0.683841</td>\n",
       "      <td>0.814687</td>\n",
       "      <td>0.571149</td>\n",
       "      <td>0.827074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>309.599117</td>\n",
       "      <td>1.048068</td>\n",
       "      <td>0.534449</td>\n",
       "      <td>0.825129</td>\n",
       "      <td>0.666186</td>\n",
       "      <td>0.871100</td>\n",
       "      <td>0.630834</td>\n",
       "      <td>0.798329</td>\n",
       "      <td>0.637816</td>\n",
       "      <td>0.810754</td>\n",
       "      <td>0.459914</td>\n",
       "      <td>0.840023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>332.337978</td>\n",
       "      <td>1.145880</td>\n",
       "      <td>0.840635</td>\n",
       "      <td>0.791825</td>\n",
       "      <td>0.771713</td>\n",
       "      <td>0.857492</td>\n",
       "      <td>0.760230</td>\n",
       "      <td>0.778963</td>\n",
       "      <td>0.901040</td>\n",
       "      <td>0.788140</td>\n",
       "      <td>0.787820</td>\n",
       "      <td>0.795544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>230.900595</td>\n",
       "      <td>1.005783</td>\n",
       "      <td>0.884003</td>\n",
       "      <td>0.797237</td>\n",
       "      <td>0.829873</td>\n",
       "      <td>0.858611</td>\n",
       "      <td>0.817961</td>\n",
       "      <td>0.780683</td>\n",
       "      <td>0.830949</td>\n",
       "      <td>0.790163</td>\n",
       "      <td>0.944294</td>\n",
       "      <td>0.804439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>593.321671</td>\n",
       "      <td>0.943430</td>\n",
       "      <td>0.370572</td>\n",
       "      <td>0.828707</td>\n",
       "      <td>0.622729</td>\n",
       "      <td>0.863435</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.792824</td>\n",
       "      <td>0.294190</td>\n",
       "      <td>0.814540</td>\n",
       "      <td>0.500526</td>\n",
       "      <td>0.843376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  305.752405    1.271256       0.945170        0.785228  0.601827   0.855696   \n",
       "1  305.543621    1.121057       0.819712        0.787692  0.592217   0.860282   \n",
       "2  318.417222    1.204314       0.496214        0.832336  0.632933   0.871196   \n",
       "3  286.996691    1.084677       0.464924        0.822268  0.631688   0.875660   \n",
       "4  327.936614    1.046848       0.348553        0.825839  0.676358   0.860434   \n",
       "5  316.047406    1.094571       0.622435        0.820834  0.759848   0.869019   \n",
       "6  309.599117    1.048068       0.534449        0.825129  0.666186   0.871100   \n",
       "7  332.337978    1.145880       0.840635        0.791825  0.771713   0.857492   \n",
       "8  230.900595    1.005783       0.884003        0.797237  0.829873   0.858611   \n",
       "9  593.321671    0.943430       0.370572        0.828707  0.622729   0.863435   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.896064        0.776746        0.896239         0.782637   \n",
       "1       0.706260        0.781593        0.910434         0.793397   \n",
       "2       0.440832        0.800909        0.346797         0.816900   \n",
       "3       0.542800        0.802900        0.690769         0.822450   \n",
       "4       0.775935        0.788105        0.495430         0.805310   \n",
       "5       0.686574        0.795159        0.683841         0.814687   \n",
       "6       0.630834        0.798329        0.637816         0.810754   \n",
       "7       0.760230        0.778963        0.901040         0.788140   \n",
       "8       0.817961        0.780683        0.830949         0.790163   \n",
       "9       0.642336        0.792824        0.294190         0.814540   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.999753      0.787836  \n",
       "1     0.745432      0.782068  \n",
       "2     0.871849      0.848367  \n",
       "3     0.350371      0.822085  \n",
       "4     0.268849      0.847442  \n",
       "5     0.571149      0.827074  \n",
       "6     0.459914      0.840023  \n",
       "7     0.787820      0.795544  \n",
       "8     0.944294      0.804439  \n",
       "9     0.500526      0.843376  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           332.685332\n",
       "score_time           1.096588\n",
       "test_F1_Score        0.632667\n",
       "train_F1_Score       0.811709\n",
       "test_AUC             0.678537\n",
       "train_AUC            0.864293\n",
       "test_Accuracy        0.689982\n",
       "train_Accuracy       0.789621\n",
       "test_Precision       0.668750\n",
       "train_Precision      0.803898\n",
       "test_Recall          0.649996\n",
       "train_Recall         0.819825\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for Logistic Regression with Kfold cv object\n",
      "0:10:06.013239\n",
      "\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811709</td>\n",
       "      <td>0.864293</td>\n",
       "      <td>0.789621</td>\n",
       "      <td>0.803898</td>\n",
       "      <td>0.819825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.811709   0.864293        0.789621         0.803898      0.819825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.632667</td>\n",
       "      <td>0.678537</td>\n",
       "      <td>0.689982</td>\n",
       "      <td>0.66875</td>\n",
       "      <td>0.649996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.632667  0.678537       0.689982         0.66875     0.649996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945170</td>\n",
       "      <td>0.601827</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.896239</td>\n",
       "      <td>0.999753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.819712</td>\n",
       "      <td>0.592217</td>\n",
       "      <td>0.706260</td>\n",
       "      <td>0.910434</td>\n",
       "      <td>0.745432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.496214</td>\n",
       "      <td>0.632933</td>\n",
       "      <td>0.440832</td>\n",
       "      <td>0.346797</td>\n",
       "      <td>0.871849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464924</td>\n",
       "      <td>0.631688</td>\n",
       "      <td>0.542800</td>\n",
       "      <td>0.690769</td>\n",
       "      <td>0.350371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348553</td>\n",
       "      <td>0.676358</td>\n",
       "      <td>0.775935</td>\n",
       "      <td>0.495430</td>\n",
       "      <td>0.268849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.759848</td>\n",
       "      <td>0.686574</td>\n",
       "      <td>0.683841</td>\n",
       "      <td>0.571149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.534449</td>\n",
       "      <td>0.666186</td>\n",
       "      <td>0.630834</td>\n",
       "      <td>0.637816</td>\n",
       "      <td>0.459914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.840635</td>\n",
       "      <td>0.771713</td>\n",
       "      <td>0.760230</td>\n",
       "      <td>0.901040</td>\n",
       "      <td>0.787820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.884003</td>\n",
       "      <td>0.829873</td>\n",
       "      <td>0.817961</td>\n",
       "      <td>0.830949</td>\n",
       "      <td>0.944294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.370572</td>\n",
       "      <td>0.622729</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.294190</td>\n",
       "      <td>0.500526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.945170  0.601827       0.896064        0.896239     0.999753\n",
       "1       0.819712  0.592217       0.706260        0.910434     0.745432\n",
       "2       0.496214  0.632933       0.440832        0.346797     0.871849\n",
       "3       0.464924  0.631688       0.542800        0.690769     0.350371\n",
       "4       0.348553  0.676358       0.775935        0.495430     0.268849\n",
       "5       0.622435  0.759848       0.686574        0.683841     0.571149\n",
       "6       0.534449  0.666186       0.630834        0.637816     0.459914\n",
       "7       0.840635  0.771713       0.760230        0.901040     0.787820\n",
       "8       0.884003  0.829873       0.817961        0.830949     0.944294\n",
       "9       0.370572  0.622729       0.642336        0.294190     0.500526"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel2 = make_pipeline(PolynomialFeatures(degree=2), StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores_kfold2 = cross_validate(logisticModel2 , X, y=y , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores_kfold2))\n",
    "display(pd.DataFrame(scores_kfold2).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Kfold cv object\")\n",
    "print(end-start)\n",
    "print()\n",
    "\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_kfold2)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_kfold2)[testCol].mean()).T)\n",
    "\n",
    "p2lrInitialModelCVTestResults = pd.DataFrame(scores_kfold2)[testCol].copy()\n",
    "p2lrInitialModelCVTestResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval3Simple_LRFTune\"></a>\n",
    "### Tuning The Model Hyper Paramters Using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search on Simple Logistic Regression\n",
    "\n",
    "**Using K_Fold Cross Validation Object :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'logisticregression__C': 75.43120063354607, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "     'logisticregression__penalty' : ['l1', 'l2'],\n",
    "    'logisticregression__C' : np.logspace(-4, 4, 50),\n",
    "    'logisticregression__solver' : ['liblinear']\n",
    "   }\n",
    "\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "grid = GridSearchCV(make_pipeline(StandardScaler(), LogisticRegression(random_state=999, class_weight=None)), \\\n",
    "                   param_grid = param_grid, cv = kfold_cv_object , verbose=False, n_jobs=-1, scoring=scoring, refit='Accuracy', \\\n",
    "                   return_train_score=True)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "grid.fit(X, y=y)\n",
    "  \n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval3GSPoly_LRFTune\"></a>\n",
    "#### Grid Search on Polynomial Logistic Regression of degree 2\n",
    "\n",
    "**_GridSearch on Polynomial Logistic Regression did not complete on either local machine or Google VM with 24vCPUs , infact it failed after hours of executing. Hence a decision was made to use Randomized GridSearch for poly to get best parameters and run a GridSearch on values near to the best parameters_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanviarora262/myenv/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'logisticregression__solver': 'liblinear', 'logisticregression__penalty': 'l2', 'logisticregression__class_weight': 'balanced', 'logisticregression__C': 0.001} with a score of 0.70\n"
     ]
    }
   ],
   "source": [
    "## Randomized GridSearch on Logistic Regression poly model\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "     'logisticregression__penalty' : ['l1', 'l2'],\n",
    "    'logisticregression__C' : [0.001, 0.10, 0.0001],\n",
    "    'logisticregression__solver' : ['liblinear'],\n",
    "    'logisticregression__class_weight' : ['balanced', None]\n",
    "   }\n",
    "\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "poly_lr = make_pipeline(PolynomialFeatures(degree=2),StandardScaler(),LogisticRegression(random_state=999) )\n",
    "# Create grid search object\n",
    "\n",
    "poly_grid = RandomizedSearchCV(estimator = poly_lr, n_iter = 50, \n",
    "                   param_distributions = param_grid, cv = kfold_cv_object , verbose=False, n_jobs=-1, scoring=scoring, refit='Accuracy', \\\n",
    "                   return_train_score=True)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "poly_grid.fit(X, y=y)\n",
    "  \n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (poly_grid.best_params_, poly_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'logisticregression__C': 0.0001} with a score of 0.70\n"
     ]
    }
   ],
   "source": [
    "##  GridSearch on Logistic Regression poly model by creating a subgrid \n",
    "##  based on best paramters obtained from Randomized GridSearch\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "sub_param_grid = {\n",
    "    'logisticregression__C' : [0.0001, 0.00001, 0.000001]\n",
    "    }\n",
    "\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "poly_lr = make_pipeline(PolynomialFeatures(degree=2),StandardScaler(),LogisticRegression(random_state=999, class_weight = \"balanced\" , penalty=\"l2\") )\n",
    "# Create grid search object\n",
    "\n",
    "poly_lr_sgrid = GridSearchCV(estimator = poly_lr, \n",
    "                   param_grid = sub_param_grid, cv = kfold_cv_object , verbose=False, n_jobs=-1, scoring=scoring, refit='Accuracy', \\\n",
    "                   return_train_score=True)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "poly_lr_sgrid.fit(X, y=y)\n",
    "  \n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (poly_lr_sgrid.best_params_, poly_lr_sgrid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval3Simple_LRFBestParam\"></a>\n",
    "### Task 2 Model 1 - Summary\n",
    "\n",
    "Simple Logistic Regression Hyper params tuning using K-Fold CV object returned **\"l1\"** penalty with a **\"75.43120063354607\"** C-score that would give a **\"0.69\"** measure of accuracy\n",
    "\n",
    "For above a class_weight value of **None** was used , since we have assumed our dataset to be _balanced_ w.r.t our response variable -_Housing_.\n",
    "\n",
    "Poly Logistic Regression on degree 2 Hyper params tuning using K-Fold CV object returned **\"l2\"** penalty with a **\"0.001\"** C-score that would give a **\"0.70\"** measure of accuracy. For this we had left it for the model to decide whether the dataset is balanced or not, and it returned class_weight = \"balanced\" as the best param value, which means it treated the dataset as imbalanced to get an accuracy score of 0.70\n",
    "\n",
    "Logistic Regression is performing slightly better in **polynomial mode** than linear and so now we will fit our models with the best params returned by both these models and evaluate which mode is better\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time taken for Logistic Regression with Kfold cv object\n",
      "0:00:04.934435\n",
      "\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.77934</td>\n",
       "      <td>0.830082</td>\n",
       "      <td>0.754219</td>\n",
       "      <td>0.773962</td>\n",
       "      <td>0.785076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0         0.77934   0.830082        0.754219         0.773962      0.785076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583567</td>\n",
       "      <td>0.671712</td>\n",
       "      <td>0.689319</td>\n",
       "      <td>0.675354</td>\n",
       "      <td>0.611073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.583567  0.671712       0.689319        0.675354     0.611073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944613</td>\n",
       "      <td>0.574600</td>\n",
       "      <td>0.895179</td>\n",
       "      <td>0.897026</td>\n",
       "      <td>0.997532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.853853</td>\n",
       "      <td>0.585174</td>\n",
       "      <td>0.752931</td>\n",
       "      <td>0.908155</td>\n",
       "      <td>0.805679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500285</td>\n",
       "      <td>0.627751</td>\n",
       "      <td>0.418934</td>\n",
       "      <td>0.343432</td>\n",
       "      <td>0.920868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088985</td>\n",
       "      <td>0.538822</td>\n",
       "      <td>0.438399</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.048381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.246082</td>\n",
       "      <td>0.669007</td>\n",
       "      <td>0.787215</td>\n",
       "      <td>0.585821</td>\n",
       "      <td>0.155754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.589492</td>\n",
       "      <td>0.761735</td>\n",
       "      <td>0.685468</td>\n",
       "      <td>0.719521</td>\n",
       "      <td>0.499267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.455639</td>\n",
       "      <td>0.696442</td>\n",
       "      <td>0.629507</td>\n",
       "      <td>0.705231</td>\n",
       "      <td>0.336534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.878928</td>\n",
       "      <td>0.772995</td>\n",
       "      <td>0.808228</td>\n",
       "      <td>0.890997</td>\n",
       "      <td>0.867181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.900643</td>\n",
       "      <td>0.843801</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.857376</td>\n",
       "      <td>0.948509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.377147</td>\n",
       "      <td>0.646790</td>\n",
       "      <td>0.631055</td>\n",
       "      <td>0.292415</td>\n",
       "      <td>0.531020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.944613  0.574600       0.895179        0.897026     0.997532\n",
       "1       0.853853  0.585174       0.752931        0.908155     0.805679\n",
       "2       0.500285  0.627751       0.418934        0.343432     0.920868\n",
       "3       0.088985  0.538822       0.438399        0.553571     0.048381\n",
       "4       0.246082  0.669007       0.787215        0.585821     0.155754\n",
       "5       0.589492  0.761735       0.685468        0.719521     0.499267\n",
       "6       0.455639  0.696442       0.629507        0.705231     0.336534\n",
       "7       0.878928  0.772995       0.808228        0.890997     0.867181\n",
       "8       0.900643  0.843801       0.846273        0.857376     0.948509\n",
       "9       0.377147  0.646790       0.631055        0.292415     0.531020"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Applying Best Fit params to Simple Logistic Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from sklearn import metrics as mt\n",
    "import warnings\n",
    "from datetime import datetime \n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel_bf = make_pipeline(StandardScaler(),  LogisticRegression(penalty='l1', C=75.43120063354607, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores_bf_kfold = cross_validate(logisticModel_bf , X, y=y , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "#display(pd.DataFrame(scores_bf_kfold))\n",
    "#display(pd.DataFrame(scores_bf_kfold).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Kfold cv object\")\n",
    "print(end-start)\n",
    "print()\n",
    "\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_bf_kfold)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_bf_kfold)[testCol].mean()).T)\n",
    "\n",
    "slrBestFitModelCVTestResults = pd.DataFrame(scores_bf_kfold)[testCol].copy()\n",
    "slrBestFitModelCVTestResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time taken for Logistic Regression with Kfold cv object\n",
      "0:00:38.290921\n",
      "\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776914</td>\n",
       "      <td>0.846259</td>\n",
       "      <td>0.76677</td>\n",
       "      <td>0.828377</td>\n",
       "      <td>0.732222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.776914   0.846259         0.76677         0.828377      0.732222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.547597</td>\n",
       "      <td>0.688262</td>\n",
       "      <td>0.696109</td>\n",
       "      <td>0.712815</td>\n",
       "      <td>0.55154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.547597  0.688262       0.696109        0.712815      0.55154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944860</td>\n",
       "      <td>0.594985</td>\n",
       "      <td>0.895621</td>\n",
       "      <td>0.897072</td>\n",
       "      <td>0.998026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.846833</td>\n",
       "      <td>0.595829</td>\n",
       "      <td>0.742756</td>\n",
       "      <td>0.907423</td>\n",
       "      <td>0.793827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.521680</td>\n",
       "      <td>0.659017</td>\n",
       "      <td>0.533953</td>\n",
       "      <td>0.385959</td>\n",
       "      <td>0.804622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033524</td>\n",
       "      <td>0.601809</td>\n",
       "      <td>0.438841</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.017167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162021</td>\n",
       "      <td>0.679159</td>\n",
       "      <td>0.787215</td>\n",
       "      <td>0.664286</td>\n",
       "      <td>0.092262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.440923</td>\n",
       "      <td>0.765325</td>\n",
       "      <td>0.641009</td>\n",
       "      <td>0.745921</td>\n",
       "      <td>0.312958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.394913</td>\n",
       "      <td>0.705025</td>\n",
       "      <td>0.621102</td>\n",
       "      <td>0.747326</td>\n",
       "      <td>0.268363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.860555</td>\n",
       "      <td>0.784757</td>\n",
       "      <td>0.785667</td>\n",
       "      <td>0.900602</td>\n",
       "      <td>0.823918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.897145</td>\n",
       "      <td>0.845178</td>\n",
       "      <td>0.841407</td>\n",
       "      <td>0.856712</td>\n",
       "      <td>0.941584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.373514</td>\n",
       "      <td>0.651532</td>\n",
       "      <td>0.673524</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.462671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.944860  0.594985       0.895621        0.897072     0.998026\n",
       "1       0.846833  0.595829       0.742756        0.907423     0.793827\n",
       "2       0.521680  0.659017       0.533953        0.385959     0.804622\n",
       "3       0.033524  0.601809       0.438841        0.709677     0.017167\n",
       "4       0.162021  0.679159       0.787215        0.664286     0.092262\n",
       "5       0.440923  0.765325       0.641009        0.745921     0.312958\n",
       "6       0.394913  0.705025       0.621102        0.747326     0.268363\n",
       "7       0.860555  0.784757       0.785667        0.900602     0.823918\n",
       "8       0.897145  0.845178       0.841407        0.856712     0.941584\n",
       "9       0.373514  0.651532       0.673524        0.313167     0.462671"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Applying Best Fit params to Ploy Logistic Model of Order 2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel2_bf = make_pipeline(PolynomialFeatures(degree=2), StandardScaler(),  LogisticRegression(penalty='l2', C=0.0001, class_weight=\"balanced\", random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores_bf_kfold2 = cross_validate(logisticModel2_bf , X, y=y , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "#display(pd.DataFrame(scores_bf_kfold2))\n",
    "#display(pd.DataFrame(scores_bf_kfold2).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Kfold cv object\")\n",
    "print(end-start)\n",
    "print()\n",
    "\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_bf_kfold2)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_bf_kfold2)[testCol].mean()).T)\n",
    "\n",
    "p2lrBestFitModelCVTestResults = pd.DataFrame(scores_bf_kfold2)[testCol].copy()\n",
    "p2lrBestFitModelCVTestResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintaining the Training model evaluations, Logistic Regression is slightly better in **polynomial** or order 2 than linear model with an test accuracy of 0.696 and 0.689 respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval4_SimpleRF\"></a>\n",
    "### Model 2 : Simple Random Forest (RF) Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.477648</td>\n",
       "      <td>0.571808</td>\n",
       "      <td>0.896149</td>\n",
       "      <td>0.987041</td>\n",
       "      <td>0.571459</td>\n",
       "      <td>0.999279</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.986679</td>\n",
       "      <td>0.902201</td>\n",
       "      <td>0.994939</td>\n",
       "      <td>0.890178</td>\n",
       "      <td>0.979267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512438</td>\n",
       "      <td>0.567625</td>\n",
       "      <td>0.612521</td>\n",
       "      <td>0.985981</td>\n",
       "      <td>0.591019</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.479761</td>\n",
       "      <td>0.985598</td>\n",
       "      <td>0.920297</td>\n",
       "      <td>0.994546</td>\n",
       "      <td>0.459012</td>\n",
       "      <td>0.977562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.460059</td>\n",
       "      <td>0.561658</td>\n",
       "      <td>0.468588</td>\n",
       "      <td>0.989164</td>\n",
       "      <td>0.615618</td>\n",
       "      <td>0.999279</td>\n",
       "      <td>0.592126</td>\n",
       "      <td>0.987442</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.994372</td>\n",
       "      <td>0.569328</td>\n",
       "      <td>0.984010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.540858</td>\n",
       "      <td>0.534197</td>\n",
       "      <td>0.325622</td>\n",
       "      <td>0.987655</td>\n",
       "      <td>0.555389</td>\n",
       "      <td>0.999319</td>\n",
       "      <td>0.484185</td>\n",
       "      <td>0.986409</td>\n",
       "      <td>0.629050</td>\n",
       "      <td>0.995186</td>\n",
       "      <td>0.219664</td>\n",
       "      <td>0.980237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.460780</td>\n",
       "      <td>0.580924</td>\n",
       "      <td>0.257084</td>\n",
       "      <td>0.989353</td>\n",
       "      <td>0.636202</td>\n",
       "      <td>0.999351</td>\n",
       "      <td>0.762221</td>\n",
       "      <td>0.987442</td>\n",
       "      <td>0.423690</td>\n",
       "      <td>0.994513</td>\n",
       "      <td>0.184524</td>\n",
       "      <td>0.984247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.509099</td>\n",
       "      <td>0.540830</td>\n",
       "      <td>0.593172</td>\n",
       "      <td>0.988580</td>\n",
       "      <td>0.721869</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.654722</td>\n",
       "      <td>0.987122</td>\n",
       "      <td>0.635045</td>\n",
       "      <td>0.994780</td>\n",
       "      <td>0.556479</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.474559</td>\n",
       "      <td>0.576514</td>\n",
       "      <td>0.509861</td>\n",
       "      <td>0.988034</td>\n",
       "      <td>0.675282</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.626189</td>\n",
       "      <td>0.986532</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>0.994505</td>\n",
       "      <td>0.421988</td>\n",
       "      <td>0.981646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.565592</td>\n",
       "      <td>0.536247</td>\n",
       "      <td>0.741019</td>\n",
       "      <td>0.986357</td>\n",
       "      <td>0.765246</td>\n",
       "      <td>0.999155</td>\n",
       "      <td>0.649193</td>\n",
       "      <td>0.985697</td>\n",
       "      <td>0.909419</td>\n",
       "      <td>0.994329</td>\n",
       "      <td>0.625241</td>\n",
       "      <td>0.978513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.505362</td>\n",
       "      <td>0.534618</td>\n",
       "      <td>0.866192</td>\n",
       "      <td>0.985505</td>\n",
       "      <td>0.813121</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.804689</td>\n",
       "      <td>0.984591</td>\n",
       "      <td>0.871873</td>\n",
       "      <td>0.993845</td>\n",
       "      <td>0.860584</td>\n",
       "      <td>0.977303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.568102</td>\n",
       "      <td>0.354954</td>\n",
       "      <td>0.988036</td>\n",
       "      <td>0.635451</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.641451</td>\n",
       "      <td>0.985869</td>\n",
       "      <td>0.285531</td>\n",
       "      <td>0.994180</td>\n",
       "      <td>0.468980</td>\n",
       "      <td>0.981968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  0.477648    0.571808       0.896149        0.987041  0.571459   0.999279   \n",
       "1  0.512438    0.567625       0.612521        0.985981  0.591019   0.999197   \n",
       "2  0.460059    0.561658       0.468588        0.989164  0.615618   0.999279   \n",
       "3  0.540858    0.534197       0.325622        0.987655  0.555389   0.999319   \n",
       "4  0.460780    0.580924       0.257084        0.989353  0.636202   0.999351   \n",
       "5  0.509099    0.540830       0.593172        0.988580  0.721869   0.999325   \n",
       "6  0.474559    0.576514       0.509861        0.988034  0.675282   0.999286   \n",
       "7  0.565592    0.536247       0.741019        0.986357  0.765246   0.999155   \n",
       "8  0.505362    0.534618       0.866192        0.985505  0.813121   0.999079   \n",
       "9  0.473552    0.568102       0.354954        0.988036  0.635451   0.999086   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.815126        0.986679        0.902201         0.994939   \n",
       "1       0.479761        0.985598        0.920297         0.994546   \n",
       "2       0.592126        0.987442        0.398139         0.994372   \n",
       "3       0.484185        0.986409        0.629050         0.995186   \n",
       "4       0.762221        0.987442        0.423690         0.994513   \n",
       "5       0.654722        0.987122        0.635045         0.994780   \n",
       "6       0.626189        0.986532        0.643956         0.994505   \n",
       "7       0.649193        0.985697        0.909419         0.994329   \n",
       "8       0.804689        0.984591        0.871873         0.993845   \n",
       "9       0.641451        0.985869        0.285531         0.994180   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.890178      0.979267  \n",
       "1     0.459012      0.977562  \n",
       "2     0.569328      0.984010  \n",
       "3     0.219664      0.980237  \n",
       "4     0.184524      0.984247  \n",
       "5     0.556479      0.982456  \n",
       "6     0.421988      0.981646  \n",
       "7     0.625241      0.978513  \n",
       "8     0.860584      0.977303  \n",
       "9     0.468980      0.981968  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987571</td>\n",
       "      <td>0.999235</td>\n",
       "      <td>0.986338</td>\n",
       "      <td>0.99452</td>\n",
       "      <td>0.980721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.987571   0.999235        0.986338          0.99452      0.980721"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.562516</td>\n",
       "      <td>0.658066</td>\n",
       "      <td>0.650966</td>\n",
       "      <td>0.66192</td>\n",
       "      <td>0.525598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.562516  0.658066       0.650966         0.66192     0.525598"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896149</td>\n",
       "      <td>0.571459</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.902201</td>\n",
       "      <td>0.890178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.612521</td>\n",
       "      <td>0.591019</td>\n",
       "      <td>0.479761</td>\n",
       "      <td>0.920297</td>\n",
       "      <td>0.459012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.468588</td>\n",
       "      <td>0.615618</td>\n",
       "      <td>0.592126</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.569328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.325622</td>\n",
       "      <td>0.555389</td>\n",
       "      <td>0.484185</td>\n",
       "      <td>0.629050</td>\n",
       "      <td>0.219664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.257084</td>\n",
       "      <td>0.636202</td>\n",
       "      <td>0.762221</td>\n",
       "      <td>0.423690</td>\n",
       "      <td>0.184524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.593172</td>\n",
       "      <td>0.721869</td>\n",
       "      <td>0.654722</td>\n",
       "      <td>0.635045</td>\n",
       "      <td>0.556479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.509861</td>\n",
       "      <td>0.675282</td>\n",
       "      <td>0.626189</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>0.421988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.741019</td>\n",
       "      <td>0.765246</td>\n",
       "      <td>0.649193</td>\n",
       "      <td>0.909419</td>\n",
       "      <td>0.625241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.866192</td>\n",
       "      <td>0.813121</td>\n",
       "      <td>0.804689</td>\n",
       "      <td>0.871873</td>\n",
       "      <td>0.860584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.354954</td>\n",
       "      <td>0.635451</td>\n",
       "      <td>0.641451</td>\n",
       "      <td>0.285531</td>\n",
       "      <td>0.468980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.896149  0.571459       0.815126        0.902201     0.890178\n",
       "1       0.612521  0.591019       0.479761        0.920297     0.459012\n",
       "2       0.468588  0.615618       0.592126        0.398139     0.569328\n",
       "3       0.325622  0.555389       0.484185        0.629050     0.219664\n",
       "4       0.257084  0.636202       0.762221        0.423690     0.184524\n",
       "5       0.593172  0.721869       0.654722        0.635045     0.556479\n",
       "6       0.509861  0.675282       0.626189        0.643956     0.421988\n",
       "7       0.741019  0.765246       0.649193        0.909419     0.625241\n",
       "8       0.866192  0.813121       0.804689        0.871873     0.860584\n",
       "9       0.354954  0.635451       0.641451        0.285531     0.468980"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Random Forest ############################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "baseRfModel = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1))\n",
    "scores_rf = cross_validate(baseRfModel, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "display(pd.DataFrame(scores_rf))\n",
    "\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_rf)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_rf)[testCol].mean()).T)\n",
    "\n",
    "RFInitialModelCVTestResults = pd.DataFrame(scores_rf)[testCol].copy()\n",
    "RFInitialModelCVTestResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The base model is overfitting as the training accuracy is 99.9%. To avoid overfitting added hyper parameter criterion **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval4_RFGid\"></a>\n",
    "### Tuning The Model Hyper Parameters\n",
    "\n",
    "#### Create RF Randomized Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'randomforestclassifier__max_features': ['auto', 'log2', 8, 9, 10], 'randomforestclassifier__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'randomforestclassifier__min_samples_split': [2, 12, 22, 32, 42, 52, 62, 72, 82, 92], 'randomforestclassifier__min_samples_leaf': [1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97], 'randomforestclassifier__class_weight': [None, 'balanced', 'balanced_subsample'], 'randomforestclassifier__bootstrap': [True, False], 'randomforestclassifier__criterion': ['gini', 'entropy']}\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# Create randomized grid\n",
    "#################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2', 8, 9, 10]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [x for x in np.arange(2, 101, 10)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [x for x in np.arange(1, 101, 4)]\n",
    "\n",
    "#Class weights\n",
    "class_weight = [None, 'balanced', 'balanced_subsample']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "              'randomforestclassifier__max_features': max_features,\n",
    "              'randomforestclassifier__max_depth': max_depth,\n",
    "              'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "              'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "              'randomforestclassifier__class_weight': class_weight,\n",
    "              'randomforestclassifier__bootstrap': bootstrap,\n",
    "              'randomforestclassifier__criterion': criterion}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFGidSearch\"></a>\n",
    "#### Randomized Grid Search for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=-1)]: Done 885 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1330 tasks      | elapsed: 65.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1857 tasks      | elapsed: 94.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 99.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__n_estimators': 200, 'randomforestclassifier__min_samples_split': 82, 'randomforestclassifier__min_samples_leaf': 25, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__max_depth': 30, 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__bootstrap': False} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#################################\n",
    "# Random Search Training\n",
    "#################################\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "#rf = RandomForestClassifier() #Originally was this\n",
    "rf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_randomgrid = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                                   n_iter = 200, \n",
    "                                   cv = kfold_cv_object,\n",
    "                                   verbose=2, \n",
    "                                   random_state=999, \n",
    "                                   n_jobs = -1,\n",
    "                                   scoring=scoring,\n",
    "                                   refit='Accuracy', \\\n",
    "                                   return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_randomgrid.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rf_randomgrid.best_params_, rf_randomgrid.best_score_))\n",
    "#rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFGidSearchMetrics\"></a>\n",
    "### Randomized Grid Search Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.173242</td>\n",
       "      <td>1.130251</td>\n",
       "      <td>0.945183</td>\n",
       "      <td>0.794560</td>\n",
       "      <td>0.632266</td>\n",
       "      <td>0.874154</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.795448</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.828145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.763592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.118589</td>\n",
       "      <td>1.212926</td>\n",
       "      <td>0.854148</td>\n",
       "      <td>0.793773</td>\n",
       "      <td>0.597230</td>\n",
       "      <td>0.876642</td>\n",
       "      <td>0.753816</td>\n",
       "      <td>0.796854</td>\n",
       "      <td>0.910081</td>\n",
       "      <td>0.837175</td>\n",
       "      <td>0.804691</td>\n",
       "      <td>0.754649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.784884</td>\n",
       "      <td>1.416365</td>\n",
       "      <td>0.499487</td>\n",
       "      <td>0.821021</td>\n",
       "      <td>0.641772</td>\n",
       "      <td>0.885518</td>\n",
       "      <td>0.460960</td>\n",
       "      <td>0.803219</td>\n",
       "      <td>0.353386</td>\n",
       "      <td>0.873069</td>\n",
       "      <td>0.851541</td>\n",
       "      <td>0.774829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.335069</td>\n",
       "      <td>0.958800</td>\n",
       "      <td>0.130249</td>\n",
       "      <td>0.821248</td>\n",
       "      <td>0.599030</td>\n",
       "      <td>0.892708</td>\n",
       "      <td>0.459412</td>\n",
       "      <td>0.814008</td>\n",
       "      <td>0.740891</td>\n",
       "      <td>0.879318</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>0.770373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.360055</td>\n",
       "      <td>0.961714</td>\n",
       "      <td>0.099815</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.683090</td>\n",
       "      <td>0.881721</td>\n",
       "      <td>0.784561</td>\n",
       "      <td>0.795675</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.879599</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.759265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.212106</td>\n",
       "      <td>1.101879</td>\n",
       "      <td>0.603139</td>\n",
       "      <td>0.817914</td>\n",
       "      <td>0.776542</td>\n",
       "      <td>0.887913</td>\n",
       "      <td>0.686795</td>\n",
       "      <td>0.806955</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.879725</td>\n",
       "      <td>0.526161</td>\n",
       "      <td>0.764219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.162438</td>\n",
       "      <td>1.108456</td>\n",
       "      <td>0.544082</td>\n",
       "      <td>0.824281</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>0.666003</td>\n",
       "      <td>0.811403</td>\n",
       "      <td>0.733116</td>\n",
       "      <td>0.872679</td>\n",
       "      <td>0.432549</td>\n",
       "      <td>0.780969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.209686</td>\n",
       "      <td>1.110232</td>\n",
       "      <td>0.795808</td>\n",
       "      <td>0.797653</td>\n",
       "      <td>0.788606</td>\n",
       "      <td>0.878692</td>\n",
       "      <td>0.706923</td>\n",
       "      <td>0.798280</td>\n",
       "      <td>0.902797</td>\n",
       "      <td>0.848660</td>\n",
       "      <td>0.711491</td>\n",
       "      <td>0.752430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.223480</td>\n",
       "      <td>1.038435</td>\n",
       "      <td>0.898419</td>\n",
       "      <td>0.802842</td>\n",
       "      <td>0.856661</td>\n",
       "      <td>0.876029</td>\n",
       "      <td>0.842292</td>\n",
       "      <td>0.798820</td>\n",
       "      <td>0.852623</td>\n",
       "      <td>0.845568</td>\n",
       "      <td>0.949413</td>\n",
       "      <td>0.764226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.181271</td>\n",
       "      <td>1.123418</td>\n",
       "      <td>0.371585</td>\n",
       "      <td>0.817368</td>\n",
       "      <td>0.643284</td>\n",
       "      <td>0.880685</td>\n",
       "      <td>0.643884</td>\n",
       "      <td>0.796977</td>\n",
       "      <td>0.295469</td>\n",
       "      <td>0.878028</td>\n",
       "      <td>0.500526</td>\n",
       "      <td>0.764548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  8.173242    1.130251       0.945183        0.794560  0.632266   0.874154   \n",
       "1  8.118589    1.212926       0.854148        0.793773  0.597230   0.876642   \n",
       "2  7.784884    1.416365       0.499487        0.821021  0.641772   0.885518   \n",
       "3  8.335069    0.958800       0.130249        0.821248  0.599030   0.892708   \n",
       "4  8.360055    0.961714       0.099815        0.815014  0.683090   0.881721   \n",
       "5  8.212106    1.101879       0.603139        0.817914  0.776542   0.887913   \n",
       "6  8.162438    1.108456       0.544082        0.824281  0.731959   0.888828   \n",
       "7  8.209686    1.110232       0.795808        0.797653  0.788606   0.878692   \n",
       "8  8.223480    1.038435       0.898419        0.802842  0.856661   0.876029   \n",
       "9  8.181271    1.123418       0.371585        0.817368  0.643284   0.880685   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.896064        0.795448        0.896064         0.828145   \n",
       "1       0.753816        0.796854        0.910081         0.837175   \n",
       "2       0.460960        0.803219        0.353386         0.873069   \n",
       "3       0.459412        0.814008        0.740891         0.879318   \n",
       "4       0.784561        0.795675        0.729730         0.879599   \n",
       "5       0.686795        0.806955        0.706500         0.879725   \n",
       "6       0.666003        0.811403        0.733116         0.872679   \n",
       "7       0.706923        0.798280        0.902797         0.848660   \n",
       "8       0.842292        0.798820        0.852623         0.845568   \n",
       "9       0.643884        0.796977        0.295469         0.878028   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     1.000000      0.763592  \n",
       "1     0.804691      0.754649  \n",
       "2     0.851541      0.774829  \n",
       "3     0.071401      0.770373  \n",
       "4     0.053571      0.759265  \n",
       "5     0.526161      0.764219  \n",
       "6     0.432549      0.780969  \n",
       "7     0.711491      0.752430  \n",
       "8     0.949413      0.764226  \n",
       "9     0.500526      0.764548  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574191</td>\n",
       "      <td>0.695044</td>\n",
       "      <td>0.690071</td>\n",
       "      <td>0.712066</td>\n",
       "      <td>0.590134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.574191  0.695044       0.690071        0.712066     0.590134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810567</td>\n",
       "      <td>0.882289</td>\n",
       "      <td>0.801764</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.76491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.810567   0.882289        0.801764         0.862197       0.76491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 200, min_samples_split = 82, min_samples_leaf = 25, \\\n",
    "                                                                         max_features = 'log2', max_depth = 30, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "display(pd.DataFrame(scores))\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval4_RFSubGrids\"></a>\n",
    "### Create RF Sub Grids\n",
    "\n",
    "Based on the above output, the training accuracy is around 80% and is not overfitted as seen in the base model. We will now proceed with GridSearch using the parameters from random grid search. **We split the grid search into five sub grids to speed the grid search process.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFSubGrid1\"></a>\n",
    "#### Sub Grid 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [200, 202, 204, 206], 'randomforestclassifier__max_features': ['log2'], 'randomforestclassifier__max_depth': [27, 28], 'randomforestclassifier__min_samples_split': [81, 83, 85], 'randomforestclassifier__min_samples_leaf': [18, 20, 22], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__criterion': ['entropy'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [200, 202, 204, 206]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [27,28]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [81,83,85]\n",
    "\n",
    "min_samples_leaf = [18,20,22]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 14.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 28, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 22, 'randomforestclassifier__min_samples_split': 83, 'randomforestclassifier__n_estimators': 200} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFSubGrid2\"></a>\n",
    "#### Sub Grid 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [201, 203, 205, 207]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [25,26]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [80,82,84]\n",
    "\n",
    "min_samples_leaf = [24,25,26]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 14.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 25, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 25, 'randomforestclassifier__min_samples_split': 80, 'randomforestclassifier__n_estimators': 207} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFSubGrid3\"></a>\n",
    "#### Sub Grid 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [191, 192, 193, 194], 'randomforestclassifier__max_features': ['log2'], 'randomforestclassifier__max_depth': [29, 30], 'randomforestclassifier__min_samples_split': [76, 78, 86], 'randomforestclassifier__min_samples_leaf': [19, 21, 23], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__criterion': ['entropy'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [191, 192, 193, 194]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [29,30]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [76,78,86]\n",
    "\n",
    "min_samples_leaf = [19,21,23]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 14.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 29, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 19, 'randomforestclassifier__min_samples_split': 76, 'randomforestclassifier__n_estimators': 194} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFSubGrid4\"></a>\n",
    "#### Sub Grid 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [195, 196, 197, 198], 'randomforestclassifier__max_features': ['log2'], 'randomforestclassifier__max_depth': [31, 32], 'randomforestclassifier__min_samples_split': [77, 79, 87], 'randomforestclassifier__min_samples_leaf': [27, 28, 29], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__criterion': ['entropy'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [195, 196, 197, 198]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [31,32]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [77,79,87]\n",
    "\n",
    "min_samples_leaf = [27,28,29]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 32, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 27, 'randomforestclassifier__min_samples_split': 79, 'randomforestclassifier__n_estimators': 197} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFSubGrid5\"></a>\n",
    "#### Sub Grid 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [191, 199, 208, 209], 'randomforestclassifier__max_features': ['log2'], 'randomforestclassifier__max_depth': [33, 34], 'randomforestclassifier__min_samples_split': [88, 89, 90], 'randomforestclassifier__min_samples_leaf': [30, 31, 32], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__criterion': ['entropy'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [191,199,208,209]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [33,34]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [88,89,90]\n",
    "\n",
    "min_samples_leaf = [30,31,32]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 34, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 30, 'randomforestclassifier__min_samples_split': 88, 'randomforestclassifier__n_estimators': 191} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval4_RFFittingModels\"></a>\n",
    "### Fitting the RF Models\n",
    "\n",
    "Below the team has fitted each sub model to determine best paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFFittingModels_subgrid1\"></a>\n",
    "#### Fitting Sub Grid 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571489</td>\n",
       "      <td>0.691526</td>\n",
       "      <td>0.688301</td>\n",
       "      <td>0.717623</td>\n",
       "      <td>0.587227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.571489  0.691526       0.688301        0.717623     0.587227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.80734</td>\n",
       "      <td>0.879171</td>\n",
       "      <td>0.798636</td>\n",
       "      <td>0.860085</td>\n",
       "      <td>0.76085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0         0.80734   0.879171        0.798636         0.860085       0.76085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from first Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 191, min_samples_split = 88, min_samples_leaf = 30, \\\n",
    "                                                                         max_features = 'log2', max_depth = 34, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFFittingModels_subgrid2\"></a>\n",
    "#### Fitting Sub Grid 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577149</td>\n",
       "      <td>0.694355</td>\n",
       "      <td>0.690513</td>\n",
       "      <td>0.714612</td>\n",
       "      <td>0.593358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.577149  0.694355       0.690513        0.714612     0.593358"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809876</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.801027</td>\n",
       "      <td>0.861577</td>\n",
       "      <td>0.764184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.809876   0.881481        0.801027         0.861577      0.764184"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from second Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 197, min_samples_split = 79, min_samples_leaf = 27, \\\n",
    "                                                                         max_features = 'log2', max_depth = 32, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFFittingModels_subgrid3\"></a>\n",
    "#### Fitting Sub Grid 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577023</td>\n",
       "      <td>0.695651</td>\n",
       "      <td>0.694627</td>\n",
       "      <td>0.717628</td>\n",
       "      <td>0.584089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.577023  0.695651       0.694627        0.717628     0.584089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814803</td>\n",
       "      <td>0.887103</td>\n",
       "      <td>0.805969</td>\n",
       "      <td>0.865543</td>\n",
       "      <td>0.769817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.814803   0.887103        0.805969         0.865543      0.769817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from third Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 194, min_samples_split = 76, min_samples_leaf = 19, \\\n",
    "                                                                         max_features = 'log2', max_depth = 29, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFFittingModels_subgrid4\"></a>\n",
    "#### Fitting Sub Grid 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.578606</td>\n",
       "      <td>0.695207</td>\n",
       "      <td>0.691995</td>\n",
       "      <td>0.715741</td>\n",
       "      <td>0.58809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.578606  0.695207       0.691995        0.715741      0.58809"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810158</td>\n",
       "      <td>0.882294</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.861934</td>\n",
       "      <td>0.764393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.810158   0.882294        0.801361         0.861934      0.764393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from fourth Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 207, min_samples_split = 80, min_samples_leaf = 25, \\\n",
    "                                                                         max_features = 'log2', max_depth = 25, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_ModelEval4_RFFittingModels_subgrid5\"></a>\n",
    "#### Fitting Sub Grid 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.580179</td>\n",
       "      <td>0.696036</td>\n",
       "      <td>0.693322</td>\n",
       "      <td>0.71494</td>\n",
       "      <td>0.590794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.580179  0.696036       0.693322         0.71494     0.590794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811959</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.803089</td>\n",
       "      <td>0.863058</td>\n",
       "      <td>0.766726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.811959   0.883871        0.803089         0.863058      0.766726"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from fourth Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 200, min_samples_split = 83, min_samples_leaf = 22, \\\n",
    "                                                                         max_features = 'log2', max_depth = 28, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval4_EvalSummary\"></a>\n",
    "### Task 2 Model 2 : Random Forest Evaluation and Summary\n",
    "\n",
    "The model was fitted with best parameter from each grid search to compare accuracy and AuC. \n",
    "The parameter set that gives the highes accuracy is as below\n",
    "n_estimators = 194 \n",
    "min_samples_split = 76\n",
    "min_samples_leaf = 19\n",
    "max_features = 'log2'\n",
    "max_depth = 29\n",
    "class_weight = \"balanced\"\n",
    "criterion = 'entropy' \n",
    "bootstrap = False\n",
    "random_state=999, n_jobs=-1\n",
    "\n",
    "The metrics are \n",
    "\ttest_F1_Score\ttest_AUC\ttest_Accuracy\ttest_Precision\ttest_Recall\n",
    "0\t0.577023\t0.695651\t0.694627\t0.717628\t0.584089\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices are .......\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814803</td>\n",
       "      <td>0.887103</td>\n",
       "      <td>0.805969</td>\n",
       "      <td>0.865543</td>\n",
       "      <td>0.769817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.814803   0.887103        0.805969         0.865543      0.769817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577023</td>\n",
       "      <td>0.695651</td>\n",
       "      <td>0.694627</td>\n",
       "      <td>0.717628</td>\n",
       "      <td>0.584089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.577023  0.695651       0.694627        0.717628     0.584089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945183</td>\n",
       "      <td>0.626861</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829328</td>\n",
       "      <td>0.602569</td>\n",
       "      <td>0.720416</td>\n",
       "      <td>0.915077</td>\n",
       "      <td>0.758272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.522429</td>\n",
       "      <td>0.647725</td>\n",
       "      <td>0.533731</td>\n",
       "      <td>0.386135</td>\n",
       "      <td>0.807423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125224</td>\n",
       "      <td>0.599905</td>\n",
       "      <td>0.459190</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.068279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.127042</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>0.787215</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.069444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.623784</td>\n",
       "      <td>0.774406</td>\n",
       "      <td>0.692104</td>\n",
       "      <td>0.697281</td>\n",
       "      <td>0.564303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.529178</td>\n",
       "      <td>0.730565</td>\n",
       "      <td>0.659146</td>\n",
       "      <td>0.727731</td>\n",
       "      <td>0.415747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.797784</td>\n",
       "      <td>0.790612</td>\n",
       "      <td>0.709356</td>\n",
       "      <td>0.903451</td>\n",
       "      <td>0.714246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.896660</td>\n",
       "      <td>0.854213</td>\n",
       "      <td>0.839858</td>\n",
       "      <td>0.852374</td>\n",
       "      <td>0.945799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.373618</td>\n",
       "      <td>0.644494</td>\n",
       "      <td>0.649193</td>\n",
       "      <td>0.299178</td>\n",
       "      <td>0.497371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.945183  0.626861       0.896064        0.896064     1.000000\n",
       "1       0.829328  0.602569       0.720416        0.915077     0.758272\n",
       "2       0.522429  0.647725       0.533731        0.386135     0.807423\n",
       "3       0.125224  0.599905       0.459190        0.754310     0.068279\n",
       "4       0.127042  0.685161       0.787215        0.744681     0.069444\n",
       "5       0.623784  0.774406       0.692104        0.697281     0.564303\n",
       "6       0.529178  0.730565       0.659146        0.727731     0.415747\n",
       "7       0.797784  0.790612       0.709356        0.903451     0.714246\n",
       "8       0.896660  0.854213       0.839858        0.852374     0.945799\n",
       "9       0.373618  0.644494       0.649193        0.299178     0.497371"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model using Best parameter \n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 194, min_samples_split = 76, min_samples_leaf = 19, \\\n",
    "                                                                         max_features = 'log2', max_depth = 29, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores_bf_rf = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_bf_rf)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_bf_rf)[testCol].mean()).T)\n",
    "\n",
    "RFBestFitModelCVTestResults = pd.DataFrame(scores_bf_rf)[testCol].copy()\n",
    "RFBestFitModelCVTestResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval3_XGBoost\"></a>\n",
    "### Task 2 Model 3 : XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.917536</td>\n",
       "      <td>0.072844</td>\n",
       "      <td>0.945183</td>\n",
       "      <td>0.770477</td>\n",
       "      <td>0.605020</td>\n",
       "      <td>0.844781</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.763990</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.776360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.928337</td>\n",
       "      <td>0.071364</td>\n",
       "      <td>0.284699</td>\n",
       "      <td>0.775013</td>\n",
       "      <td>0.606372</td>\n",
       "      <td>0.850232</td>\n",
       "      <td>0.243088</td>\n",
       "      <td>0.771811</td>\n",
       "      <td>0.927793</td>\n",
       "      <td>0.792115</td>\n",
       "      <td>0.168148</td>\n",
       "      <td>0.758634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.938471</td>\n",
       "      <td>0.079324</td>\n",
       "      <td>0.512365</td>\n",
       "      <td>0.823392</td>\n",
       "      <td>0.633066</td>\n",
       "      <td>0.861851</td>\n",
       "      <td>0.489715</td>\n",
       "      <td>0.788326</td>\n",
       "      <td>0.366939</td>\n",
       "      <td>0.800973</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.847102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.037564</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>0.279616</td>\n",
       "      <td>0.812954</td>\n",
       "      <td>0.617099</td>\n",
       "      <td>0.870083</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.795601</td>\n",
       "      <td>0.674627</td>\n",
       "      <td>0.825372</td>\n",
       "      <td>0.176356</td>\n",
       "      <td>0.800904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.887819</td>\n",
       "      <td>0.074913</td>\n",
       "      <td>0.271976</td>\n",
       "      <td>0.815787</td>\n",
       "      <td>0.695842</td>\n",
       "      <td>0.849997</td>\n",
       "      <td>0.785667</td>\n",
       "      <td>0.776554</td>\n",
       "      <td>0.560372</td>\n",
       "      <td>0.797812</td>\n",
       "      <td>0.179563</td>\n",
       "      <td>0.834591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.922586</td>\n",
       "      <td>0.078524</td>\n",
       "      <td>0.677658</td>\n",
       "      <td>0.809885</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.859674</td>\n",
       "      <td>0.701615</td>\n",
       "      <td>0.786360</td>\n",
       "      <td>0.662617</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.693399</td>\n",
       "      <td>0.802079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.938117</td>\n",
       "      <td>0.132638</td>\n",
       "      <td>0.610099</td>\n",
       "      <td>0.816907</td>\n",
       "      <td>0.722520</td>\n",
       "      <td>0.862697</td>\n",
       "      <td>0.668657</td>\n",
       "      <td>0.789432</td>\n",
       "      <td>0.666288</td>\n",
       "      <td>0.804834</td>\n",
       "      <td>0.562650</td>\n",
       "      <td>0.829349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.011389</td>\n",
       "      <td>0.183354</td>\n",
       "      <td>0.822016</td>\n",
       "      <td>0.779925</td>\n",
       "      <td>0.771475</td>\n",
       "      <td>0.853483</td>\n",
       "      <td>0.736784</td>\n",
       "      <td>0.776063</td>\n",
       "      <td>0.898921</td>\n",
       "      <td>0.811234</td>\n",
       "      <td>0.757233</td>\n",
       "      <td>0.750942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.955481</td>\n",
       "      <td>0.086746</td>\n",
       "      <td>0.896013</td>\n",
       "      <td>0.785553</td>\n",
       "      <td>0.860954</td>\n",
       "      <td>0.846968</td>\n",
       "      <td>0.834992</td>\n",
       "      <td>0.768715</td>\n",
       "      <td>0.834155</td>\n",
       "      <td>0.780803</td>\n",
       "      <td>0.967781</td>\n",
       "      <td>0.790362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.569197</td>\n",
       "      <td>0.181650</td>\n",
       "      <td>0.383854</td>\n",
       "      <td>0.825341</td>\n",
       "      <td>0.654493</td>\n",
       "      <td>0.858418</td>\n",
       "      <td>0.642115</td>\n",
       "      <td>0.788474</td>\n",
       "      <td>0.300896</td>\n",
       "      <td>0.810199</td>\n",
       "      <td>0.529968</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  4.917536    0.072844       0.945183        0.770477  0.605020   0.844781   \n",
       "1  4.928337    0.071364       0.284699        0.775013  0.606372   0.850232   \n",
       "2  4.938471    0.079324       0.512365        0.823392  0.633066   0.861851   \n",
       "3  5.037564    0.080088       0.279616        0.812954  0.617099   0.870083   \n",
       "4  4.887819    0.074913       0.271976        0.815787  0.695842   0.849997   \n",
       "5  4.922586    0.078524       0.677658        0.809885  0.774233   0.859674   \n",
       "6  4.938117    0.132638       0.610099        0.816907  0.722520   0.862697   \n",
       "7  5.011389    0.183354       0.822016        0.779925  0.771475   0.853483   \n",
       "8  4.955481    0.086746       0.896013        0.785553  0.860954   0.846968   \n",
       "9  5.569197    0.181650       0.383854        0.825341  0.654493   0.858418   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.896064        0.763990        0.896064         0.776360   \n",
       "1       0.243088        0.771811        0.927793         0.792115   \n",
       "2       0.489715        0.788326        0.366939         0.800973   \n",
       "3       0.484848        0.795601        0.674627         0.825372   \n",
       "4       0.785667        0.776554        0.560372         0.797812   \n",
       "5       0.701615        0.786360        0.662617         0.817845   \n",
       "6       0.668657        0.789432        0.666288         0.804834   \n",
       "7       0.736784        0.776063        0.898921         0.811234   \n",
       "8       0.834992        0.768715        0.834155         0.780803   \n",
       "9       0.642115        0.788474        0.300896         0.810199   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     1.000000      0.764684  \n",
       "1     0.168148      0.758634  \n",
       "2     0.848739      0.847102  \n",
       "3     0.176356      0.800904  \n",
       "4     0.179563      0.834591  \n",
       "5     0.693399      0.802079  \n",
       "6     0.562650      0.829349  \n",
       "7     0.757233      0.750942  \n",
       "8     0.967781      0.790362  \n",
       "9     0.529968      0.841060  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801524</td>\n",
       "      <td>0.855818</td>\n",
       "      <td>0.780533</td>\n",
       "      <td>0.801755</td>\n",
       "      <td>0.801971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.801524   0.855818        0.780533         0.801755      0.801971"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568348</td>\n",
       "      <td>0.694107</td>\n",
       "      <td>0.648354</td>\n",
       "      <td>0.678867</td>\n",
       "      <td>0.588384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.568348  0.694107       0.648354        0.678867     0.588384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945183</td>\n",
       "      <td>0.605020</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.284699</td>\n",
       "      <td>0.606372</td>\n",
       "      <td>0.243088</td>\n",
       "      <td>0.927793</td>\n",
       "      <td>0.168148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.512365</td>\n",
       "      <td>0.633066</td>\n",
       "      <td>0.489715</td>\n",
       "      <td>0.366939</td>\n",
       "      <td>0.848739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279616</td>\n",
       "      <td>0.617099</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.674627</td>\n",
       "      <td>0.176356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.271976</td>\n",
       "      <td>0.695842</td>\n",
       "      <td>0.785667</td>\n",
       "      <td>0.560372</td>\n",
       "      <td>0.179563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.677658</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.701615</td>\n",
       "      <td>0.662617</td>\n",
       "      <td>0.693399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.610099</td>\n",
       "      <td>0.722520</td>\n",
       "      <td>0.668657</td>\n",
       "      <td>0.666288</td>\n",
       "      <td>0.562650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.822016</td>\n",
       "      <td>0.771475</td>\n",
       "      <td>0.736784</td>\n",
       "      <td>0.898921</td>\n",
       "      <td>0.757233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.896013</td>\n",
       "      <td>0.860954</td>\n",
       "      <td>0.834992</td>\n",
       "      <td>0.834155</td>\n",
       "      <td>0.967781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.383854</td>\n",
       "      <td>0.654493</td>\n",
       "      <td>0.642115</td>\n",
       "      <td>0.300896</td>\n",
       "      <td>0.529968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.945183  0.605020       0.896064        0.896064     1.000000\n",
       "1       0.284699  0.606372       0.243088        0.927793     0.168148\n",
       "2       0.512365  0.633066       0.489715        0.366939     0.848739\n",
       "3       0.279616  0.617099       0.484848        0.674627     0.176356\n",
       "4       0.271976  0.695842       0.785667        0.560372     0.179563\n",
       "5       0.677658  0.774233       0.701615        0.662617     0.693399\n",
       "6       0.610099  0.722520       0.668657        0.666288     0.562650\n",
       "7       0.822016  0.771475       0.736784        0.898921     0.757233\n",
       "8       0.896013  0.860954       0.834992        0.834155     0.967781\n",
       "9       0.383854  0.654493       0.642115        0.300896     0.529968"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Start XGBoost ####\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "#class xgboost.XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, \n",
    "#                            silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1,\n",
    "#                            nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1,\n",
    "#                            colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, \n",
    "#                            scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
    "\n",
    "xgb_baseModel = XGBClassifier(n_jobs=-1, random_state=999)\n",
    "scores_xgb = cross_validate(xgb_baseModel, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "display(pd.DataFrame(scores_xgb))\n",
    "\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_xgb)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_xgb)[testCol].mean()).T)\n",
    "\n",
    "XGBInitialModelCVTestResults = pd.DataFrame(scores_xgb)[testCol].copy()\n",
    "XGBInitialModelCVTestResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval3_XGBGid\"></a>\n",
    "### Tunig the Model Hyper Parameters\n",
    "\n",
    "#### Randomized GridSearch Level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [2, 3, 4, 5, 6, 7, 8], 'min_child_weight': [1, 2, 3, 4, 5, 6, 7, 8], 'n_estimators': [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470, 490, 510, 530, 550, 570, 590, 610, 630, 650, 670, 690, 710, 730, 750, 770, 790, 810, 830, 850, 870, 890, 910, 930, 950, 970, 990], 'learning_rate': [0.05, 0.1, 0.15000000000000002, 0.2, 0.25, 0.3, 0.35000000000000003, 0.4, 0.45, 0.5, 0.55, 0.6000000000000001, 0.6500000000000001, 0.7000000000000001, 0.7500000000000001, 0.8, 0.8500000000000001, 0.9000000000000001, 0.9500000000000001, 1.0, 1.05, 1.1, 1.1500000000000001, 1.2000000000000002, 1.2500000000000002, 1.3, 1.35, 1.4000000000000001, 1.4500000000000002, 1.5000000000000002, 1.55, 1.6, 1.6500000000000001, 1.7000000000000002, 1.7500000000000002, 1.8, 1.85, 1.9000000000000001, 1.9500000000000002, 2.0, 2.05, 2.1, 2.15, 2.1999999999999997, 2.25, 2.3, 2.35, 2.4, 2.45, 2.5, 2.55, 2.6, 2.65, 2.7, 2.75, 2.8, 2.85, 2.9, 2.95], 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6], 'subsample': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'reg_alpha': [0.0001, 1e-05, 5e-05, 2.5e-05], 'scale_pos_weight': [1.0, 1.05, 1.1, 1.1500000000000001, 1.2000000000000002, 1.2500000000000002, 1.3000000000000003, 1.3500000000000003, 1.4000000000000004, 1.4500000000000004, 1.5000000000000004, 1.5500000000000005, 1.6000000000000005, 1.6500000000000006, 1.7000000000000006, 1.7500000000000007, 1.8000000000000007, 1.8500000000000008, 1.9000000000000008, 1.9500000000000008, 2.000000000000001, 2.0500000000000007, 2.100000000000001, 2.1500000000000012, 2.200000000000001, 2.250000000000001, 2.300000000000001, 2.3500000000000014, 2.4000000000000012, 2.450000000000001, 2.5000000000000013, 2.5500000000000016, 2.6000000000000014, 2.6500000000000012, 2.7000000000000015, 2.7500000000000018, 2.8000000000000016, 2.8500000000000014, 2.9000000000000017, 2.950000000000002]}\n"
     ]
    }
   ],
   "source": [
    "#### Random Grid Search for XGBoost\n",
    "\n",
    "# Number of boosted trees to fit.\n",
    "n_estimators = [int(x) for x in np.arange(10, 1000, 20)]\n",
    "\n",
    "# Boosting learning rate (xgbs eta)\n",
    "learning_rate = [x for x in np.arange(0.05, 3, 0.05)]\n",
    "\n",
    "# Maximum tree depth for base learners.\n",
    "max_depth = [int(x) for x in np.arange(2, 9)]\n",
    "\n",
    "# Minimum sum of instance weight(hessian) needed in a child.\n",
    "min_child_weight = [int(x) for x in np.arange(1, 9)]\n",
    "\n",
    "gamma = [i/10.0 for i in range(0,7)]\n",
    "\n",
    "subsample  = [i/10.0 for i in range(3,11)]\n",
    "\n",
    "colsample_bytree = [i/10.0 for i in range(3,11)]\n",
    "\n",
    "reg_alpha = [0.0001, 0.00001, 0.00005, 0.000025]\n",
    "\n",
    "scale_pos_weight = [x for x in np.arange(1,3,0.05)]\n",
    "\n",
    "# Create the random grid for all params\n",
    "sub_grid_tree = {'max_depth': max_depth,\n",
    "                 'min_child_weight': min_child_weight,\n",
    "                 'n_estimators' : n_estimators,\n",
    "                'learning_rate': learning_rate, \n",
    "                'gamma': gamma, \n",
    "                'subsample': subsample,\n",
    "                 'colsample_bytree': colsample_bytree,\n",
    "                 'reg_alpha': reg_alpha,\n",
    "                 'scale_pos_weight': scale_pos_weight\n",
    "                }\n",
    "\n",
    "print(sub_grid_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 300 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 885 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1330 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1857 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2464 tasks      | elapsed: 39.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 47.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'subsample': 0.8, 'scale_pos_weight': 1.4500000000000004, 'reg_alpha': 1e-05, 'n_estimators': 10, 'min_child_weight': 8, 'max_depth': 4, 'learning_rate': 1.35, 'gamma': 0.5, 'colsample_bytree': 0.9} with a score of 0.70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgbEstimator = XGBClassifier(n_jobs=-1, random_state=999)\n",
    "\n",
    "# Perform Random Grid search using Stratified Shuffle Split CV Object.\n",
    "xgb_randomgrid = RandomizedSearchCV(estimator = xgbEstimator, param_distributions = sub_grid_tree, \n",
    "                                   n_iter = 300, \n",
    "                                   cv = kfold_cv_object,\n",
    "                                   verbose=2, \n",
    "                                   random_state=999, \n",
    "                                   n_jobs = -1,\n",
    "                                   scoring=scoring,\n",
    "                                   refit='Accuracy', \\\n",
    "                                   return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_randomgrid.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (xgb_randomgrid.best_params_, xgb_randomgrid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.485966</td>\n",
       "      <td>0.024948</td>\n",
       "      <td>0.945158</td>\n",
       "      <td>0.780826</td>\n",
       "      <td>0.594759</td>\n",
       "      <td>0.844149</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.756494</td>\n",
       "      <td>0.896414</td>\n",
       "      <td>0.731474</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>0.837319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.721622</td>\n",
       "      <td>0.126194</td>\n",
       "      <td>0.780847</td>\n",
       "      <td>0.785828</td>\n",
       "      <td>0.599608</td>\n",
       "      <td>0.850966</td>\n",
       "      <td>0.657819</td>\n",
       "      <td>0.765421</td>\n",
       "      <td>0.915919</td>\n",
       "      <td>0.745561</td>\n",
       "      <td>0.680494</td>\n",
       "      <td>0.830693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.761778</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>0.334671</td>\n",
       "      <td>0.827037</td>\n",
       "      <td>0.595428</td>\n",
       "      <td>0.866752</td>\n",
       "      <td>0.633267</td>\n",
       "      <td>0.788253</td>\n",
       "      <td>0.391917</td>\n",
       "      <td>0.788871</td>\n",
       "      <td>0.292017</td>\n",
       "      <td>0.869083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.403876</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>0.601229</td>\n",
       "      <td>0.816976</td>\n",
       "      <td>0.544984</td>\n",
       "      <td>0.868347</td>\n",
       "      <td>0.540810</td>\n",
       "      <td>0.788351</td>\n",
       "      <td>0.592130</td>\n",
       "      <td>0.784947</td>\n",
       "      <td>0.610613</td>\n",
       "      <td>0.851730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.405256</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>0.374866</td>\n",
       "      <td>0.820737</td>\n",
       "      <td>0.617724</td>\n",
       "      <td>0.850423</td>\n",
       "      <td>0.742535</td>\n",
       "      <td>0.771910</td>\n",
       "      <td>0.408665</td>\n",
       "      <td>0.768363</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.880773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.326016</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>0.705593</td>\n",
       "      <td>0.818800</td>\n",
       "      <td>0.747588</td>\n",
       "      <td>0.863592</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.783313</td>\n",
       "      <td>0.607193</td>\n",
       "      <td>0.778955</td>\n",
       "      <td>0.842054</td>\n",
       "      <td>0.862941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.639212</td>\n",
       "      <td>0.090369</td>\n",
       "      <td>0.622319</td>\n",
       "      <td>0.820481</td>\n",
       "      <td>0.688070</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>0.614466</td>\n",
       "      <td>0.784591</td>\n",
       "      <td>0.567141</td>\n",
       "      <td>0.777019</td>\n",
       "      <td>0.689390</td>\n",
       "      <td>0.869094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.284697</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>0.905496</td>\n",
       "      <td>0.791353</td>\n",
       "      <td>0.771973</td>\n",
       "      <td>0.851594</td>\n",
       "      <td>0.841407</td>\n",
       "      <td>0.764930</td>\n",
       "      <td>0.867863</td>\n",
       "      <td>0.745173</td>\n",
       "      <td>0.946542</td>\n",
       "      <td>0.843635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.176553</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>0.879945</td>\n",
       "      <td>0.796511</td>\n",
       "      <td>0.790533</td>\n",
       "      <td>0.851561</td>\n",
       "      <td>0.805353</td>\n",
       "      <td>0.767781</td>\n",
       "      <td>0.804440</td>\n",
       "      <td>0.750954</td>\n",
       "      <td>0.971093</td>\n",
       "      <td>0.847953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.398726</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>0.371612</td>\n",
       "      <td>0.823651</td>\n",
       "      <td>0.643434</td>\n",
       "      <td>0.856296</td>\n",
       "      <td>0.610263</td>\n",
       "      <td>0.777759</td>\n",
       "      <td>0.281166</td>\n",
       "      <td>0.779262</td>\n",
       "      <td>0.547844</td>\n",
       "      <td>0.873403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  1.485966    0.024948       0.945158        0.780826  0.594759   0.844149   \n",
       "1  1.721622    0.126194       0.780847        0.785828  0.599608   0.850966   \n",
       "2  1.761778    0.025301       0.334671        0.827037  0.595428   0.866752   \n",
       "3  1.403876    0.021240       0.601229        0.816976  0.544984   0.868347   \n",
       "4  1.405256    0.037173       0.374866        0.820737  0.617724   0.850423   \n",
       "5  1.326016    0.025349       0.705593        0.818800  0.747588   0.863592   \n",
       "6  1.639212    0.090369       0.622319        0.820481  0.688070   0.865333   \n",
       "7  1.284697    0.021294       0.905496        0.791353  0.771973   0.851594   \n",
       "8  1.176553    0.017729       0.879945        0.796511  0.790533   0.851561   \n",
       "9  1.398726    0.024436       0.371612        0.823651  0.643434   0.856296   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.896064        0.756494        0.896414         0.731474   \n",
       "1       0.657819        0.765421        0.915919         0.745561   \n",
       "2       0.633267        0.788253        0.391917         0.788871   \n",
       "3       0.540810        0.788351        0.592130         0.784947   \n",
       "4       0.742535        0.771910        0.408665         0.768363   \n",
       "5       0.682150        0.783313        0.607193         0.778955   \n",
       "6       0.614466        0.784591        0.567141         0.777019   \n",
       "7       0.841407        0.764930        0.867863         0.745173   \n",
       "8       0.805353        0.767781        0.804440         0.750954   \n",
       "9       0.610263        0.777759        0.281166         0.779262   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.999506      0.837319  \n",
       "1     0.680494      0.830693  \n",
       "2     0.292017      0.869083  \n",
       "3     0.610613      0.851730  \n",
       "4     0.346230      0.880773  \n",
       "5     0.842054      0.862941  \n",
       "6     0.689390      0.869094  \n",
       "7     0.946542      0.843635  \n",
       "8     0.971093      0.847953  \n",
       "9     0.547844      0.873403  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.65941</td>\n",
       "      <td>0.702413</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>0.692578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.652174   0.65941       0.702413        0.633285     0.692578"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_UpdatedModel = XGBClassifier(subsample = 0.8, scale_pos_weight = 1.45,  reg_alpha = 1e-05, \\\n",
    "                                 min_child_weight = 8,max_depth = 4, gamma = 0.5, colsample_bytree = 0.9, \\\n",
    "                                 learning_rate = 1.35, n_estimators = 10, n_jobs=-1, random_state=999)\n",
    "scores = cross_validate(xgb_UpdatedModel, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "display(pd.DataFrame(scores))\n",
    "print(\"\\n Mean values for Performance Metrices are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.65941</td>\n",
       "      <td>0.702413</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>0.692578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.652174   0.65941       0.702413        0.633285     0.692578"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_UpdatedModel = XGBClassifier(subsample = 0.8, scale_pos_weight = 1.45,  reg_alpha = 1e-05, \\\n",
    "                                 min_child_weight = 8,max_depth = 4, gamma = 0.5, colsample_bytree = 0.9, \\\n",
    "                                 learning_rate = 1.35, n_estimators = 10, n_jobs=-1, random_state=999)\n",
    "scores = cross_validate(xgb_UpdatedModel, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "display(pd.DataFrame(scores))\n",
    "print(\"\\n Mean values for Performance Metrices are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval3_XGBGidSearch2\"></a>\n",
    "#### Randomized GridSearch Level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_weight': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'reg_alpha': [2e-05, 5e-05, 1e-06, 9e-06]}\n"
     ]
    }
   ],
   "source": [
    "# Furthur tuning parameters that are returned on boundry of random grid search\n",
    "\n",
    "n_estimators = [int(x) for x in np.arange(5, 21, 1)]\n",
    "min_child_weight = [int(x) for x in np.arange(7, 21)]\n",
    "reg_alpha = [2e-05, 5e-05, 0.1e-05, 0.9e-05]\n",
    "\n",
    "# Create the sub grid for all above params\n",
    "sub_grid_tree = {\n",
    "                 'min_child_weight': min_child_weight,\n",
    "                 'n_estimators' : n_estimators,\n",
    "                 'reg_alpha': reg_alpha,\n",
    "                }\n",
    "\n",
    "print(sub_grid_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 150 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 885 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1330 tasks      | elapsed:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'reg_alpha': 1e-06, 'n_estimators': 9, 'min_child_weight': 8} with a score of 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:  6.9min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgbEstimator = XGBClassifier(subsample = 0.8, scale_pos_weight = 1.45, \\\n",
    "                                max_depth = 4, gamma = 0.5, colsample_bytree = 0.9, \\\n",
    "                                 learning_rate = 1.35, n_jobs=-1, random_state=999)\n",
    "\n",
    "# Perform Random Grid search using Stratified Shuffle Split CV Object.\n",
    "xgb_randomgrid = RandomizedSearchCV(estimator = xgbEstimator, param_distributions = sub_grid_tree, \n",
    "                                   n_iter = 150, \n",
    "                                   cv = kfold_cv_object,\n",
    "                                   verbose=2, \n",
    "                                   random_state=999, \n",
    "                                   n_jobs = -1,\n",
    "                                   scoring=scoring,\n",
    "                                   refit='Accuracy', \\\n",
    "                                   return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_randomgrid.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (xgb_randomgrid.best_params_, xgb_randomgrid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval3_XGBGidSearch3\"></a>\n",
    "#### Randomized GridSearch Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [3, 4, 5], 'min_child_weight': [7, 8, 9], 'n_estimators': [8, 9, 10, 11], 'learning_rate': [1.4, 1.42, 1.44, 1.46, 1.48, 1.5], 'gamma': [0.4, 0.5, 0.6], 'subsample': [0.8, 0.9], 'colsample_bytree': [0.8, 0.9], 'reg_alpha': [1e-06, 1e-07], 'scale_pos_weight': [1.45]}\n"
     ]
    }
   ],
   "source": [
    "#### Final Grid Search for XGBoost\n",
    "\n",
    "# Number of boosted trees to fit.\n",
    "n_estimators = [int(x) for x in np.arange(8, 12)]\n",
    "\n",
    "# Boosting learning rate (xgbs eta)\n",
    "learning_rate = [x for x in np.arange(1.40, 1.51, 0.02)]\n",
    "\n",
    "# Maximum tree depth for base learners.\n",
    "max_depth = [int(x) for x in np.arange(3, 6)]\n",
    "\n",
    "# Minimum sum of instance weight(hessian) needed in a child.\n",
    "min_child_weight = [int(x) for x in np.arange(7, 10)]\n",
    "\n",
    "gamma = [i/10.0 for i in range(4,7)]\n",
    "\n",
    "subsample  = [0.8, 0.9]\n",
    "\n",
    "colsample_bytree = [i/10.0 for i in range(8,10)]\n",
    "\n",
    "reg_alpha = [1e-06, 0.1e-06]\n",
    "\n",
    "scale_pos_weight = [1.45]\n",
    "\n",
    "# Create the grid for all params\n",
    "grid_tree = {'max_depth': max_depth,\n",
    "                 'min_child_weight': min_child_weight,\n",
    "                 'n_estimators' : n_estimators,\n",
    "                'learning_rate': learning_rate, \n",
    "                'gamma': gamma, \n",
    "                'subsample': subsample,\n",
    "                 'colsample_bytree': colsample_bytree,\n",
    "                 'reg_alpha': reg_alpha,\n",
    "                 'scale_pos_weight': scale_pos_weight\n",
    "                }\n",
    "\n",
    "print(grid_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5184 candidates, totalling 15552 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6797 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7890 tasks      | elapsed: 50.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9065 tasks      | elapsed: 58.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10320 tasks      | elapsed: 66.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11657 tasks      | elapsed: 75.0min\n",
      "[Parallel(n_jobs=-1)]: Done 13074 tasks      | elapsed: 84.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14573 tasks      | elapsed: 94.0min\n",
      "[Parallel(n_jobs=-1)]: Done 15552 out of 15552 | elapsed: 100.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'colsample_bytree': 0.9, 'gamma': 0.4, 'learning_rate': 1.46, 'max_depth': 3, 'min_child_weight': 7, 'n_estimators': 8, 'reg_alpha': 1e-06, 'scale_pos_weight': 1.45, 'subsample': 0.9} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "xgbGridEstimator = XGBClassifier(n_jobs=-1, random_state=999)\n",
    "\n",
    "xgbGridModel = GridSearchCV(estimator = xgbGridEstimator, \n",
    "                              param_grid = grid_tree,  \n",
    "                              cv = KFold(n_splits=3 , shuffle = False , random_state=999),\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "xgbGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (xgbGridModel.best_params_, xgbGridModel.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval3_EvalSummary\"></a>\n",
    "\n",
    "### Task 2 Model 3 - Summary\n",
    "\n",
    "Fitting the model with best params as found from XGBoost Grid search and subsequent grid searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.485966</td>\n",
       "      <td>0.024948</td>\n",
       "      <td>0.945158</td>\n",
       "      <td>0.780826</td>\n",
       "      <td>0.594759</td>\n",
       "      <td>0.844149</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.756494</td>\n",
       "      <td>0.896414</td>\n",
       "      <td>0.731474</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>0.837319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.721622</td>\n",
       "      <td>0.126194</td>\n",
       "      <td>0.780847</td>\n",
       "      <td>0.785828</td>\n",
       "      <td>0.599608</td>\n",
       "      <td>0.850966</td>\n",
       "      <td>0.657819</td>\n",
       "      <td>0.765421</td>\n",
       "      <td>0.915919</td>\n",
       "      <td>0.745561</td>\n",
       "      <td>0.680494</td>\n",
       "      <td>0.830693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.761778</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>0.334671</td>\n",
       "      <td>0.827037</td>\n",
       "      <td>0.595428</td>\n",
       "      <td>0.866752</td>\n",
       "      <td>0.633267</td>\n",
       "      <td>0.788253</td>\n",
       "      <td>0.391917</td>\n",
       "      <td>0.788871</td>\n",
       "      <td>0.292017</td>\n",
       "      <td>0.869083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.403876</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>0.601229</td>\n",
       "      <td>0.816976</td>\n",
       "      <td>0.544984</td>\n",
       "      <td>0.868347</td>\n",
       "      <td>0.540810</td>\n",
       "      <td>0.788351</td>\n",
       "      <td>0.592130</td>\n",
       "      <td>0.784947</td>\n",
       "      <td>0.610613</td>\n",
       "      <td>0.851730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.405256</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>0.374866</td>\n",
       "      <td>0.820737</td>\n",
       "      <td>0.617724</td>\n",
       "      <td>0.850423</td>\n",
       "      <td>0.742535</td>\n",
       "      <td>0.771910</td>\n",
       "      <td>0.408665</td>\n",
       "      <td>0.768363</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.880773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.326016</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>0.705593</td>\n",
       "      <td>0.818800</td>\n",
       "      <td>0.747588</td>\n",
       "      <td>0.863592</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.783313</td>\n",
       "      <td>0.607193</td>\n",
       "      <td>0.778955</td>\n",
       "      <td>0.842054</td>\n",
       "      <td>0.862941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.639212</td>\n",
       "      <td>0.090369</td>\n",
       "      <td>0.622319</td>\n",
       "      <td>0.820481</td>\n",
       "      <td>0.688070</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>0.614466</td>\n",
       "      <td>0.784591</td>\n",
       "      <td>0.567141</td>\n",
       "      <td>0.777019</td>\n",
       "      <td>0.689390</td>\n",
       "      <td>0.869094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.284697</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>0.905496</td>\n",
       "      <td>0.791353</td>\n",
       "      <td>0.771973</td>\n",
       "      <td>0.851594</td>\n",
       "      <td>0.841407</td>\n",
       "      <td>0.764930</td>\n",
       "      <td>0.867863</td>\n",
       "      <td>0.745173</td>\n",
       "      <td>0.946542</td>\n",
       "      <td>0.843635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.176553</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>0.879945</td>\n",
       "      <td>0.796511</td>\n",
       "      <td>0.790533</td>\n",
       "      <td>0.851561</td>\n",
       "      <td>0.805353</td>\n",
       "      <td>0.767781</td>\n",
       "      <td>0.804440</td>\n",
       "      <td>0.750954</td>\n",
       "      <td>0.971093</td>\n",
       "      <td>0.847953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.398726</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>0.371612</td>\n",
       "      <td>0.823651</td>\n",
       "      <td>0.643434</td>\n",
       "      <td>0.856296</td>\n",
       "      <td>0.610263</td>\n",
       "      <td>0.777759</td>\n",
       "      <td>0.281166</td>\n",
       "      <td>0.779262</td>\n",
       "      <td>0.547844</td>\n",
       "      <td>0.873403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  1.485966    0.024948       0.945158        0.780826  0.594759   0.844149   \n",
       "1  1.721622    0.126194       0.780847        0.785828  0.599608   0.850966   \n",
       "2  1.761778    0.025301       0.334671        0.827037  0.595428   0.866752   \n",
       "3  1.403876    0.021240       0.601229        0.816976  0.544984   0.868347   \n",
       "4  1.405256    0.037173       0.374866        0.820737  0.617724   0.850423   \n",
       "5  1.326016    0.025349       0.705593        0.818800  0.747588   0.863592   \n",
       "6  1.639212    0.090369       0.622319        0.820481  0.688070   0.865333   \n",
       "7  1.284697    0.021294       0.905496        0.791353  0.771973   0.851594   \n",
       "8  1.176553    0.017729       0.879945        0.796511  0.790533   0.851561   \n",
       "9  1.398726    0.024436       0.371612        0.823651  0.643434   0.856296   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.896064        0.756494        0.896414         0.731474   \n",
       "1       0.657819        0.765421        0.915919         0.745561   \n",
       "2       0.633267        0.788253        0.391917         0.788871   \n",
       "3       0.540810        0.788351        0.592130         0.784947   \n",
       "4       0.742535        0.771910        0.408665         0.768363   \n",
       "5       0.682150        0.783313        0.607193         0.778955   \n",
       "6       0.614466        0.784591        0.567141         0.777019   \n",
       "7       0.841407        0.764930        0.867863         0.745173   \n",
       "8       0.805353        0.767781        0.804440         0.750954   \n",
       "9       0.610263        0.777759        0.281166         0.779262   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.999506      0.837319  \n",
       "1     0.680494      0.830693  \n",
       "2     0.292017      0.869083  \n",
       "3     0.610613      0.851730  \n",
       "4     0.346230      0.880773  \n",
       "5     0.842054      0.862941  \n",
       "6     0.689390      0.869094  \n",
       "7     0.946542      0.843635  \n",
       "8     0.971093      0.847953  \n",
       "9     0.547844      0.873403  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.65941</td>\n",
       "      <td>0.702413</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>0.692578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.652174   0.65941       0.702413        0.633285     0.692578"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_UpdatedModel = XGBClassifier(subsample = 0.8, scale_pos_weight = 1.45,  reg_alpha = 1e-05, \\\n",
    "                                 min_child_weight = 8,max_depth = 4, gamma = 0.5, colsample_bytree = 0.9, \\\n",
    "                                 learning_rate = 1.35, n_estimators = 10, n_jobs=-1, random_state=999)\n",
    "scores = cross_validate(xgb_UpdatedModel, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "display(pd.DataFrame(scores))\n",
    "print(\"\\n Mean values for Performance Metrices are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993565</td>\n",
       "      <td>0.021221</td>\n",
       "      <td>0.945034</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.595259</td>\n",
       "      <td>0.842621</td>\n",
       "      <td>0.895843</td>\n",
       "      <td>0.759026</td>\n",
       "      <td>0.896391</td>\n",
       "      <td>0.737476</td>\n",
       "      <td>0.999260</td>\n",
       "      <td>0.830439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.132427</td>\n",
       "      <td>0.086495</td>\n",
       "      <td>0.790737</td>\n",
       "      <td>0.780779</td>\n",
       "      <td>0.603841</td>\n",
       "      <td>0.847466</td>\n",
       "      <td>0.670206</td>\n",
       "      <td>0.758835</td>\n",
       "      <td>0.916098</td>\n",
       "      <td>0.737871</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.828985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.105918</td>\n",
       "      <td>0.023778</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.823674</td>\n",
       "      <td>0.593389</td>\n",
       "      <td>0.863334</td>\n",
       "      <td>0.643884</td>\n",
       "      <td>0.784812</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.787910</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.862839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.993330</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>0.593112</td>\n",
       "      <td>0.816532</td>\n",
       "      <td>0.539755</td>\n",
       "      <td>0.867667</td>\n",
       "      <td>0.537492</td>\n",
       "      <td>0.788031</td>\n",
       "      <td>0.591615</td>\n",
       "      <td>0.785182</td>\n",
       "      <td>0.594616</td>\n",
       "      <td>0.850490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.114381</td>\n",
       "      <td>0.055844</td>\n",
       "      <td>0.372844</td>\n",
       "      <td>0.819540</td>\n",
       "      <td>0.615197</td>\n",
       "      <td>0.847928</td>\n",
       "      <td>0.750719</td>\n",
       "      <td>0.772942</td>\n",
       "      <td>0.424588</td>\n",
       "      <td>0.774848</td>\n",
       "      <td>0.332341</td>\n",
       "      <td>0.869704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.095343</td>\n",
       "      <td>0.025658</td>\n",
       "      <td>0.707811</td>\n",
       "      <td>0.818150</td>\n",
       "      <td>0.752005</td>\n",
       "      <td>0.862445</td>\n",
       "      <td>0.680602</td>\n",
       "      <td>0.783509</td>\n",
       "      <td>0.603728</td>\n",
       "      <td>0.781511</td>\n",
       "      <td>0.855257</td>\n",
       "      <td>0.858393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.112996</td>\n",
       "      <td>0.026809</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.819843</td>\n",
       "      <td>0.685084</td>\n",
       "      <td>0.862689</td>\n",
       "      <td>0.615129</td>\n",
       "      <td>0.784370</td>\n",
       "      <td>0.570258</td>\n",
       "      <td>0.778172</td>\n",
       "      <td>0.668267</td>\n",
       "      <td>0.866230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.089367</td>\n",
       "      <td>0.026092</td>\n",
       "      <td>0.907441</td>\n",
       "      <td>0.790381</td>\n",
       "      <td>0.774590</td>\n",
       "      <td>0.850906</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.764783</td>\n",
       "      <td>0.867740</td>\n",
       "      <td>0.746916</td>\n",
       "      <td>0.950951</td>\n",
       "      <td>0.839217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.209534</td>\n",
       "      <td>0.102373</td>\n",
       "      <td>0.880832</td>\n",
       "      <td>0.793609</td>\n",
       "      <td>0.802926</td>\n",
       "      <td>0.848317</td>\n",
       "      <td>0.807344</td>\n",
       "      <td>0.766675</td>\n",
       "      <td>0.807172</td>\n",
       "      <td>0.754537</td>\n",
       "      <td>0.969286</td>\n",
       "      <td>0.836948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.258883</td>\n",
       "      <td>0.148780</td>\n",
       "      <td>0.369938</td>\n",
       "      <td>0.822080</td>\n",
       "      <td>0.639579</td>\n",
       "      <td>0.855047</td>\n",
       "      <td>0.618005</td>\n",
       "      <td>0.776063</td>\n",
       "      <td>0.283240</td>\n",
       "      <td>0.778657</td>\n",
       "      <td>0.533123</td>\n",
       "      <td>0.870632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  0.993565    0.021221       0.945034        0.781202  0.595259   0.842621   \n",
       "1  1.132427    0.086495       0.790737        0.780779  0.603841   0.847466   \n",
       "2  1.105918    0.023778       0.281250        0.823674  0.593389   0.863334   \n",
       "3  0.993330    0.024966       0.593112        0.816532  0.539755   0.867667   \n",
       "4  1.114381    0.055844       0.372844        0.819540  0.615197   0.847928   \n",
       "5  1.095343    0.025658       0.707811        0.818150  0.752005   0.862445   \n",
       "6  1.112996    0.026809       0.615385        0.819843  0.685084   0.862689   \n",
       "7  1.089367    0.026092       0.907441        0.790381  0.774590   0.850906   \n",
       "8  1.209534    0.102373       0.880832        0.793609  0.802926   0.848317   \n",
       "9  1.258883    0.148780       0.369938        0.822080  0.639579   0.855047   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.895843        0.759026        0.896391         0.737476   \n",
       "1       0.670206        0.758835        0.916098         0.737871   \n",
       "2       0.643884        0.784812        0.387931         0.787910   \n",
       "3       0.537492        0.788031        0.591615         0.785182   \n",
       "4       0.750719        0.772942        0.424588         0.774848   \n",
       "5       0.680602        0.783509        0.603728         0.781511   \n",
       "6       0.615129        0.784370        0.570258         0.778172   \n",
       "7       0.844282        0.764783        0.867740         0.746916   \n",
       "8       0.807344        0.766675        0.807172         0.754537   \n",
       "9       0.618005        0.776063        0.283240         0.778657   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.999260      0.830439  \n",
       "1     0.695556      0.828985  \n",
       "2     0.220588      0.862839  \n",
       "3     0.594616      0.850490  \n",
       "4     0.332341      0.869704  \n",
       "5     0.855257      0.858393  \n",
       "6     0.668267      0.866230  \n",
       "7     0.950951      0.839217  \n",
       "8     0.969286      0.836948  \n",
       "9     0.533123      0.870632  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices are .......\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806579</td>\n",
       "      <td>0.854842</td>\n",
       "      <td>0.773905</td>\n",
       "      <td>0.766308</td>\n",
       "      <td>0.851388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.806579   0.854842        0.773905         0.766308      0.851388"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646438</td>\n",
       "      <td>0.660162</td>\n",
       "      <td>0.70635</td>\n",
       "      <td>0.634876</td>\n",
       "      <td>0.681924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.646438  0.660162        0.70635        0.634876     0.681924"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945034</td>\n",
       "      <td>0.595259</td>\n",
       "      <td>0.895843</td>\n",
       "      <td>0.896391</td>\n",
       "      <td>0.999260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.790737</td>\n",
       "      <td>0.603841</td>\n",
       "      <td>0.670206</td>\n",
       "      <td>0.916098</td>\n",
       "      <td>0.695556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.593389</td>\n",
       "      <td>0.643884</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.220588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.593112</td>\n",
       "      <td>0.539755</td>\n",
       "      <td>0.537492</td>\n",
       "      <td>0.591615</td>\n",
       "      <td>0.594616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.372844</td>\n",
       "      <td>0.615197</td>\n",
       "      <td>0.750719</td>\n",
       "      <td>0.424588</td>\n",
       "      <td>0.332341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.707811</td>\n",
       "      <td>0.752005</td>\n",
       "      <td>0.680602</td>\n",
       "      <td>0.603728</td>\n",
       "      <td>0.855257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.685084</td>\n",
       "      <td>0.615129</td>\n",
       "      <td>0.570258</td>\n",
       "      <td>0.668267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.907441</td>\n",
       "      <td>0.774590</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.867740</td>\n",
       "      <td>0.950951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.880832</td>\n",
       "      <td>0.802926</td>\n",
       "      <td>0.807344</td>\n",
       "      <td>0.807172</td>\n",
       "      <td>0.969286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.369938</td>\n",
       "      <td>0.639579</td>\n",
       "      <td>0.618005</td>\n",
       "      <td>0.283240</td>\n",
       "      <td>0.533123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.945034  0.595259       0.895843        0.896391     0.999260\n",
       "1       0.790737  0.603841       0.670206        0.916098     0.695556\n",
       "2       0.281250  0.593389       0.643884        0.387931     0.220588\n",
       "3       0.593112  0.539755       0.537492        0.591615     0.594616\n",
       "4       0.372844  0.615197       0.750719        0.424588     0.332341\n",
       "5       0.707811  0.752005       0.680602        0.603728     0.855257\n",
       "6       0.615385  0.685084       0.615129        0.570258     0.668267\n",
       "7       0.907441  0.774590       0.844282        0.867740     0.950951\n",
       "8       0.880832  0.802926       0.807344        0.807172     0.969286\n",
       "9       0.369938  0.639579       0.618005        0.283240     0.533123"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgb_UpdatedModel = XGBClassifier(subsample = 0.8, scale_pos_weight = 1.45,  reg_alpha = 1e-05, \\\n",
    "#                                 min_child_weight = 8,max_depth = 4, gamma = 0.5, colsample_bytree = 0.9, \\\n",
    "#                                 learning_rate = 1.35, n_estimators = 10, n_jobs=-1, random_state=999)\n",
    "\n",
    "xgb_UpdatedModel = XGBClassifier(subsample = 0.8, scale_pos_weight = 1.45, \\\n",
    "                                max_depth = 4, gamma = 0.5, colsample_bytree = 0.9, \\\n",
    "                                 learning_rate = 1.35, n_jobs=-1, random_state=999, \\\n",
    "                            reg_alpha= 1e-06, n_estimators= 9, min_child_weight= 8 )\n",
    "\n",
    "scores_bf_xgb = cross_validate(xgb_UpdatedModel, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "display(pd.DataFrame(scores_bf_xgb))\n",
    "print(\"\\n Mean values for Performance Metrices are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_bf_xgb)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores_bf_xgb)[testCol].mean()).T)\n",
    "\n",
    "XGBBestFitModelCVTestResults = pd.DataFrame(scores_bf_xgb)[testCol].copy()\n",
    "XGBBestFitModelCVTestResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval4\"></a>\n",
    "### Model and Evaluation 4\n",
    "\n",
    "#### Task 2 Model 1 : Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.547597</td>\n",
       "      <td>0.688262</td>\n",
       "      <td>0.696109</td>\n",
       "      <td>0.712815</td>\n",
       "      <td>0.55154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.547597  0.688262       0.696109        0.712815      0.55154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.632667</td>\n",
       "      <td>0.678537</td>\n",
       "      <td>0.689982</td>\n",
       "      <td>0.66875</td>\n",
       "      <td>0.649996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.632667  0.678537       0.689982         0.66875     0.649996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35         # the width of the bars\n",
    "p1 = ax.bar(ind, p2lrBestFitModelCVTestResults.mean(), width, color='r', bottom=0)\n",
    "\n",
    "\n",
    "p2 = ax.bar(ind + width, p2lrInitialModelCVTestResults.mean(), width, color='y', bottom=0)\n",
    "\n",
    "ax.set_title('Comparison of Mean final and initial CV test Scores for SVM model ')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('F1 Score', 'AuC', 'Accuracy', 'Precision', 'Recall'))\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('Final', 'Initial'))\n",
    "ax.autoscale_view()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(pd.DataFrame(p2lrBestFitModelCVTestResults.mean()).T)\n",
    "display(pd.DataFrame(p2lrInitialModelCVTestResults.mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 Model 2 : Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577023</td>\n",
       "      <td>0.695651</td>\n",
       "      <td>0.694627</td>\n",
       "      <td>0.717628</td>\n",
       "      <td>0.584089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.577023  0.695651       0.694627        0.717628     0.584089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.562516</td>\n",
       "      <td>0.658066</td>\n",
       "      <td>0.650966</td>\n",
       "      <td>0.66192</td>\n",
       "      <td>0.525598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.562516  0.658066       0.650966         0.66192     0.525598"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35         # the width of the bars\n",
    "p1 = ax.bar(ind, RFBestFitModelCVTestResults.mean(), width, color='r', bottom=0)\n",
    "\n",
    "\n",
    "p2 = ax.bar(ind + width, RFInitialModelCVTestResults.mean(), width, color='y', bottom=0)\n",
    "\n",
    "ax.set_title('Comparison of Mean final and initial CV test Scores for SVM model ')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('F1 Score', 'AuC', 'Accuracy', 'Precision', 'Recall'))\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('Final', 'Initial'))\n",
    "ax.autoscale_view()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(pd.DataFrame(RFBestFitModelCVTestResults.mean()).T)\n",
    "display(pd.DataFrame(RFInitialModelCVTestResults.mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 Model 3 : XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646438</td>\n",
       "      <td>0.660162</td>\n",
       "      <td>0.70635</td>\n",
       "      <td>0.634876</td>\n",
       "      <td>0.681924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.646438  0.660162        0.70635        0.634876     0.681924"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568348</td>\n",
       "      <td>0.694107</td>\n",
       "      <td>0.648354</td>\n",
       "      <td>0.678867</td>\n",
       "      <td>0.588384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.568348  0.694107       0.648354        0.678867     0.588384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35         # the width of the bars\n",
    "p1 = ax.bar(ind, XGBBestFitModelCVTestResults.mean(), width, color='r', bottom=0)\n",
    "\n",
    "\n",
    "p2 = ax.bar(ind + width, XGBInitialModelCVTestResults.mean(), width, color='y', bottom=0)\n",
    "\n",
    "ax.set_title('Comparison of Mean final and initial CV test Scores for SVM model ')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('F1 Score', 'AuC', 'Accuracy', 'Precision', 'Recall'))\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('Final', 'Initial'))\n",
    "ax.autoscale_view()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(pd.DataFrame(XGBBestFitModelCVTestResults.mean()).T)\n",
    "display(pd.DataFrame(XGBInitialModelCVTestResults.mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 : Model and Evaluation 4 - Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_ModelEval5\"></a>\n",
    "### Task 2 : Model and Evaluation 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Logistic Regression and Random Forest Best Models\n",
      "==========================================================\n",
      "Range of: -0.02557748658263166 0.02261352098731311\n",
      "0.6961093647112042 0.694627381913545\n",
      "-0.04395573948769182\n",
      "\n",
      "Compare Logistic Regression and XGBoost Best Models\n",
      "==========================================================\n",
      "Range of: -0.03302202168469786 0.05350420610668021\n",
      "0.6961093647112042 0.7063504569221954\n",
      "0.16917529435198034\n",
      "\n",
      "Compare Random Forest and XGBoost Best Models\n",
      "==========================================================\n",
      "Range of: -0.03516750981008533 0.05861365982738623\n",
      "0.694627381913545 0.7063504569221954\n",
      "0.17867522334112074\n"
     ]
    }
   ],
   "source": [
    "t = 2.26 / np.sqrt(10)\n",
    "\n",
    "## Compare Logistic Regression and Random Forest Best Models\n",
    "acc1 = p2lrBestFitModelCVTestResults['test_Accuracy']\n",
    "acc2 = RFBestFitModelCVTestResults['test_Accuracy']\n",
    "\n",
    "e = (1-acc1)-(1-acc2)\n",
    "stdtot = np.std(e)\n",
    "\n",
    "dbar = np.mean(e)\n",
    "print(\"Compare Logistic Regression and Random Forest Best Models\")\n",
    "print(\"==========================================================\")\n",
    "print ('Range of:', dbar-t*stdtot,dbar+t*stdtot )\n",
    "print (np.mean(acc1), np.mean(acc2))\n",
    "print (dbar/stdtot)\n",
    "print()\n",
    "\n",
    "## Compare Logistic Regression and XGBoost Best Models\n",
    "acc1 = p2lrBestFitModelCVTestResults['test_Accuracy']\n",
    "acc2 = XGBBestFitModelCVTestResults['test_Accuracy']\n",
    "\n",
    "e = (1-acc1)-(1-acc2)\n",
    "stdtot = np.std(e)\n",
    "\n",
    "dbar = np.mean(e)\n",
    "print(\"Compare Logistic Regression and XGBoost Best Models\")\n",
    "print(\"==========================================================\")\n",
    "print ('Range of:', dbar-t*stdtot,dbar+t*stdtot )\n",
    "print (np.mean(acc1), np.mean(acc2))\n",
    "print (dbar/stdtot)\n",
    "print()\n",
    "\n",
    "## Compare Random Forest and XGBoost Best Models\n",
    "acc1 = RFBestFitModelCVTestResults['test_Accuracy']\n",
    "acc2 = XGBBestFitModelCVTestResults['test_Accuracy']\n",
    "\n",
    "e = (1-acc1)-(1-acc2)\n",
    "stdtot = np.std(e)\n",
    "\n",
    "dbar = np.mean(e)\n",
    "print(\"Compare Random Forest and XGBoost Best Models\")\n",
    "print(\"==========================================================\")\n",
    "print ('Range of:', dbar-t*stdtot,dbar+t*stdtot )\n",
    "print (np.mean(acc1), np.mean(acc2))\n",
    "print (dbar/stdtot)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance on the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestclassifier', RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
       "            criterion='entropy', max_depth=29, max_features='log2',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=...mators=194, n_jobs=-1, oob_score=False, random_state=999,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model using Best parameter \n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 194, min_samples_split = 76, min_samples_leaf = 19, \\\n",
    "                                                                         max_features = 'log2', max_depth = 29, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "rfRandomGridEst.fit(X,y=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5f6c42e7f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#do code to support model\n",
    "#\"data\" is the X dataframe and model is the SKlearn object\n",
    "\n",
    "\n",
    "classifier_model = rfRandomGridEst.named_steps['randomforestclassifier']\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(bankPromoModel_hsng_Df.columns, classifier_model.feature_importances_):\n",
    "   feats[feature] = importance #add the name/value pair\n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'entropy-importance'})\n",
    "importances.sort_values(by='entropy-importance').plot(kind='bar', rot=45, figsize = (20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_Deployment\"></a>\n",
    "### Deployment of Models for Task 1 and Task 2\n",
    "\n",
    "The models that we have derived, for both home loans and subscription to term deposits,  are of interest to the bank.  Banks, similar to other businesses, have a business case to increase customer base (or increase what current customers use the bank for) without increasing (or decrease) their customer acquisition cost.  We have focused on building predictive models for existing bank customers and would not affect the acquisiton cost for new customers.\n",
    "\n",
    "In order to benefit the bank's sales, the banks could use these models to increase probability of the customers they phone that ultimately will subscribe to a term deposit or invest in a home.  This reduces the number of phone calls, reduces the hours that are paid to the bankers to make those phone calls and increases the probaility of the banks earning interest on the term deposits or home loans.\n",
    "\n",
    "We would encourage the bankers to continue to enter the data in order to refine the model at a later date.  Market changes could effect the models' accuracy and continuing to collect data will make it simplier to refine for the next campaign.  Since the models do not need to be used for each phone call, the use of the model can be deployed to a few people in the bank and then the list of more likely candidates be distributed to the bankers that will be contacting the existing customers.  The use of the models could also be added to the process during signing up new customers.  The bank could run the model on the attributes of the new customer and then make offers on the spot if the model shows the determined level of probability. \n",
    "\n",
    "The attribute that we believe would refine the models even further and increase the models' performance is income.  Income is important to home loans as it shows purchasing power on average homes in the neighborhood.  Income is important to term deposits as it is an indicator on disposable income of the customers to save more. \n",
    "\n",
    "The model could be refined in any time intervals, but at a minimum the model should be updated significant change in the market or national interst rate adjustments.\n",
    "\n",
    "Note:  We have no evidence that these models can be extrapolated to other banks in Portugal or other countries.  (Despite us not knowing the randomness of the sample or the calls, we are going to assume that they were random in this case and we can use the model to predict the subscribe or housing outcomes to the entire bank population).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
