{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id=\"top\"></a>\n",
    "## Task 2 - Housing Loan\n",
    "\n",
    "\n",
    "## Contents\n",
    "* <a href=\"#tsk2_bu_understanding\">Business Understanding</a>\n",
    "\n",
    "* <a href=\"#tsk2_dataprepI\">Data Prep Part I for Task 2</a>\n",
    "    * <a href=\"#tsk2_dataprepmodules\">Import Modules</a>\n",
    "    * <a href=\"#tsk2_dataprepviewdata\">View Data</a>\n",
    "    * <a href=\"#tsk2_dataprepnulls\">Validate Nulls</a>\n",
    "    * <a href=\"#tsk2_dataprepdups\">Validate Duplicate Entries</a>\n",
    "    * <a href=\"#tsk2_datapreptarget\">Set Target Variable</a>\n",
    "* <a href=\"#TrainingSet\">Training Date Set-Up</a>\n",
    "    * <a href=\"#TrainingSet_CategVarSetUp\">Convert Categorical Variables</a>\n",
    "    * <a href=\"#TrainingSetClassPredVar\">Seperate Class and Predictor Variables</a>\n",
    "    * <a href=\"#TrainingSetFeatElim\">Feature Elimination</a>\n",
    "* <a href=\"#ModelLR\">Model Build</a>\n",
    "    * <a href=\"#ModelLRBuild\">Logistic Regression (LR) Building</a>\n",
    "    * <a href=\"#ModelLRFeatureAnalysis\">LR Feature Analysis</a>\n",
    "* <a href=\"#ModelLDA\">Gather Numeric Variables for LDA</a>\n",
    "* <a href=\"#FeatureSelection\">Feaature Selection</a>\n",
    "    * <a href=\"#FeatureSelectionChiSq\">Chi-Sq Test</a>\n",
    "    * <a href=\"#FeatureSelectionPearosn\">Pearson Correlation</a>\n",
    "    * <a href=\"#FeatureSelectionChiSqII\">Chi-Sq Test Feature Selection</a>\n",
    "* <a href=\"#LRFitting\">LR Fit Estimator</a>\n",
    "* <a href=\"#LRFittingSelection\">LR Feature Selection</a>\n",
    "* <a href=\"#RFFeatSelection\">Random Forest (RF) Feature Selection</a>\n",
    "* <a href=\"#LGBMFeatSelection\">Light GBM Feature Selection</a>\n",
    "* <a href=\"#FeatSelectionSummary\">Feature Selection Summary</a>\n",
    "* <a href=\"#SummaryObjDataPrep1\">Objective Summary</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id=\"tsk2_bu_understanding\"></a>\n",
    "### Business Understanding (2nd Variable)\n",
    "\n",
    "The team decided that the variable housing would be of interest to the banks as this could be an avenue for additional revenue for the industry.  Individuals and families that own homes could be swayed into refinancing homes for a lower interest rate or need other loans to pay for home improvements.  These transactions, though benefiting the home owner in the short term, in the long run banks do benefit additionally with fees and service transactions that must be paid.\n",
    "\n",
    "The housing variable is a binary response that is balanced in our sampled data set (the population of the bank clients that have a home loan are unknown).  The variable represents if the client has or does not have a home loan.\n",
    "\n",
    "From the figure 1 we can see several trends happening during the time of the data set (ref: https://tradingeconomics.com/portugal):\n",
    "- Household savings increasing\n",
    "- Bank lending decreasing\n",
    "- Average wage increasing\n",
    "- Consumer spending decreasing\n",
    "\n",
    "_Figure 1:_\n",
    "\n",
    "![alt text](https://github.com/nhendersonkuns/awesomedataminers/raw/master/ReferenceMaterial/HousingReasons.PNG \"Key Indicators\")\n",
    "\n",
    "During the time of the marketing campaign, a global recession occurred (figure 2).  We inferred that to prepare for the possiblity of upcoming hardships, many individuals/families would have attemped to save more of their disposable income.  The above charts yields us to that inference.  The banks could use this data to direct resources in an attempt to help these home owners refinance and save additional disposable income.  This helps out the customers in the short term and helps out the bank in the long term now that they have gained customers and revenue from interest payments. \n",
    "\n",
    "_Figure 2:_\n",
    "![alt text](https://github.com/nhendersonkuns/awesomedataminers/raw/master/ReferenceMaterial/StockMarketCompare.PNG \"US vs Portugal Stock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_dataprepI\"></a>\n",
    "### Data Preparation Part 1 for Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_dataprepmodules\"></a>\n",
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime \n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# To display plots inside the iPython Notebook itself\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_dataprepviewdata\"></a>\n",
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n",
      "\n",
      "58;\"management\";\"married\";\"tertiary\";\"no\";2143;\"yes\";\"no\";\"unknown\";5;\"may\";261;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "44;\"technician\";\"single\";\"secondary\";\"no\";29;\"yes\";\"no\";\"unknown\";5;\"may\";151;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "33;\"entrepreneur\";\"married\";\"secondary\";\"no\";2;\"yes\";\"yes\";\"unknown\";5;\"may\";76;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "47;\"blue-collar\";\"married\";\"unknown\";\"no\";1506;\"yes\";\"no\";\"unknown\";5;\"may\";92;1;-1;0;\"unknown\";\"no\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>Subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>231</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>447</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "5   35    management  married   tertiary      no      231     yes   no   \n",
       "6   28    management   single   tertiary      no      447     yes  yes   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome Subscribed  \n",
       "0  unknown    5   may       261         1     -1         0  unknown         no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown         no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown         no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown         no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown         no  \n",
       "5  unknown    5   may       139         1     -1         0  unknown         no  \n",
       "6  unknown    5   may       217         1     -1         0  unknown         no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To verify how data is orgainzed in file(to find the delimiter) and then\n",
    "# use corresponding function to open the file. eg\n",
    "# data could be in .csv. .tsv, excel format etc.\n",
    "pathOfDataFile = \"data/bank-full.csv\"\n",
    "firstFewLines = list()\n",
    "noOfLinesToView = 5\n",
    "\n",
    "with open(pathOfDataFile) as dataFile:\n",
    "    firstFewLines = [next(dataFile) for i in range(noOfLinesToView)]\n",
    "    for line in firstFewLines:\n",
    "        print(line)\n",
    "\n",
    "# Import the semi-colon delimited data file into pandas dataFrame\n",
    "bankPromo_df = pd.read_csv(pathOfDataFile, sep = \";\")\n",
    "\n",
    "# Rename the Target/Final Outcome column from \"y\" to \"Subscribed\" as based on data description.\n",
    "bankPromo_df = bankPromo_df.rename(columns={\"y\":\"Subscribed\"})\n",
    "\n",
    "bankPromo_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_dataprepnulls\"></a>\n",
    "### Validate Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bankPromoModel_hsng_Df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3960d67554eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Check for null values in data Frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbankPromoModel_hsng_Df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bankPromoModel_hsng_Df' is not defined"
     ]
    }
   ],
   "source": [
    "#Check for null values in data Frame\n",
    "bankPromoModel_hsng_Df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_As all the missing/unknown values in the dataset have been accounted already. Our dataset contains no missing values_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tsk2_dataprepdups\"></a>\n",
    "### Identify duplicate entires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find duplicated rows in data Frame\n",
    "bankPromoModel_hsng_Df.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_There are no duplicate values for any observations/rows in our data set._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"tsk2_datapreptarget\"></a>\n",
    "### Set Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get list of categorical variables , keeping 'housing' as target/response variable for Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      "age           45211 non-null int64\n",
      "job           45211 non-null object\n",
      "marital       45211 non-null object\n",
      "education     45211 non-null object\n",
      "default       45211 non-null object\n",
      "balance       45211 non-null int64\n",
      "loan          45211 non-null object\n",
      "contact       45211 non-null object\n",
      "day           45211 non-null int64\n",
      "month         45211 non-null object\n",
      "duration      45211 non-null int64\n",
      "campaign      45211 non-null int64\n",
      "pdays         45211 non-null int64\n",
      "previous      45211 non-null int64\n",
      "poutcome      45211 non-null object\n",
      "Subscribed    45211 non-null object\n",
      "Target        45211 non-null int32\n",
      "dtypes: int32(1), int64(7), object(9)\n",
      "memory usage: 5.7+ MB\n",
      "['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
      "['job', 'marital', 'education', 'default', 'loan', 'contact', 'month', 'poutcome', 'Subscribed']\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of original data frame\n",
    "bankPromoModel_hsng_Df = bankPromo_df.copy()\n",
    "bankPromoModel_hsng_Df['Target'] = bankPromoModel_hsng_Df['housing'].apply(lambda resp : 1 if resp == \"yes\" else 0)\n",
    "bankPromoModel_hsng_Df['Target'] = bankPromoModel_hsng_Df['Target'].astype(np.int)\n",
    "\n",
    "# Delete the original 'housing' column\n",
    "del bankPromoModel_hsng_Df['housing']\n",
    "\n",
    "# List final variables of the new dataset\n",
    "bankPromoModel_hsng_Df.info()\n",
    "\n",
    "# Get the unique values(Levels) for categorical variables.\n",
    "# List to hold names of categorical variables\n",
    "categoricalVars = list()\n",
    "# List to hold names of numerical variables\n",
    "numericalVars = list()\n",
    "\n",
    "for colName in bankPromoModel_hsng_Df.columns:\n",
    "    if bankPromoModel_hsng_Df[colName].dtype == np.int64:\n",
    "        numericalVars.append(colName)\n",
    "    elif bankPromoModel_hsng_Df[colName].dtype == np.object:\n",
    "        categoricalVars.append(colName)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# Remove Target column from final categorical Var list\n",
    "#categoricalVars.remove('housing')\n",
    "\n",
    "print(numericalVars)\n",
    "print(categoricalVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"TrainingSet\"></a>\n",
    "       \n",
    "### Training Data Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"TrainingSet_CategVarSetUp\"></a>\n",
    "       \n",
    "### Convert Categorical to Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset info\n",
      "=====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 43 columns):\n",
      "age                    45211 non-null int64\n",
      "balance                45211 non-null int64\n",
      "day                    45211 non-null int64\n",
      "duration               45211 non-null int64\n",
      "campaign               45211 non-null int64\n",
      "pdays                  45211 non-null int64\n",
      "previous               45211 non-null int64\n",
      "Target                 45211 non-null int32\n",
      "job_blue-collar        45211 non-null uint8\n",
      "job_entrepreneur       45211 non-null uint8\n",
      "job_housemaid          45211 non-null uint8\n",
      "job_management         45211 non-null uint8\n",
      "job_retired            45211 non-null uint8\n",
      "job_self-employed      45211 non-null uint8\n",
      "job_services           45211 non-null uint8\n",
      "job_student            45211 non-null uint8\n",
      "job_technician         45211 non-null uint8\n",
      "job_unemployed         45211 non-null uint8\n",
      "job_unknown            45211 non-null uint8\n",
      "marital_married        45211 non-null uint8\n",
      "marital_single         45211 non-null uint8\n",
      "education_secondary    45211 non-null uint8\n",
      "education_tertiary     45211 non-null uint8\n",
      "education_unknown      45211 non-null uint8\n",
      "default_yes            45211 non-null uint8\n",
      "loan_yes               45211 non-null uint8\n",
      "contact_telephone      45211 non-null uint8\n",
      "contact_unknown        45211 non-null uint8\n",
      "month_aug              45211 non-null uint8\n",
      "month_dec              45211 non-null uint8\n",
      "month_feb              45211 non-null uint8\n",
      "month_jan              45211 non-null uint8\n",
      "month_jul              45211 non-null uint8\n",
      "month_jun              45211 non-null uint8\n",
      "month_mar              45211 non-null uint8\n",
      "month_may              45211 non-null uint8\n",
      "month_nov              45211 non-null uint8\n",
      "month_oct              45211 non-null uint8\n",
      "month_sep              45211 non-null uint8\n",
      "poutcome_other         45211 non-null uint8\n",
      "poutcome_success       45211 non-null uint8\n",
      "poutcome_unknown       45211 non-null uint8\n",
      "Subscribed_yes         45211 non-null uint8\n",
      "dtypes: int32(1), int64(7), uint8(35)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "## Training Dataset\n",
    "###################\n",
    "# Convert all categorical variables to corresponding indicator variables\n",
    "for categoricalVar in categoricalVars:\n",
    "    tmpDf = pd.DataFrame()\n",
    "    # Remove 1st class level to avoid multicollinearity\n",
    "    tmpDf = pd.get_dummies(bankPromoModel_hsng_Df[categoricalVar], prefix=categoricalVar, drop_first=True)\n",
    "    bankPromoModel_hsng_Df = pd.concat((bankPromoModel_hsng_Df, tmpDf), axis=1)\n",
    "\n",
    "# Now remove the original categorical vars since indicator variables are created from them.\n",
    "bankPromoModel_hsng_Df.drop(categoricalVars, inplace=True, axis=1)\n",
    "print(\"Training dataset info\")\n",
    "print(\"=====================\")\n",
    "bankPromoModel_hsng_Df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id=\"top\"></a>\n",
    "<a id=\"TrainingSetClassPredVar\"></a>\n",
    "       \n",
    "### Seperate Class and Predictor Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seperate the class and predictor variables\n",
    "if 'Target' in bankPromoModel_hsng_Df:\n",
    "    y = bankPromoModel_hsng_Df['Target'].values # get the labels we want\n",
    "    del bankPromoModel_hsng_Df['Target']        # get rid of the class label\n",
    "    X = bankPromoModel_hsng_Df.values           # use everything else to predict!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id=\"top\"></a>\n",
    "<a id=\"TrainingSetFeatElim\"></a>\n",
    "\n",
    "### Feature Elimination Using Lasso Logistic Regression\n",
    "\n",
    "Featuring the same dataset as Task1 , it does not have a very high dimensionality , an attempt is made to eliminate any features that may not be useful to our task of classification of the response variable. A simple Logistic Regression model is run to analyze any features that can be eliminated.\n",
    "From our EDA phase, we know that dataset hosts an almost balanced set for response variable(\"housing\") classifiers - 56% for Yes and 44% for No. So for executing a simple model, class_weight as None is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ModelLR\"></a>\n",
    "       \n",
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id=\"ModelLRBuild\"></a>\n",
    "       \n",
    "### Logistic Regression Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month_aug has weight of -0.8218055880934713\n",
      "month_jun has weight of -0.5133078366224679\n",
      "age has weight of -0.34770575197344655\n",
      "month_jul has weight of -0.33219653576913705\n",
      "month_feb has weight of -0.30401987123143503\n",
      "job_student has weight of -0.2298849457383366\n",
      "month_jan has weight of -0.22251032200338852\n",
      "month_sep has weight of -0.21537644820959612\n",
      "month_oct has weight of -0.21508786998788285\n",
      "Subscribed_yes has weight of -0.21214732837628966\n",
      "marital_single has weight of -0.20485834964766605\n",
      "job_retired has weight of -0.20184179660375864\n",
      "job_unknown has weight of -0.17482566966737745\n",
      "month_mar has weight of -0.16929127133360752\n",
      "month_nov has weight of -0.1548033384929472\n",
      "month_dec has weight of -0.13777989156208167\n",
      "poutcome_success has weight of -0.12940030098315464\n",
      "day has weight of -0.11748156842113988\n",
      "job_housemaid has weight of -0.10266310732500522\n",
      "job_unemployed has weight of -0.0914933371853685\n",
      "contact_telephone has weight of -0.06990775131880754\n",
      "education_unknown has weight of -0.06908889225349335\n",
      "balance has weight of -0.06160846607376792\n",
      "job_self-employed has weight of -0.05478816511057268\n",
      "default_yes has weight of -0.03866118123443981\n",
      "poutcome_other has weight of -0.03355139251796191\n",
      "job_management has weight of -0.022941418672475247\n",
      "education_tertiary has weight of -0.017756816488902896\n",
      "job_entrepreneur has weight of -0.006165283082501696\n",
      "poutcome_unknown has weight of 0.0\n",
      "marital_married has weight of 0.0041355680086494935\n",
      "loan_yes has weight of 0.01581283932897791\n",
      "job_technician has weight of 0.016666225844844076\n",
      "job_services has weight of 0.02849243722019241\n",
      "education_secondary has weight of 0.03800683810887228\n",
      "previous has weight of 0.04202665532912485\n",
      "duration has weight of 0.07694250335968696\n",
      "campaign has weight of 0.11315624060102945\n",
      "job_blue-collar has weight of 0.12915086527664046\n",
      "contact_unknown has weight of 0.20524849208746798\n",
      "pdays has weight of 0.3212502833060009\n",
      "month_may has weight of 0.34290313815923523\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel_hsng = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', C=1.0,\\\n",
    "                                                                   class_weight=None, random_state=999, \\\n",
    "                                                                   solver='liblinear'))\n",
    "\n",
    "# Fit the whole training dataset now, since validation would be done on additional dataset\n",
    "logisticModel_hsng.fit(X,y) \n",
    "\n",
    "classifier_model = logisticModel_hsng.named_steps['logisticregression']\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(classifier_model.coef_.T, bankPromoModel_hsng_Df.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0])\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(20,9))\n",
    "weights = pd.Series(classifier_model.coef_[0],index=bankPromoModel_hsng_Df.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ModelLRFeatureAnalysis\"></a>\n",
    "       \n",
    "### Logistic Regression Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, above from results of Lasso Logistic Model with degree = 1 that following features ( with coeff = 0 ) can be eliminated. Next, we will explore them one by one :\n",
    "    \n",
    "    poutcome_unknown has weight of 0.0\n",
    "    \n",
    "Only 1 feature shows a -.0 coeff and is a level of categorical variable. **Hence this cannot be eliminated**. Next attempt was made to look at this model with different methods used for feature elimination to see if the results were different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Delete any features that do not relate to the response variable in the business sense\n",
    "\n",
    "BankPromo dataset contains \n",
    "\n",
    "i) bank client data like age, balance, education, job , marital status , any loans - housing/personal , if they have defaulted  \n",
    "\n",
    "ii) information regarding last contact  in current campaign - contact type, day/month when last contacted, duration of last call \n",
    "\n",
    "iii) other attributes like number of times contacted during current campaign ,number of days since last contact, number of contacts made in last campaign, outcome from previous campaign , outcome from current campagin i.e. Subscribed or not  \n",
    "\n",
    "\n",
    "From business use case perspective, any information regarding Term deposit subscription campaign may have no effect on the client data but vice-versa may not be true. It will be interesting to find what features from the campaign information should be considered to predict if a customer has a housing loan or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  58, 2143,    5, ...,    0,    1,    0],\n",
       "       [  44,   29,    5, ...,    0,    1,    0],\n",
       "       [  33,    2,    5, ...,    0,    1,    0],\n",
       "       ...,\n",
       "       [  72, 5715,   17, ...,    1,    0,    1],\n",
       "       [  57,  668,   17, ...,    0,    1,    0],\n",
       "       [  37, 2971,   17, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankPromoModel_hsng_Df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ModelLDA\"></a>\n",
    "       \n",
    "### Gather Numeric Variables for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fs info\n",
      "==========\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 42 columns):\n",
      "age                    45211 non-null int64\n",
      "balance                45211 non-null int64\n",
      "day                    45211 non-null int64\n",
      "duration               45211 non-null int64\n",
      "campaign               45211 non-null int64\n",
      "pdays                  45211 non-null int64\n",
      "previous               45211 non-null int64\n",
      "job_blue-collar        45211 non-null uint8\n",
      "job_entrepreneur       45211 non-null uint8\n",
      "job_housemaid          45211 non-null uint8\n",
      "job_management         45211 non-null uint8\n",
      "job_retired            45211 non-null uint8\n",
      "job_self-employed      45211 non-null uint8\n",
      "job_services           45211 non-null uint8\n",
      "job_student            45211 non-null uint8\n",
      "job_technician         45211 non-null uint8\n",
      "job_unemployed         45211 non-null uint8\n",
      "job_unknown            45211 non-null uint8\n",
      "marital_married        45211 non-null uint8\n",
      "marital_single         45211 non-null uint8\n",
      "education_secondary    45211 non-null uint8\n",
      "education_tertiary     45211 non-null uint8\n",
      "education_unknown      45211 non-null uint8\n",
      "default_yes            45211 non-null uint8\n",
      "loan_yes               45211 non-null uint8\n",
      "contact_telephone      45211 non-null uint8\n",
      "contact_unknown        45211 non-null uint8\n",
      "month_aug              45211 non-null uint8\n",
      "month_dec              45211 non-null uint8\n",
      "month_feb              45211 non-null uint8\n",
      "month_jan              45211 non-null uint8\n",
      "month_jul              45211 non-null uint8\n",
      "month_jun              45211 non-null uint8\n",
      "month_mar              45211 non-null uint8\n",
      "month_may              45211 non-null uint8\n",
      "month_nov              45211 non-null uint8\n",
      "month_oct              45211 non-null uint8\n",
      "month_sep              45211 non-null uint8\n",
      "poutcome_other         45211 non-null uint8\n",
      "poutcome_success       45211 non-null uint8\n",
      "poutcome_unknown       45211 non-null uint8\n",
      "Subscribed_yes         45211 non-null uint8\n",
      "dtypes: int64(7), uint8(35)\n",
      "memory usage: 3.9 MB\n",
      "y_fs info\n",
      "==========\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "# gather numerical variables for LDA\n",
    "\n",
    "X_fs = bankPromoModel_hsng_Df.copy()\n",
    "y_fs = y\n",
    "\n",
    "print(\"X_fs info\")\n",
    "print(\"==========\")\n",
    "X_fs.info()\n",
    "\n",
    "print(\"y_fs info\")\n",
    "print(\"==========\")\n",
    "print(y_fs.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"FeatureSelection\"></a>\n",
    "       \n",
    "### Feature Selections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FeatureSelectionChiSq\"></a>\n",
    "### Chi-Sq Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Sq test for feature selection amongst categorical variables\n",
    "# below code referred from http://www.insightsbot.com/blog/2AeuRL/chi-square-feature-selection-in-python\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "class ChiSquare:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.p = None #P-Value\n",
    "        self.chi2 = None #Chi Test Statistic\n",
    "        self.dof = None\n",
    "        \n",
    "        self.dfTabular = None\n",
    "        self.dfExpected = None\n",
    "        \n",
    "    def TestIndependence(self,colX,colY, alpha=0.05):\n",
    "        X = self.df[colX].astype(str)\n",
    "        Y = self.df[colY].astype(str)\n",
    "        \n",
    "        self.dfObserved = pd.crosstab(Y,X) \n",
    "        chi2, p, dof, expected = stats.chi2_contingency(self.dfObserved.values)\n",
    "        self.p = p\n",
    "        self.chi2 = chi2\n",
    "        self.dof = dof \n",
    "        \n",
    "        self.dfExpected = pd.DataFrame(expected, columns=self.dfObserved.columns, index = self.dfObserved.index)\n",
    "        \n",
    "        self._print_chisquare_result(colX, alpha)\n",
    "    \n",
    "    def _print_chisquare_result(self, colX, alpha):\n",
    "        result = \"\"\n",
    "        if self.p<alpha:\n",
    "            result=\"{0} is IMPORTANT for Prediction\".format(colX)\n",
    "        else:\n",
    "            result=\"{0} is NOT an important predictor. (Discard {0} from model)\".format(colX)\n",
    "\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"FeatureSelectionPearosn\"></a>\n",
    "\n",
    "### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 selected features\n",
      "                      0\n",
      "0           job_unknown\n",
      "1             month_sep\n",
      "2         job_housemaid\n",
      "3     contact_telephone\n",
      "4           job_student\n",
      "5             month_oct\n",
      "6      poutcome_success\n",
      "7    education_tertiary\n",
      "8   education_secondary\n",
      "9             month_jun\n",
      "10                pdays\n",
      "11       Subscribed_yes\n",
      "12          job_retired\n",
      "13      job_blue-collar\n",
      "14                  age\n",
      "15      contact_unknown\n",
      "16            month_aug\n",
      "17            month_may\n"
     ]
    }
   ],
   "source": [
    "# Pearson Correlation\n",
    "feature_name = X_fs.columns.tolist()\n",
    "\n",
    "def cor_selector(X, y):\n",
    "    cor_list = []\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-18:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "\n",
    "cor_support, cor_feature = cor_selector(X_fs, y_fs)\n",
    "print(str(len(cor_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame( cor_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"FeatureSelectionChiSqII\"></a>\n",
    "### Chi-Sq Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 selected features\n",
      "                      0\n",
      "0       job_blue-collar\n",
      "1         job_housemaid\n",
      "2           job_retired\n",
      "3          job_services\n",
      "4           job_student\n",
      "5           job_unknown\n",
      "6   education_secondary\n",
      "7    education_tertiary\n",
      "8     contact_telephone\n",
      "9       contact_unknown\n",
      "10            month_aug\n",
      "11            month_jun\n",
      "12            month_mar\n",
      "13            month_may\n",
      "14            month_oct\n",
      "15            month_sep\n",
      "16     poutcome_success\n",
      "17       Subscribed_yes\n"
     ]
    }
   ],
   "source": [
    "# Chi-sq test\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_norm = MinMaxScaler().fit_transform(X_fs)\n",
    "chi_selector = SelectKBest(chi2, k=18)\n",
    "chi_selector.fit(X_norm, y_fs)\n",
    "\n",
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = X_fs.loc[:,chi_support].columns.tolist()\n",
    "print(str(len(chi_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(chi_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"LRFitting\"></a>\n",
    "### Logistic Regression Fitting Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 22 features.\n",
      "18 selected features\n",
      "                   0\n",
      "0                age\n",
      "1            balance\n",
      "2           duration\n",
      "3           campaign\n",
      "4              pdays\n",
      "5        job_retired\n",
      "6        job_student\n",
      "7        job_unknown\n",
      "8          month_aug\n",
      "9          month_dec\n",
      "10         month_feb\n",
      "11         month_jan\n",
      "12         month_mar\n",
      "13         month_may\n",
      "14         month_oct\n",
      "15         month_sep\n",
      "16  poutcome_success\n",
      "17    Subscribed_yes\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=18, step=10, verbose=5)\n",
    "rfe_selector.fit(X_norm, y_fs)\n",
    "\n",
    "\n",
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = X_fs.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(rfe_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"LRFittingSelection\"></a>\n",
    "### Logistic Regression Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 selected features\n",
      "              0\n",
      "0           age\n",
      "1       balance\n",
      "2      duration\n",
      "3      campaign\n",
      "4         pdays\n",
      "5   job_retired\n",
      "6   job_student\n",
      "7   job_unknown\n",
      "8     month_aug\n",
      "9     month_dec\n",
      "10    month_feb\n",
      "11    month_jan\n",
      "12    month_jul\n",
      "13    month_jun\n",
      "14    month_mar\n",
      "15    month_oct\n",
      "16    month_sep\n"
     ]
    }
   ],
   "source": [
    "## Embed\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\"), '1.25*median',max_features=18)\n",
    "embeded_lr_selector.fit(X_norm, y_fs)\n",
    "\n",
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X_fs.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(embeded_lr_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"RFFeatSelection\"></a>\n",
    "### Random Forest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 selected features\n",
      "                      0\n",
      "0                   age\n",
      "1               balance\n",
      "2                   day\n",
      "3              duration\n",
      "4              campaign\n",
      "5                 pdays\n",
      "6              previous\n",
      "7       job_blue-collar\n",
      "8       marital_married\n",
      "9   education_secondary\n",
      "10             loan_yes\n",
      "11      contact_unknown\n",
      "12            month_aug\n",
      "13            month_jul\n",
      "14            month_jun\n",
      "15            month_may\n",
      "16       Subscribed_yes\n"
     ]
    }
   ],
   "source": [
    "## Random forest\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), threshold='1.25*median', max_features=42)\n",
    "embeded_rf_selector.fit(X_fs, y_fs)\n",
    "\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X_fs.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(embeded_rf_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"LGBMFeatSelection\"></a>\n",
    "### Light GBM Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b883e53a5e77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "## LightGBM\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "\n",
    "embeded_lgb_selector = SelectFromModel(lgbc, threshold='1.25*median',max_features=18)\n",
    "embeded_lgb_selector.fit(X_fs, y_fs)\n",
    "\n",
    "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
    "embeded_lgb_feature = X_fs.loc[:,embeded_lgb_support].columns.tolist()\n",
    "print(str(len(embeded_lgb_feature)), 'selected features')\n",
    "\n",
    "print(pd.DataFrame(embeded_lgb_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "# put all selection together\n",
    "feature_selection_df = pd.DataFrame({'Feature':feature_name, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'Logistics':embeded_lr_support,\n",
    "                                    'Random Forest':embeded_rf_support, 'LightGBM':embeded_lgb_support})\n",
    "# count the selected times for each feature\n",
    "feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
    "# display the top 100\n",
    "feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
    "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
    "feature_selection_df.head(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"FeatSelectionSummary\"></a>\n",
    "### Feature Selection Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen through the various methods deployed, the features that show least or no importance from all methods are :\n",
    " \n",
    "poutcome_unknown\n",
    "poutcome_other\n",
    "month_nov\n",
    "job_unemployed\n",
    "job_self-employed\n",
    "job_management\n",
    "job_entrepreneur\n",
    "education_unknown\n",
    "default_yes\n",
    "\n",
    "**All features except default_yes are one of multiple levels of a categorical variable. Removing default did not yield better results and this not being a high-dimensional dataset, decision is made to proceed with all features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"SummaryObjDataPrep1\"></a>\n",
    "### Summary and Objectives tracking for section: Data Preparation Part 1\n",
    "\n",
    "Define and prepare your class variables.\n",
    "// \"housing\" variable is identified and prepared as class variable.\n",
    "\n",
    "Use proper variable representations (int, float, one-hot, etc.).\n",
    "// As can be seen from above code, all the numericals variables have been appropriatly represented in the dataset and all categorical variables have been encoded using one-hot encoding.\n",
    "\n",
    "Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc.\n",
    "// Scaling of the variables would be later performed before model preparation using pipeline which would first scale the variables before fitting them to model. Since, our data is not that high dimensional in feature space, hence no dimensionality reduction technique was performed. Rest all pre-processing was performed.\n",
    "\n",
    "Remove variables that are not needed/useful for the analysis.\n",
    "// No feature was deemed as non-important enough to be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 2 for Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>Subscribed_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.936210</td>\n",
       "      <td>1362.272058</td>\n",
       "      <td>15.806419</td>\n",
       "      <td>258.163080</td>\n",
       "      <td>2.763841</td>\n",
       "      <td>40.197828</td>\n",
       "      <td>0.580323</td>\n",
       "      <td>0.215257</td>\n",
       "      <td>0.032890</td>\n",
       "      <td>0.027427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118135</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>0.304483</td>\n",
       "      <td>0.087810</td>\n",
       "      <td>0.016323</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.033421</td>\n",
       "      <td>0.817478</td>\n",
       "      <td>0.116985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.618762</td>\n",
       "      <td>3044.765829</td>\n",
       "      <td>8.322476</td>\n",
       "      <td>257.527812</td>\n",
       "      <td>3.098021</td>\n",
       "      <td>100.128746</td>\n",
       "      <td>2.303441</td>\n",
       "      <td>0.411005</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>0.163326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322771</td>\n",
       "      <td>0.102174</td>\n",
       "      <td>0.460193</td>\n",
       "      <td>0.283022</td>\n",
       "      <td>0.126718</td>\n",
       "      <td>0.112441</td>\n",
       "      <td>0.197592</td>\n",
       "      <td>0.179735</td>\n",
       "      <td>0.386278</td>\n",
       "      <td>0.321406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        balance           day      duration      campaign  \\\n",
       "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
       "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
       "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
       "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
       "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
       "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
       "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
       "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
       "\n",
       "              pdays      previous  job_blue-collar  job_entrepreneur  \\\n",
       "count  45211.000000  45211.000000     45211.000000      45211.000000   \n",
       "mean      40.197828      0.580323         0.215257          0.032890   \n",
       "std      100.128746      2.303441         0.411005          0.178351   \n",
       "min       -1.000000      0.000000         0.000000          0.000000   \n",
       "25%       -1.000000      0.000000         0.000000          0.000000   \n",
       "50%       -1.000000      0.000000         0.000000          0.000000   \n",
       "75%       -1.000000      0.000000         0.000000          0.000000   \n",
       "max      871.000000    275.000000         1.000000          1.000000   \n",
       "\n",
       "       job_housemaid  ...     month_jun     month_mar     month_may  \\\n",
       "count   45211.000000  ...  45211.000000  45211.000000  45211.000000   \n",
       "mean        0.027427  ...      0.118135      0.010551      0.304483   \n",
       "std         0.163326  ...      0.322771      0.102174      0.460193   \n",
       "min         0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%         0.000000  ...      0.000000      0.000000      0.000000   \n",
       "50%         0.000000  ...      0.000000      0.000000      0.000000   \n",
       "75%         0.000000  ...      0.000000      0.000000      1.000000   \n",
       "max         1.000000  ...      1.000000      1.000000      1.000000   \n",
       "\n",
       "          month_nov     month_oct     month_sep  poutcome_other  \\\n",
       "count  45211.000000  45211.000000  45211.000000    45211.000000   \n",
       "mean       0.087810      0.016323      0.012807        0.040698   \n",
       "std        0.283022      0.126718      0.112441        0.197592   \n",
       "min        0.000000      0.000000      0.000000        0.000000   \n",
       "25%        0.000000      0.000000      0.000000        0.000000   \n",
       "50%        0.000000      0.000000      0.000000        0.000000   \n",
       "75%        0.000000      0.000000      0.000000        0.000000   \n",
       "max        1.000000      1.000000      1.000000        1.000000   \n",
       "\n",
       "       poutcome_success  poutcome_unknown  Subscribed_yes  \n",
       "count      45211.000000      45211.000000    45211.000000  \n",
       "mean           0.033421          0.817478        0.116985  \n",
       "std            0.179735          0.386278        0.321406  \n",
       "min            0.000000          0.000000        0.000000  \n",
       "25%            0.000000          1.000000        0.000000  \n",
       "50%            0.000000          1.000000        0.000000  \n",
       "75%            0.000000          1.000000        0.000000  \n",
       "max            1.000000          1.000000        1.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankPromoModel_hsng_Df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 42 columns):\n",
      "age                    45211 non-null int64\n",
      "balance                45211 non-null int64\n",
      "day                    45211 non-null int64\n",
      "duration               45211 non-null int64\n",
      "campaign               45211 non-null int64\n",
      "pdays                  45211 non-null int64\n",
      "previous               45211 non-null int64\n",
      "job_blue-collar        45211 non-null uint8\n",
      "job_entrepreneur       45211 non-null uint8\n",
      "job_housemaid          45211 non-null uint8\n",
      "job_management         45211 non-null uint8\n",
      "job_retired            45211 non-null uint8\n",
      "job_self-employed      45211 non-null uint8\n",
      "job_services           45211 non-null uint8\n",
      "job_student            45211 non-null uint8\n",
      "job_technician         45211 non-null uint8\n",
      "job_unemployed         45211 non-null uint8\n",
      "job_unknown            45211 non-null uint8\n",
      "marital_married        45211 non-null uint8\n",
      "marital_single         45211 non-null uint8\n",
      "education_secondary    45211 non-null uint8\n",
      "education_tertiary     45211 non-null uint8\n",
      "education_unknown      45211 non-null uint8\n",
      "default_yes            45211 non-null uint8\n",
      "loan_yes               45211 non-null uint8\n",
      "contact_telephone      45211 non-null uint8\n",
      "contact_unknown        45211 non-null uint8\n",
      "month_aug              45211 non-null uint8\n",
      "month_dec              45211 non-null uint8\n",
      "month_feb              45211 non-null uint8\n",
      "month_jan              45211 non-null uint8\n",
      "month_jul              45211 non-null uint8\n",
      "month_jun              45211 non-null uint8\n",
      "month_mar              45211 non-null uint8\n",
      "month_may              45211 non-null uint8\n",
      "month_nov              45211 non-null uint8\n",
      "month_oct              45211 non-null uint8\n",
      "month_sep              45211 non-null uint8\n",
      "poutcome_other         45211 non-null uint8\n",
      "poutcome_success       45211 non-null uint8\n",
      "poutcome_unknown       45211 non-null uint8\n",
      "Subscribed_yes         45211 non-null uint8\n",
      "dtypes: int64(7), uint8(35)\n",
      "memory usage: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "bankPromoModel_hsng_Df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So we would use above 42 predictors to create and validate our models; and variable \"Housing\" has been renamed to Target variable and would be used as class label.** The description of these variables is as:\n",
    "\n",
    "- **Age** – Age is a numeric variable that ranges from ages 18-95 years.  \n",
    "- **Job** – Job type is a categorical variable that entered the client into types of occupations.  The choices were: admin., unknown, unemployed, management, housemaid, entrepreneur, student, blue-collar, self-employed, retired, technician and services.  \n",
    "- **Marital** – Marital status is a categorical variable that describes if the client is married, divorced or single.  For widowed clients, the bank has selected the divorced selection.\n",
    "- **Education** – Education represents the client’s highest level of education.  The categorical variable has the following selections:  unknown, primary, secondary or tertiary.  Primary level is equivalent to the US elementary and middle school grades.  Secondary is similar to the US high school, but is split between more professional teachings versus vocations.  Tertiary level represents all level of higher education from special licenses, bachelors to post doctorate school (https://www.scholaro.com/pro/Countries/Portugal/Education-System).\n",
    "- **Default** – Default represents if the client has defaulted in their credit history as a binary variable denoted with yes for default or no for no default.\n",
    "- **Balance** – Balance is a numeric variable which signifies the yearly average balance in Euros.\n",
    "- **Housing** – Housing is a binary variable which represents if the client has a home loan or not.  The selections are yes or no.\n",
    "- **Loan** – Loan is similar to the housing variable except it represents if the client has a personal loan.\n",
    "- **Contact** – Contact is a categorical variable describing the method of telecommunication between the bank and the client.  The selections are:  unknown, telephone or cellular.\n",
    "- **Day** – Day is a numeric variable that represents the day of the month of the last contact.\n",
    "- **Month** – Month is represented as a categorical variable where each month is denoted by the first three letters.  Every month of the year is represented.  The month corresponds to the last contact made with the client.\n",
    "- **Duration** – Duration is the amount of time (a numeric variable) in seconds that the last contact with the client lasted.  This attribute is not the total time the clients were interviewed.     \n",
    "- **Campaign** – Campaign is a numeric variable which represents the number of times the bank has contacted, using any method of communication, the client during this particular marketing campaign.\n",
    "- **Previous** – Previous is a numeric variable that identifies the number of times a client has been involved with a marketing campaign with this bank prior to the current campaign. \n",
    "- **pOutcome** – pOutcome represents the outcome of a previous marketing campaign.  The categorical variable is identified by:  unknown, other, failure or success.  Each client that has not participated in a previous marketing campaign has been marked as unknown for pOutcome.\n",
    "- **pdays** - pdays represents the number of days since the last contact in a previous campaign. This feature has seen to be correlated to pOutcome in the analysis for Task1.\n",
    "- **Subscribed** – Y signifies yes if the customer accepted a term deposit during the current marketing campaign.  The binary variable is defined as yes or no.  In the remaining portions of the report, this variable is denoted as subscribed with the results remaining as yes or no. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and Objectives tracking for section: Data Preparation Part 2\n",
    "\n",
    "Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "// The final dataset that is to be used for classification in Task 2 has been described as above. No new variables were created for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1 - Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this task, we are predicting whether a bank client has a housing loan. 56% of the clients in this data set have housing loan and the remaining 44% do not, which dataset is closely balanced for this task. We used accuracy to evaluate the model performance and select the model parameters.\n",
    "\n",
    "- From a business standpoint, it is equally important to know who has a loan or not. Banks could offer additional promotions regarding home refinancing for customers who have housing loans. Similarly, if the bank wants to attract new home owners, they can contact people who do not have housing loans. **Correct prediction is more important for this model and accuracy is chosen as a primary metric to evaluate the models.**\n",
    "\n",
    "- **This will be followed by AuC scores**, as accuracy is calculated at a threshold value of 0.5. In real life, the probability of the population having a housing loan is not 50-50. This data set was collected at time of economic recession, so it is likely that prior probabilities of people having housing loan were not at 50-50 level. (reference: https://tradingeconomics.com/portugal/home-ownership-rate shows in 2010 the home ownership rate was ~75%, no 2008-2009 data was found) . **Hence, AuC score (in conjunction to ROC curve) score which basically provides accuracies at different threshold values, would overall provide a better measure of model performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2 - Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For task 2, we are using 10-fold cross validation method to split the training set. As shown, we also have a separate data set from UCI Machine Learning website for prediction and test. There are 45,211 instances in the training set and 4,521 in the holdout test dataset. So next we would explore **stsndard 10-fold and stratified 10-fold Shuffle Split** as possible Cross validation techniques for dividing our dataet into training and testing splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create 10 Splits  Cross Validation Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=999, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "# Training and Test Split\n",
    "# Since housing is a balanced dataset ( with 56% yes and 44% No , we will use simple KFold and ShuffleSplit cv objects)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "      \n",
    "# To use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 10\n",
    "kfold_cv_object = KFold(n_splits=num_cv_iterations , shuffle = False , random_state=999)\n",
    "#n_splits=num_cv_iterations,test_size  = 0.2, random_state=999\n",
    "                         \n",
    "print(kfold_cv_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3350</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.944613</td>\n",
       "      <td>0.744731</td>\n",
       "      <td>0.574598</td>\n",
       "      <td>0.816525</td>\n",
       "      <td>0.895179</td>\n",
       "      <td>0.735653</td>\n",
       "      <td>0.897026</td>\n",
       "      <td>0.745085</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>0.744378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.853853</td>\n",
       "      <td>0.751690</td>\n",
       "      <td>0.585186</td>\n",
       "      <td>0.824778</td>\n",
       "      <td>0.752931</td>\n",
       "      <td>0.745441</td>\n",
       "      <td>0.908155</td>\n",
       "      <td>0.759814</td>\n",
       "      <td>0.805679</td>\n",
       "      <td>0.743738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3075</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.500095</td>\n",
       "      <td>0.809572</td>\n",
       "      <td>0.627757</td>\n",
       "      <td>0.842206</td>\n",
       "      <td>0.418491</td>\n",
       "      <td>0.771369</td>\n",
       "      <td>0.343252</td>\n",
       "      <td>0.786251</td>\n",
       "      <td>0.920868</td>\n",
       "      <td>0.834318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3375</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.088985</td>\n",
       "      <td>0.800586</td>\n",
       "      <td>0.538851</td>\n",
       "      <td>0.849564</td>\n",
       "      <td>0.438399</td>\n",
       "      <td>0.779258</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.802225</td>\n",
       "      <td>0.048381</td>\n",
       "      <td>0.798954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2100</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.245696</td>\n",
       "      <td>0.792306</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.786773</td>\n",
       "      <td>0.748169</td>\n",
       "      <td>0.581481</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.155754</td>\n",
       "      <td>0.810256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2400</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.590136</td>\n",
       "      <td>0.786064</td>\n",
       "      <td>0.761794</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.685689</td>\n",
       "      <td>0.757483</td>\n",
       "      <td>0.719409</td>\n",
       "      <td>0.786815</td>\n",
       "      <td>0.500244</td>\n",
       "      <td>0.785315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2900</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.455639</td>\n",
       "      <td>0.792442</td>\n",
       "      <td>0.696512</td>\n",
       "      <td>0.838221</td>\n",
       "      <td>0.629507</td>\n",
       "      <td>0.761637</td>\n",
       "      <td>0.705231</td>\n",
       "      <td>0.781817</td>\n",
       "      <td>0.336534</td>\n",
       "      <td>0.803358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.2800</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.878076</td>\n",
       "      <td>0.754189</td>\n",
       "      <td>0.772711</td>\n",
       "      <td>0.822239</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>0.742910</td>\n",
       "      <td>0.891286</td>\n",
       "      <td>0.762158</td>\n",
       "      <td>0.865252</td>\n",
       "      <td>0.746384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.900643</td>\n",
       "      <td>0.760999</td>\n",
       "      <td>0.843792</td>\n",
       "      <td>0.821425</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.857376</td>\n",
       "      <td>0.755513</td>\n",
       "      <td>0.948509</td>\n",
       "      <td>0.766564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.377330</td>\n",
       "      <td>0.800729</td>\n",
       "      <td>0.646786</td>\n",
       "      <td>0.829804</td>\n",
       "      <td>0.630613</td>\n",
       "      <td>0.758270</td>\n",
       "      <td>0.292317</td>\n",
       "      <td>0.784798</td>\n",
       "      <td>0.532072</td>\n",
       "      <td>0.817321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0    1.3350      0.0325       0.944613        0.744731  0.574598   0.816525   \n",
       "1    1.3625      0.0500       0.853853        0.751690  0.585186   0.824778   \n",
       "2    1.3075      0.0525       0.500095        0.809572  0.627757   0.842206   \n",
       "3    1.3375      0.0400       0.088985        0.800586  0.538851   0.849564   \n",
       "4    1.2100      0.0400       0.245696        0.792306  0.669041   0.821918   \n",
       "5    1.2400      0.0400       0.590136        0.786064  0.761794   0.834171   \n",
       "6    1.2900      0.0300       0.455639        0.792442  0.696512   0.838221   \n",
       "7    2.2800      0.0400       0.878076        0.754189  0.772711   0.822239   \n",
       "8    0.8900      0.0400       0.900643        0.760999  0.843792   0.821425   \n",
       "9    0.9500      0.0300       0.377330        0.800729  0.646786   0.829804   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.895179        0.735653        0.897026         0.745085   \n",
       "1       0.752931        0.745441        0.908155         0.759814   \n",
       "2       0.418491        0.771369        0.343252         0.786251   \n",
       "3       0.438399        0.779258        0.553571         0.802225   \n",
       "4       0.786773        0.748169        0.581481         0.775134   \n",
       "5       0.685689        0.757483        0.719409         0.786815   \n",
       "6       0.629507        0.761637        0.705231         0.781817   \n",
       "7       0.807122        0.742910        0.891286         0.762158   \n",
       "8       0.846273        0.741927        0.857376         0.755513   \n",
       "9       0.630613        0.758270        0.292317         0.784798   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.997532      0.744378  \n",
       "1     0.805679      0.743738  \n",
       "2     0.920868      0.834318  \n",
       "3     0.048381      0.798954  \n",
       "4     0.155754      0.810256  \n",
       "5     0.500244      0.785315  \n",
       "6     0.336534      0.803358  \n",
       "7     0.865252      0.746384  \n",
       "8     0.948509      0.766564  \n",
       "9     0.532072      0.817321  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           1.320250\n",
       "score_time         0.039500\n",
       "test_F1_Score      0.583507\n",
       "train_F1_Score     0.779331\n",
       "test_AUC           0.671703\n",
       "train_AUC          0.830085\n",
       "test_Accuracy      0.689098\n",
       "train_Accuracy     0.754212\n",
       "test_Precision     0.674911\n",
       "train_Precision    0.773961\n",
       "test_Recall        0.611083\n",
       "train_Recall       0.785059\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.779331</td>\n",
       "      <td>0.830085</td>\n",
       "      <td>0.754212</td>\n",
       "      <td>0.773961</td>\n",
       "      <td>0.785059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.779331   0.830085        0.754212         0.773961      0.785059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583507</td>\n",
       "      <td>0.671703</td>\n",
       "      <td>0.689098</td>\n",
       "      <td>0.674911</td>\n",
       "      <td>0.611083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.583507  0.671703       0.689098        0.674911     0.611083"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from sklearn import metrics as mt\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel = make_pipeline(StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores = cross_validate(logisticModel , X, y=y , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores))\n",
    "display(pd.DataFrame(scores).mean())\n",
    "end = datetime.now()\n",
    "\n",
    "print()\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb3929e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(scores)[testCol].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=10, random_state=999, test_size=0.1, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "# To use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 10\n",
    "shuffle_cv_object = ShuffleSplit(n_splits=num_cv_iterations, test_size = 0.1, random_state=999)\n",
    "                         \n",
    "print(shuffle_cv_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3850</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.775268</td>\n",
       "      <td>0.778855</td>\n",
       "      <td>0.827496</td>\n",
       "      <td>0.829789</td>\n",
       "      <td>0.749226</td>\n",
       "      <td>0.752316</td>\n",
       "      <td>0.772817</td>\n",
       "      <td>0.773054</td>\n",
       "      <td>0.777734</td>\n",
       "      <td>0.784745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4325</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.788132</td>\n",
       "      <td>0.777900</td>\n",
       "      <td>0.835867</td>\n",
       "      <td>0.828970</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.783452</td>\n",
       "      <td>0.771810</td>\n",
       "      <td>0.792869</td>\n",
       "      <td>0.784086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4050</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.781732</td>\n",
       "      <td>0.778234</td>\n",
       "      <td>0.838677</td>\n",
       "      <td>0.828603</td>\n",
       "      <td>0.755860</td>\n",
       "      <td>0.751505</td>\n",
       "      <td>0.779882</td>\n",
       "      <td>0.771818</td>\n",
       "      <td>0.783591</td>\n",
       "      <td>0.784757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3675</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.782011</td>\n",
       "      <td>0.778980</td>\n",
       "      <td>0.833092</td>\n",
       "      <td>0.829253</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.767836</td>\n",
       "      <td>0.772082</td>\n",
       "      <td>0.796719</td>\n",
       "      <td>0.786002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.787298</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.838794</td>\n",
       "      <td>0.828522</td>\n",
       "      <td>0.764485</td>\n",
       "      <td>0.750399</td>\n",
       "      <td>0.781833</td>\n",
       "      <td>0.770795</td>\n",
       "      <td>0.792840</td>\n",
       "      <td>0.784888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.3600</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>0.777182</td>\n",
       "      <td>0.831703</td>\n",
       "      <td>0.829384</td>\n",
       "      <td>0.756966</td>\n",
       "      <td>0.750694</td>\n",
       "      <td>0.785601</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.779093</td>\n",
       "      <td>0.782961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.3500</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.774514</td>\n",
       "      <td>0.778807</td>\n",
       "      <td>0.824350</td>\n",
       "      <td>0.830311</td>\n",
       "      <td>0.748784</td>\n",
       "      <td>0.751702</td>\n",
       "      <td>0.763302</td>\n",
       "      <td>0.772398</td>\n",
       "      <td>0.786060</td>\n",
       "      <td>0.785323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.3800</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.784175</td>\n",
       "      <td>0.778494</td>\n",
       "      <td>0.830247</td>\n",
       "      <td>0.829594</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>0.751628</td>\n",
       "      <td>0.776270</td>\n",
       "      <td>0.771426</td>\n",
       "      <td>0.792244</td>\n",
       "      <td>0.785692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.768526</td>\n",
       "      <td>0.779463</td>\n",
       "      <td>0.823310</td>\n",
       "      <td>0.830286</td>\n",
       "      <td>0.743034</td>\n",
       "      <td>0.752759</td>\n",
       "      <td>0.761247</td>\n",
       "      <td>0.773899</td>\n",
       "      <td>0.775945</td>\n",
       "      <td>0.785109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.771485</td>\n",
       "      <td>0.779363</td>\n",
       "      <td>0.821751</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.752587</td>\n",
       "      <td>0.762128</td>\n",
       "      <td>0.773346</td>\n",
       "      <td>0.781075</td>\n",
       "      <td>0.785474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0    1.3850        0.03       0.775268        0.778855  0.827496   0.829789   \n",
       "1    1.4325        0.03       0.788132        0.777900  0.835867   0.828970   \n",
       "2    1.4050        0.03       0.781732        0.778234  0.838677   0.828603   \n",
       "3    1.3675        0.03       0.782011        0.778980  0.833092   0.829253   \n",
       "4    1.4000        0.04       0.787298        0.777778  0.838794   0.828522   \n",
       "5    1.3600        0.04       0.782333        0.777182  0.831703   0.829384   \n",
       "6    1.3500        0.03       0.774514        0.778807  0.824350   0.830311   \n",
       "7    1.3800        0.04       0.784175        0.778494  0.830247   0.829594   \n",
       "8    0.5900        0.02       0.768526        0.779463  0.823310   0.830286   \n",
       "9    0.5800        0.02       0.771485        0.779363  0.821751   0.830527   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.749226        0.752316        0.772817         0.773054   \n",
       "1       0.764706        0.750940        0.783452         0.771810   \n",
       "2       0.755860        0.751505        0.779882         0.771818   \n",
       "3       0.754533        0.751923        0.767836         0.772082   \n",
       "4       0.764485        0.750399        0.781833         0.770795   \n",
       "5       0.756966        0.750694        0.785601         0.771488   \n",
       "6       0.748784        0.751702        0.763302         0.772398   \n",
       "7       0.756303        0.751628        0.776270         0.771426   \n",
       "8       0.743034        0.752759        0.761247         0.773899   \n",
       "9       0.744803        0.752587        0.762128         0.773346   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.777734      0.784745  \n",
       "1     0.792869      0.784086  \n",
       "2     0.783591      0.784757  \n",
       "3     0.796719      0.786002  \n",
       "4     0.792840      0.784888  \n",
       "5     0.779093      0.782961  \n",
       "6     0.786060      0.785323  \n",
       "7     0.792244      0.785692  \n",
       "8     0.775945      0.785109  \n",
       "9     0.781075      0.785474  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           1.225000\n",
       "score_time         0.031000\n",
       "test_F1_Score      0.779547\n",
       "train_F1_Score     0.778506\n",
       "test_AUC           0.830529\n",
       "train_AUC          0.829524\n",
       "test_Accuracy      0.753870\n",
       "train_Accuracy     0.751645\n",
       "test_Precision     0.773437\n",
       "train_Precision    0.772212\n",
       "test_Recall        0.785817\n",
       "train_Recall       0.784904\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Mean values for Performance Metrices on Train Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.778506</td>\n",
       "      <td>0.829524</td>\n",
       "      <td>0.751645</td>\n",
       "      <td>0.772212</td>\n",
       "      <td>0.784904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.778506   0.829524        0.751645         0.772212      0.784904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.779547</td>\n",
       "      <td>0.830529</td>\n",
       "      <td>0.75387</td>\n",
       "      <td>0.773437</td>\n",
       "      <td>0.785817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.779547  0.830529        0.75387        0.773437     0.785817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from sklearn import metrics as mt\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "\n",
    "logisticModel = make_pipeline(StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores = cross_validate(logisticModel , X, y=y , cv = shuffle_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores))\n",
    "display(pd.DataFrame(scores).mean())\n",
    "end = datetime.now()\n",
    "\n",
    "\n",
    "print()\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Train Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)\n",
    "\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb424668>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(scores)[testCol].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard K-fold was chosen for this mode.** Reasons for using k-fold for splitting the data versus Shuffle split\n",
    "•   Based on the visualization, there are no outliers in standard K-fold\n",
    "•\tShuffleSplit will randomly sample the entire dataset during each iteration to generate a training set and a test set. Since we are sampling from the entire dataset during each iteration, values selected during one iteration, could be selected again during another iteration. Whereas in K-fold the test data is different in each fold. This generalizes the model for prediction on future datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready Additional Test Dataset(with 10% instances) for final model fitting and evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      "age           4521 non-null int64\n",
      "job           4521 non-null object\n",
      "marital       4521 non-null object\n",
      "education     4521 non-null object\n",
      "default       4521 non-null object\n",
      "balance       4521 non-null int64\n",
      "loan          4521 non-null object\n",
      "contact       4521 non-null object\n",
      "day           4521 non-null int64\n",
      "month         4521 non-null object\n",
      "duration      4521 non-null int64\n",
      "campaign      4521 non-null int64\n",
      "pdays         4521 non-null int64\n",
      "previous      4521 non-null int64\n",
      "poutcome      4521 non-null object\n",
      "Subscribed    4521 non-null object\n",
      "Target        4521 non-null int32\n",
      "dtypes: int32(1), int64(7), object(9)\n",
      "memory usage: 582.9+ KB\n"
     ]
    }
   ],
   "source": [
    "pathOfAdditionalDataFile = \"data/bank.csv\"\n",
    "\n",
    "# Import the semi-colon delimited data file into pandas dataFrame\n",
    "bankPromoAdditional_h_df = pd.read_csv(pathOfAdditionalDataFile, sep = \";\")\n",
    "\n",
    "# Rename the Target/Final Outcome column from \"y\" to \"Subscribed\" as based on data description.\n",
    "bankPromoAdditional_h_df = bankPromoAdditional_h_df.rename(columns={\"y\":\"Subscribed\"})\n",
    "\n",
    "bankPromoAdditional_h_df['Target'] = bankPromoAdditional_h_df['housing'].apply(lambda resp : 1 if resp == \"yes\" else 0)\n",
    "bankPromoAdditional_h_df['Target'] = bankPromoAdditional_h_df['Target'].astype(np.int)\n",
    "# Delete the original 'housing' column\n",
    "del bankPromoAdditional_h_df['housing']\n",
    "\n",
    "bankPromoAdditional_h_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset info\n",
      "=====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 42 columns):\n",
      "age                    4521 non-null int64\n",
      "balance                4521 non-null int64\n",
      "day                    4521 non-null int64\n",
      "duration               4521 non-null int64\n",
      "campaign               4521 non-null int64\n",
      "pdays                  4521 non-null int64\n",
      "previous               4521 non-null int64\n",
      "job_blue-collar        4521 non-null uint8\n",
      "job_entrepreneur       4521 non-null uint8\n",
      "job_housemaid          4521 non-null uint8\n",
      "job_management         4521 non-null uint8\n",
      "job_retired            4521 non-null uint8\n",
      "job_self-employed      4521 non-null uint8\n",
      "job_services           4521 non-null uint8\n",
      "job_student            4521 non-null uint8\n",
      "job_technician         4521 non-null uint8\n",
      "job_unemployed         4521 non-null uint8\n",
      "job_unknown            4521 non-null uint8\n",
      "marital_married        4521 non-null uint8\n",
      "marital_single         4521 non-null uint8\n",
      "education_secondary    4521 non-null uint8\n",
      "education_tertiary     4521 non-null uint8\n",
      "education_unknown      4521 non-null uint8\n",
      "default_yes            4521 non-null uint8\n",
      "loan_yes               4521 non-null uint8\n",
      "contact_telephone      4521 non-null uint8\n",
      "contact_unknown        4521 non-null uint8\n",
      "month_aug              4521 non-null uint8\n",
      "month_dec              4521 non-null uint8\n",
      "month_feb              4521 non-null uint8\n",
      "month_jan              4521 non-null uint8\n",
      "month_jul              4521 non-null uint8\n",
      "month_jun              4521 non-null uint8\n",
      "month_mar              4521 non-null uint8\n",
      "month_may              4521 non-null uint8\n",
      "month_nov              4521 non-null uint8\n",
      "month_oct              4521 non-null uint8\n",
      "month_sep              4521 non-null uint8\n",
      "poutcome_other         4521 non-null uint8\n",
      "poutcome_success       4521 non-null uint8\n",
      "poutcome_unknown       4521 non-null uint8\n",
      "Subscribed_yes         4521 non-null uint8\n",
      "dtypes: int64(7), uint8(35)\n",
      "memory usage: 401.8 KB\n"
     ]
    }
   ],
   "source": [
    "## Test Dataset\n",
    "###################\n",
    "# Covert all categorical variables to corresponding indicator variables\n",
    "for categoricalVar in categoricalVars:\n",
    "    tmpDf = pd.DataFrame()\n",
    "    # Remove 1st class level to avoid multicollinearity\n",
    "    tmpDf = pd.get_dummies(bankPromoAdditional_h_df[categoricalVar], prefix=categoricalVar, drop_first=True)\n",
    "    bankPromoAdditional_h_df = pd.concat((bankPromoAdditional_h_df, tmpDf), axis=1)\n",
    "\n",
    "# Now remove the original categorical vars since indicator variables are created from them.\n",
    "bankPromoAdditional_h_df.drop(categoricalVars, inplace=True, axis=1)\n",
    "\n",
    "if 'Target' in bankPromoAdditional_h_df:\n",
    "    y_Final = bankPromoAdditional_h_df['Target'].values # get the labels we want\n",
    "    del bankPromoAdditional_h_df['Target']        # get rid of the class label\n",
    "    X_Final = bankPromoAdditional_h_df.values\n",
    "\n",
    "print(\"Test dataset info\")\n",
    "print(\"=====================\")\n",
    "bankPromoAdditional_h_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Logistic Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.043045</td>\n",
       "      <td>0.114479</td>\n",
       "      <td>0.944613</td>\n",
       "      <td>0.744731</td>\n",
       "      <td>0.574598</td>\n",
       "      <td>0.816525</td>\n",
       "      <td>0.895179</td>\n",
       "      <td>0.735653</td>\n",
       "      <td>0.897026</td>\n",
       "      <td>0.745085</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>0.744378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.879607</td>\n",
       "      <td>0.109446</td>\n",
       "      <td>0.853853</td>\n",
       "      <td>0.751690</td>\n",
       "      <td>0.585186</td>\n",
       "      <td>0.824778</td>\n",
       "      <td>0.752931</td>\n",
       "      <td>0.745441</td>\n",
       "      <td>0.908155</td>\n",
       "      <td>0.759814</td>\n",
       "      <td>0.805679</td>\n",
       "      <td>0.743738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.886063</td>\n",
       "      <td>0.085486</td>\n",
       "      <td>0.500095</td>\n",
       "      <td>0.809572</td>\n",
       "      <td>0.627757</td>\n",
       "      <td>0.842206</td>\n",
       "      <td>0.418491</td>\n",
       "      <td>0.771369</td>\n",
       "      <td>0.343252</td>\n",
       "      <td>0.786251</td>\n",
       "      <td>0.920868</td>\n",
       "      <td>0.834318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.041555</td>\n",
       "      <td>0.093085</td>\n",
       "      <td>0.088985</td>\n",
       "      <td>0.800586</td>\n",
       "      <td>0.538851</td>\n",
       "      <td>0.849564</td>\n",
       "      <td>0.438399</td>\n",
       "      <td>0.779258</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.802225</td>\n",
       "      <td>0.048381</td>\n",
       "      <td>0.798954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.826891</td>\n",
       "      <td>0.100516</td>\n",
       "      <td>0.245696</td>\n",
       "      <td>0.792306</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.786773</td>\n",
       "      <td>0.748169</td>\n",
       "      <td>0.581481</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.155754</td>\n",
       "      <td>0.810256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.825351</td>\n",
       "      <td>0.095947</td>\n",
       "      <td>0.590136</td>\n",
       "      <td>0.786064</td>\n",
       "      <td>0.761794</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.685689</td>\n",
       "      <td>0.757483</td>\n",
       "      <td>0.719409</td>\n",
       "      <td>0.786815</td>\n",
       "      <td>0.500244</td>\n",
       "      <td>0.785315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.992232</td>\n",
       "      <td>0.097947</td>\n",
       "      <td>0.455639</td>\n",
       "      <td>0.792442</td>\n",
       "      <td>0.696512</td>\n",
       "      <td>0.838221</td>\n",
       "      <td>0.629507</td>\n",
       "      <td>0.761637</td>\n",
       "      <td>0.705231</td>\n",
       "      <td>0.781817</td>\n",
       "      <td>0.336534</td>\n",
       "      <td>0.803358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.823812</td>\n",
       "      <td>0.080319</td>\n",
       "      <td>0.878076</td>\n",
       "      <td>0.754189</td>\n",
       "      <td>0.772711</td>\n",
       "      <td>0.822239</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>0.742910</td>\n",
       "      <td>0.891286</td>\n",
       "      <td>0.762158</td>\n",
       "      <td>0.865252</td>\n",
       "      <td>0.746384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.818219</td>\n",
       "      <td>0.082956</td>\n",
       "      <td>0.900643</td>\n",
       "      <td>0.760999</td>\n",
       "      <td>0.843792</td>\n",
       "      <td>0.821425</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.741927</td>\n",
       "      <td>0.857376</td>\n",
       "      <td>0.755513</td>\n",
       "      <td>0.948509</td>\n",
       "      <td>0.766564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.037698</td>\n",
       "      <td>0.077663</td>\n",
       "      <td>0.377330</td>\n",
       "      <td>0.800729</td>\n",
       "      <td>0.646786</td>\n",
       "      <td>0.829804</td>\n",
       "      <td>0.630613</td>\n",
       "      <td>0.758270</td>\n",
       "      <td>0.292317</td>\n",
       "      <td>0.784798</td>\n",
       "      <td>0.532072</td>\n",
       "      <td>0.817321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  2.043045    0.114479       0.944613        0.744731  0.574598   0.816525   \n",
       "1  1.879607    0.109446       0.853853        0.751690  0.585186   0.824778   \n",
       "2  1.886063    0.085486       0.500095        0.809572  0.627757   0.842206   \n",
       "3  2.041555    0.093085       0.088985        0.800586  0.538851   0.849564   \n",
       "4  1.826891    0.100516       0.245696        0.792306  0.669041   0.821918   \n",
       "5  1.825351    0.095947       0.590136        0.786064  0.761794   0.834171   \n",
       "6  1.992232    0.097947       0.455639        0.792442  0.696512   0.838221   \n",
       "7  3.823812    0.080319       0.878076        0.754189  0.772711   0.822239   \n",
       "8  1.818219    0.082956       0.900643        0.760999  0.843792   0.821425   \n",
       "9  2.037698    0.077663       0.377330        0.800729  0.646786   0.829804   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.895179        0.735653        0.897026         0.745085   \n",
       "1       0.752931        0.745441        0.908155         0.759814   \n",
       "2       0.418491        0.771369        0.343252         0.786251   \n",
       "3       0.438399        0.779258        0.553571         0.802225   \n",
       "4       0.786773        0.748169        0.581481         0.775134   \n",
       "5       0.685689        0.757483        0.719409         0.786815   \n",
       "6       0.629507        0.761637        0.705231         0.781817   \n",
       "7       0.807122        0.742910        0.891286         0.762158   \n",
       "8       0.846273        0.741927        0.857376         0.755513   \n",
       "9       0.630613        0.758270        0.292317         0.784798   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.997532      0.744378  \n",
       "1     0.805679      0.743738  \n",
       "2     0.920868      0.834318  \n",
       "3     0.048381      0.798954  \n",
       "4     0.155754      0.810256  \n",
       "5     0.500244      0.785315  \n",
       "6     0.336534      0.803358  \n",
       "7     0.865252      0.746384  \n",
       "8     0.948509      0.766564  \n",
       "9     0.532072      0.817321  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           2.117447\n",
       "score_time         0.093784\n",
       "test_F1_Score      0.583507\n",
       "train_F1_Score     0.779331\n",
       "test_AUC           0.671703\n",
       "train_AUC          0.830085\n",
       "test_Accuracy      0.689098\n",
       "train_Accuracy     0.754212\n",
       "test_Precision     0.674911\n",
       "train_Precision    0.773961\n",
       "test_Recall        0.611083\n",
       "train_Recall       0.785059\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for Logistic Regression with Kfold cv object\n",
      "0:00:11.708129\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.184534</td>\n",
       "      <td>0.077950</td>\n",
       "      <td>0.775268</td>\n",
       "      <td>0.778855</td>\n",
       "      <td>0.827496</td>\n",
       "      <td>0.829789</td>\n",
       "      <td>0.749226</td>\n",
       "      <td>0.752316</td>\n",
       "      <td>0.772817</td>\n",
       "      <td>0.773054</td>\n",
       "      <td>0.777734</td>\n",
       "      <td>0.784745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.150011</td>\n",
       "      <td>0.124972</td>\n",
       "      <td>0.788132</td>\n",
       "      <td>0.777900</td>\n",
       "      <td>0.835867</td>\n",
       "      <td>0.828970</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.783452</td>\n",
       "      <td>0.771810</td>\n",
       "      <td>0.792869</td>\n",
       "      <td>0.784086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.131026</td>\n",
       "      <td>0.095480</td>\n",
       "      <td>0.781732</td>\n",
       "      <td>0.778234</td>\n",
       "      <td>0.838677</td>\n",
       "      <td>0.828603</td>\n",
       "      <td>0.755860</td>\n",
       "      <td>0.751505</td>\n",
       "      <td>0.779882</td>\n",
       "      <td>0.771818</td>\n",
       "      <td>0.783591</td>\n",
       "      <td>0.784757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.261994</td>\n",
       "      <td>0.120514</td>\n",
       "      <td>0.782011</td>\n",
       "      <td>0.778980</td>\n",
       "      <td>0.833092</td>\n",
       "      <td>0.829253</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.767836</td>\n",
       "      <td>0.772082</td>\n",
       "      <td>0.796719</td>\n",
       "      <td>0.786002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.388806</td>\n",
       "      <td>0.178146</td>\n",
       "      <td>0.787298</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.838794</td>\n",
       "      <td>0.828522</td>\n",
       "      <td>0.764485</td>\n",
       "      <td>0.750399</td>\n",
       "      <td>0.781833</td>\n",
       "      <td>0.770795</td>\n",
       "      <td>0.792840</td>\n",
       "      <td>0.784888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.307807</td>\n",
       "      <td>0.125958</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>0.777182</td>\n",
       "      <td>0.831703</td>\n",
       "      <td>0.829384</td>\n",
       "      <td>0.756966</td>\n",
       "      <td>0.750694</td>\n",
       "      <td>0.785601</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.779093</td>\n",
       "      <td>0.782961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.366782</td>\n",
       "      <td>0.121443</td>\n",
       "      <td>0.774514</td>\n",
       "      <td>0.778807</td>\n",
       "      <td>0.824350</td>\n",
       "      <td>0.830311</td>\n",
       "      <td>0.748784</td>\n",
       "      <td>0.751702</td>\n",
       "      <td>0.763302</td>\n",
       "      <td>0.772398</td>\n",
       "      <td>0.786060</td>\n",
       "      <td>0.785323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.418973</td>\n",
       "      <td>0.108017</td>\n",
       "      <td>0.784175</td>\n",
       "      <td>0.778494</td>\n",
       "      <td>0.830247</td>\n",
       "      <td>0.829594</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>0.751628</td>\n",
       "      <td>0.776270</td>\n",
       "      <td>0.771426</td>\n",
       "      <td>0.792244</td>\n",
       "      <td>0.785692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.478042</td>\n",
       "      <td>0.075487</td>\n",
       "      <td>0.768526</td>\n",
       "      <td>0.779463</td>\n",
       "      <td>0.823310</td>\n",
       "      <td>0.830286</td>\n",
       "      <td>0.743034</td>\n",
       "      <td>0.752759</td>\n",
       "      <td>0.761247</td>\n",
       "      <td>0.773899</td>\n",
       "      <td>0.775945</td>\n",
       "      <td>0.785109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.466558</td>\n",
       "      <td>0.056030</td>\n",
       "      <td>0.771485</td>\n",
       "      <td>0.779363</td>\n",
       "      <td>0.821751</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.744803</td>\n",
       "      <td>0.752587</td>\n",
       "      <td>0.762128</td>\n",
       "      <td>0.773346</td>\n",
       "      <td>0.781075</td>\n",
       "      <td>0.785474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  2.184534    0.077950       0.775268        0.778855  0.827496   0.829789   \n",
       "1  2.150011    0.124972       0.788132        0.777900  0.835867   0.828970   \n",
       "2  2.131026    0.095480       0.781732        0.778234  0.838677   0.828603   \n",
       "3  2.261994    0.120514       0.782011        0.778980  0.833092   0.829253   \n",
       "4  2.388806    0.178146       0.787298        0.777778  0.838794   0.828522   \n",
       "5  2.307807    0.125958       0.782333        0.777182  0.831703   0.829384   \n",
       "6  2.366782    0.121443       0.774514        0.778807  0.824350   0.830311   \n",
       "7  2.418973    0.108017       0.784175        0.778494  0.830247   0.829594   \n",
       "8  1.478042    0.075487       0.768526        0.779463  0.823310   0.830286   \n",
       "9  1.466558    0.056030       0.771485        0.779363  0.821751   0.830527   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.749226        0.752316        0.772817         0.773054   \n",
       "1       0.764706        0.750940        0.783452         0.771810   \n",
       "2       0.755860        0.751505        0.779882         0.771818   \n",
       "3       0.754533        0.751923        0.767836         0.772082   \n",
       "4       0.764485        0.750399        0.781833         0.770795   \n",
       "5       0.756966        0.750694        0.785601         0.771488   \n",
       "6       0.748784        0.751702        0.763302         0.772398   \n",
       "7       0.756303        0.751628        0.776270         0.771426   \n",
       "8       0.743034        0.752759        0.761247         0.773899   \n",
       "9       0.744803        0.752587        0.762128         0.773346   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.777734      0.784745  \n",
       "1     0.792869      0.784086  \n",
       "2     0.783591      0.784757  \n",
       "3     0.796719      0.786002  \n",
       "4     0.792840      0.784888  \n",
       "5     0.779093      0.782961  \n",
       "6     0.786060      0.785323  \n",
       "7     0.792244      0.785692  \n",
       "8     0.775945      0.785109  \n",
       "9     0.781075      0.785474  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           2.115453\n",
       "score_time         0.108400\n",
       "test_F1_Score      0.779547\n",
       "train_F1_Score     0.778506\n",
       "test_AUC           0.830529\n",
       "train_AUC          0.829524\n",
       "test_Accuracy      0.753870\n",
       "train_Accuracy     0.751645\n",
       "test_Precision     0.773437\n",
       "train_Precision    0.772212\n",
       "test_Recall        0.785817\n",
       "train_Recall       0.784904\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for Logistic Regression with Shuffle cv object\n",
      "0:00:07.977410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from sklearn import metrics as mt\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel = make_pipeline(StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores_kfold = cross_validate(logisticModel , X, y=y , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores_kfold))\n",
    "display(pd.DataFrame(scores_kfold).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Kfold cv object\")\n",
    "print(end-start)\n",
    "print()\n",
    "\n",
    "start = datetime.now()\n",
    "scores_shuffle = cross_validate(logisticModel , X, y=y , cv = shuffle_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores_shuffle))\n",
    "display(pd.DataFrame(scores_shuffle).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Shuffle cv object\")\n",
    "print(end-start)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running poylnomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>696.325340</td>\n",
       "      <td>2.765477</td>\n",
       "      <td>0.945170</td>\n",
       "      <td>0.785199</td>\n",
       "      <td>0.601824</td>\n",
       "      <td>0.855696</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.776721</td>\n",
       "      <td>0.896239</td>\n",
       "      <td>0.782627</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.787788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>565.157112</td>\n",
       "      <td>2.596520</td>\n",
       "      <td>0.819712</td>\n",
       "      <td>0.787748</td>\n",
       "      <td>0.592195</td>\n",
       "      <td>0.860283</td>\n",
       "      <td>0.706260</td>\n",
       "      <td>0.781666</td>\n",
       "      <td>0.910434</td>\n",
       "      <td>0.793512</td>\n",
       "      <td>0.745432</td>\n",
       "      <td>0.782068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>646.139728</td>\n",
       "      <td>2.634551</td>\n",
       "      <td>0.496214</td>\n",
       "      <td>0.832336</td>\n",
       "      <td>0.632943</td>\n",
       "      <td>0.871197</td>\n",
       "      <td>0.440832</td>\n",
       "      <td>0.800909</td>\n",
       "      <td>0.346797</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>0.871849</td>\n",
       "      <td>0.848367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>601.435450</td>\n",
       "      <td>2.529556</td>\n",
       "      <td>0.464406</td>\n",
       "      <td>0.822294</td>\n",
       "      <td>0.631675</td>\n",
       "      <td>0.875659</td>\n",
       "      <td>0.542358</td>\n",
       "      <td>0.802925</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.822458</td>\n",
       "      <td>0.349980</td>\n",
       "      <td>0.822130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>546.226694</td>\n",
       "      <td>2.693989</td>\n",
       "      <td>0.348553</td>\n",
       "      <td>0.825839</td>\n",
       "      <td>0.676370</td>\n",
       "      <td>0.860427</td>\n",
       "      <td>0.775935</td>\n",
       "      <td>0.788105</td>\n",
       "      <td>0.495430</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.268849</td>\n",
       "      <td>0.847442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>643.732224</td>\n",
       "      <td>2.031840</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.820816</td>\n",
       "      <td>0.759851</td>\n",
       "      <td>0.869019</td>\n",
       "      <td>0.686574</td>\n",
       "      <td>0.795134</td>\n",
       "      <td>0.683841</td>\n",
       "      <td>0.814652</td>\n",
       "      <td>0.571149</td>\n",
       "      <td>0.827074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>611.188166</td>\n",
       "      <td>2.688979</td>\n",
       "      <td>0.534449</td>\n",
       "      <td>0.825147</td>\n",
       "      <td>0.666164</td>\n",
       "      <td>0.871099</td>\n",
       "      <td>0.630834</td>\n",
       "      <td>0.798353</td>\n",
       "      <td>0.637816</td>\n",
       "      <td>0.810788</td>\n",
       "      <td>0.459914</td>\n",
       "      <td>0.840023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>688.180470</td>\n",
       "      <td>1.603086</td>\n",
       "      <td>0.839953</td>\n",
       "      <td>0.791889</td>\n",
       "      <td>0.771620</td>\n",
       "      <td>0.857495</td>\n",
       "      <td>0.759345</td>\n",
       "      <td>0.779037</td>\n",
       "      <td>0.900915</td>\n",
       "      <td>0.788222</td>\n",
       "      <td>0.786718</td>\n",
       "      <td>0.795591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>471.425449</td>\n",
       "      <td>1.358225</td>\n",
       "      <td>0.884973</td>\n",
       "      <td>0.797228</td>\n",
       "      <td>0.830222</td>\n",
       "      <td>0.858635</td>\n",
       "      <td>0.819509</td>\n",
       "      <td>0.780708</td>\n",
       "      <td>0.831964</td>\n",
       "      <td>0.790278</td>\n",
       "      <td>0.945197</td>\n",
       "      <td>0.804301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>423.629601</td>\n",
       "      <td>0.783531</td>\n",
       "      <td>0.368894</td>\n",
       "      <td>0.828717</td>\n",
       "      <td>0.622348</td>\n",
       "      <td>0.863413</td>\n",
       "      <td>0.642778</td>\n",
       "      <td>0.792848</td>\n",
       "      <td>0.293532</td>\n",
       "      <td>0.814597</td>\n",
       "      <td>0.496320</td>\n",
       "      <td>0.843335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  696.325340    2.765477       0.945170        0.785199  0.601824   0.855696   \n",
       "1  565.157112    2.596520       0.819712        0.787748  0.592195   0.860283   \n",
       "2  646.139728    2.634551       0.496214        0.832336  0.632943   0.871197   \n",
       "3  601.435450    2.529556       0.464406        0.822294  0.631675   0.875659   \n",
       "4  546.226694    2.693989       0.348553        0.825839  0.676370   0.860427   \n",
       "5  643.732224    2.031840       0.622435        0.820816  0.759851   0.869019   \n",
       "6  611.188166    2.688979       0.534449        0.825147  0.666164   0.871099   \n",
       "7  688.180470    1.603086       0.839953        0.791889  0.771620   0.857495   \n",
       "8  471.425449    1.358225       0.884973        0.797228  0.830222   0.858635   \n",
       "9  423.629601    0.783531       0.368894        0.828717  0.622348   0.863413   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.896064        0.776721        0.896239         0.782627   \n",
       "1       0.706260        0.781666        0.910434         0.793512   \n",
       "2       0.440832        0.800909        0.346797         0.816900   \n",
       "3       0.542358        0.802925        0.690000         0.822458   \n",
       "4       0.775935        0.788105        0.495430         0.805310   \n",
       "5       0.686574        0.795134        0.683841         0.814652   \n",
       "6       0.630834        0.798353        0.637816         0.810788   \n",
       "7       0.759345        0.779037        0.900915         0.788222   \n",
       "8       0.819509        0.780708        0.831964         0.790278   \n",
       "9       0.642778        0.792848        0.293532         0.814597   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.999753      0.787788  \n",
       "1     0.745432      0.782068  \n",
       "2     0.871849      0.848367  \n",
       "3     0.349980      0.822130  \n",
       "4     0.268849      0.847442  \n",
       "5     0.571149      0.827074  \n",
       "6     0.459914      0.840023  \n",
       "7     0.786718      0.795591  \n",
       "8     0.945197      0.804301  \n",
       "9     0.496320      0.843335  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           589.344023\n",
       "score_time           2.168575\n",
       "test_F1_Score        0.632476\n",
       "train_F1_Score       0.811721\n",
       "test_AUC             0.678521\n",
       "train_AUC            0.864292\n",
       "test_Accuracy        0.690049\n",
       "train_Accuracy       0.789641\n",
       "test_Precision       0.668697\n",
       "train_Precision      0.803934\n",
       "test_Recall          0.649516\n",
       "train_Recall         0.819812\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for Logistic Regression with Kfold cv object\n",
      "0:29:05.146339\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>599.361578</td>\n",
       "      <td>2.512565</td>\n",
       "      <td>0.800315</td>\n",
       "      <td>0.812515</td>\n",
       "      <td>0.851785</td>\n",
       "      <td>0.864261</td>\n",
       "      <td>0.775763</td>\n",
       "      <td>0.788960</td>\n",
       "      <td>0.792821</td>\n",
       "      <td>0.802510</td>\n",
       "      <td>0.807952</td>\n",
       "      <td>0.822772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>613.813326</td>\n",
       "      <td>2.223731</td>\n",
       "      <td>0.808485</td>\n",
       "      <td>0.811089</td>\n",
       "      <td>0.859143</td>\n",
       "      <td>0.863162</td>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.786969</td>\n",
       "      <td>0.800235</td>\n",
       "      <td>0.800344</td>\n",
       "      <td>0.816907</td>\n",
       "      <td>0.822126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>719.080238</td>\n",
       "      <td>2.477588</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.810918</td>\n",
       "      <td>0.862007</td>\n",
       "      <td>0.862917</td>\n",
       "      <td>0.787705</td>\n",
       "      <td>0.787363</td>\n",
       "      <td>0.803260</td>\n",
       "      <td>0.801391</td>\n",
       "      <td>0.820452</td>\n",
       "      <td>0.820675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>631.250372</td>\n",
       "      <td>2.141786</td>\n",
       "      <td>0.810588</td>\n",
       "      <td>0.812057</td>\n",
       "      <td>0.855950</td>\n",
       "      <td>0.863685</td>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.788075</td>\n",
       "      <td>0.794694</td>\n",
       "      <td>0.801247</td>\n",
       "      <td>0.827131</td>\n",
       "      <td>0.823163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410.447711</td>\n",
       "      <td>2.488578</td>\n",
       "      <td>0.811047</td>\n",
       "      <td>0.811267</td>\n",
       "      <td>0.863257</td>\n",
       "      <td>0.862834</td>\n",
       "      <td>0.789695</td>\n",
       "      <td>0.787240</td>\n",
       "      <td>0.801335</td>\n",
       "      <td>0.801119</td>\n",
       "      <td>0.820998</td>\n",
       "      <td>0.821675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>639.324061</td>\n",
       "      <td>2.574531</td>\n",
       "      <td>0.801990</td>\n",
       "      <td>0.810330</td>\n",
       "      <td>0.851309</td>\n",
       "      <td>0.864012</td>\n",
       "      <td>0.779965</td>\n",
       "      <td>0.786650</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.800207</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.820713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>685.550675</td>\n",
       "      <td>2.823392</td>\n",
       "      <td>0.804493</td>\n",
       "      <td>0.812186</td>\n",
       "      <td>0.849843</td>\n",
       "      <td>0.864287</td>\n",
       "      <td>0.780628</td>\n",
       "      <td>0.788493</td>\n",
       "      <td>0.787423</td>\n",
       "      <td>0.802969</td>\n",
       "      <td>0.822321</td>\n",
       "      <td>0.821618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>706.072124</td>\n",
       "      <td>2.130784</td>\n",
       "      <td>0.795762</td>\n",
       "      <td>0.812512</td>\n",
       "      <td>0.848338</td>\n",
       "      <td>0.864507</td>\n",
       "      <td>0.769792</td>\n",
       "      <td>0.788911</td>\n",
       "      <td>0.789105</td>\n",
       "      <td>0.801922</td>\n",
       "      <td>0.802533</td>\n",
       "      <td>0.823386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>554.663549</td>\n",
       "      <td>1.456168</td>\n",
       "      <td>0.799127</td>\n",
       "      <td>0.812253</td>\n",
       "      <td>0.846864</td>\n",
       "      <td>0.864569</td>\n",
       "      <td>0.776205</td>\n",
       "      <td>0.788665</td>\n",
       "      <td>0.788793</td>\n",
       "      <td>0.803256</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.821454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>413.419742</td>\n",
       "      <td>0.938464</td>\n",
       "      <td>0.798974</td>\n",
       "      <td>0.813192</td>\n",
       "      <td>0.846567</td>\n",
       "      <td>0.864553</td>\n",
       "      <td>0.774657</td>\n",
       "      <td>0.789378</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.802625</td>\n",
       "      <td>0.811949</td>\n",
       "      <td>0.824041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  599.361578    2.512565       0.800315        0.812515  0.851785   0.864261   \n",
       "1  613.813326    2.223731       0.808485        0.811089  0.859143   0.863162   \n",
       "2  719.080238    2.477588       0.811765        0.810918  0.862007   0.862917   \n",
       "3  631.250372    2.141786       0.810588        0.812057  0.855950   0.863685   \n",
       "4  410.447711    2.488578       0.811047        0.811267  0.863257   0.862834   \n",
       "5  639.324061    2.574531       0.801990        0.810330  0.851309   0.864012   \n",
       "6  685.550675    2.823392       0.804493        0.812186  0.849843   0.864287   \n",
       "7  706.072124    2.130784       0.795762        0.812512  0.848338   0.864507   \n",
       "8  554.663549    1.456168       0.799127        0.812253  0.846864   0.864569   \n",
       "9  413.419742    0.938464       0.798974        0.813192  0.846567   0.864553   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.775763        0.788960        0.792821         0.802510   \n",
       "1       0.786378        0.786969        0.800235         0.800344   \n",
       "2       0.787705        0.787363        0.803260         0.801391   \n",
       "3       0.786378        0.788075        0.794694         0.801247   \n",
       "4       0.789695        0.787240        0.801335         0.801119   \n",
       "5       0.779965        0.786650        0.809237         0.800207   \n",
       "6       0.780628        0.788493        0.787423         0.802969   \n",
       "7       0.769792        0.788911        0.789105         0.801922   \n",
       "8       0.776205        0.788665        0.788793         0.803256   \n",
       "9       0.774657        0.789378        0.786408         0.802625   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.807952      0.822772  \n",
       "1     0.816907      0.822126  \n",
       "2     0.820452      0.820675  \n",
       "3     0.827131      0.823163  \n",
       "4     0.820998      0.821675  \n",
       "5     0.794872      0.820713  \n",
       "6     0.822321      0.821618  \n",
       "7     0.802533      0.823386  \n",
       "8     0.809735      0.821454  \n",
       "9     0.811949      0.824041  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           597.298337\n",
       "score_time           2.176759\n",
       "test_F1_Score        0.804255\n",
       "train_F1_Score       0.811832\n",
       "test_AUC             0.853506\n",
       "train_AUC            0.863879\n",
       "test_Accuracy        0.780716\n",
       "train_Accuracy       0.788070\n",
       "test_Precision       0.795331\n",
       "train_Precision      0.801759\n",
       "test_Recall          0.813485\n",
       "train_Recall         0.822162\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for Logistic Regression with Shuffle cv object\n",
      "0:28:53.219431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel2 = make_pipeline(PolynomialFeatures(degree=2), StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores_kfold2 = cross_validate(logisticModel2 , X, y=y , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores_kfold2))\n",
    "display(pd.DataFrame(scores_kfold2).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Kfold cv object\")\n",
    "print(end-start)\n",
    "print()\n",
    "\n",
    "start = datetime.now()\n",
    "scores_shuffle2 = cross_validate(logisticModel2 , X, y=y , cv = shuffle_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores_shuffle2))\n",
    "display(pd.DataFrame(scores_shuffle2).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Shuffle cv object\")\n",
    "print(end-start)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "## polynomial of degree 3\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel3 = make_pipeline(PolynomialFeatures(degree=3), StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores_kfold3 = cross_validate(logisticModel3 , X, y=y , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores_kfold3))\n",
    "display(pd.DataFrame(scores_kfold3).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Kfold cv object\")\n",
    "print(end-start)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fir the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month_aug has weight of -0.8218055880934713\n",
      "month_jun has weight of -0.5133078366224679\n",
      "age has weight of -0.34770575197344655\n",
      "month_jul has weight of -0.33219653576913705\n",
      "month_feb has weight of -0.30401987123143503\n",
      "job_student has weight of -0.2298849457383366\n",
      "month_jan has weight of -0.22251032200338852\n",
      "month_sep has weight of -0.21537644820959612\n",
      "month_oct has weight of -0.21508786998788285\n",
      "Subscribed_yes has weight of -0.21214732837628966\n",
      "marital_single has weight of -0.20485834964766605\n",
      "job_retired has weight of -0.20184179660375864\n",
      "job_unknown has weight of -0.17482566966737745\n",
      "month_mar has weight of -0.16929127133360752\n",
      "month_nov has weight of -0.1548033384929472\n",
      "month_dec has weight of -0.13777989156208167\n",
      "poutcome_success has weight of -0.12940030098315464\n",
      "day has weight of -0.11748156842113988\n",
      "job_housemaid has weight of -0.10266310732500522\n",
      "job_unemployed has weight of -0.0914933371853685\n",
      "contact_telephone has weight of -0.06990775131880754\n",
      "education_unknown has weight of -0.06908889225349335\n",
      "balance has weight of -0.06160846607376792\n",
      "job_self-employed has weight of -0.05478816511057268\n",
      "default_yes has weight of -0.03866118123443981\n",
      "poutcome_other has weight of -0.03355139251796191\n",
      "job_management has weight of -0.022941418672475247\n",
      "education_tertiary has weight of -0.017756816488902896\n",
      "job_entrepreneur has weight of -0.006165283082501696\n",
      "poutcome_unknown has weight of 0.0\n",
      "marital_married has weight of 0.0041355680086494935\n",
      "loan_yes has weight of 0.01581283932897791\n",
      "job_technician has weight of 0.016666225844844076\n",
      "job_services has weight of 0.02849243722019241\n",
      "education_secondary has weight of 0.03800683810887228\n",
      "previous has weight of 0.04202665532912485\n",
      "duration has weight of 0.07694250335968696\n",
      "campaign has weight of 0.11315624060102945\n",
      "job_blue-collar has weight of 0.12915086527664046\n",
      "contact_unknown has weight of 0.20524849208746798\n",
      "pdays has weight of 0.3212502833060009\n",
      "month_may has weight of 0.34290313815923523\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning The Model Hyper Paramters Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'logisticregression__C': 75.43120063354607, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "     'logisticregression__penalty' : ['l1', 'l2'],\n",
    "    'logisticregression__C' : np.logspace(-4, 4, 50),\n",
    "    'logisticregression__solver' : ['liblinear']\n",
    "   }\n",
    "\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "grid = GridSearchCV(make_pipeline(StandardScaler(), LogisticRegression(random_state=999, class_weight=None)), \\\n",
    "                   param_grid = param_grid, cv = kfold_cv_object , verbose=False, n_jobs=-1, scoring=scoring, refit='Accuracy', \\\n",
    "                   return_train_score=True)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "grid.fit(X, y=y)\n",
    "  \n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'logisticregression__C': 0.0020235896477251557, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'} with a score of 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "     'logisticregression__penalty' : ['l1', 'l2'],\n",
    "    'logisticregression__C' : np.logspace(-4, 4, 50),\n",
    "    'logisticregression__solver' : ['liblinear']\n",
    "   }\n",
    "\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "grid = GridSearchCV(make_pipeline(StandardScaler(), LogisticRegression(random_state=999, class_weight=None)), \\\n",
    "                   param_grid = param_grid, cv = shuffle_cv_object , verbose=False, n_jobs=-1, scoring=scoring, refit='Accuracy', \\\n",
    "                   return_train_score=True)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "grid.fit(X, y=y)\n",
    "  \n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection based on pearson coeff and Chi-Sq2 tests and top 18 imp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'pdays']\n",
      "['job', 'education', 'loan', 'contact', 'month', 'poutcome', 'Subscribed']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 35 columns):\n",
      "age                    45211 non-null int64\n",
      "pdays                  45211 non-null int64\n",
      "Target                 45211 non-null int32\n",
      "job_blue-collar        45211 non-null uint8\n",
      "job_entrepreneur       45211 non-null uint8\n",
      "job_housemaid          45211 non-null uint8\n",
      "job_management         45211 non-null uint8\n",
      "job_retired            45211 non-null uint8\n",
      "job_self-employed      45211 non-null uint8\n",
      "job_services           45211 non-null uint8\n",
      "job_student            45211 non-null uint8\n",
      "job_technician         45211 non-null uint8\n",
      "job_unemployed         45211 non-null uint8\n",
      "job_unknown            45211 non-null uint8\n",
      "education_secondary    45211 non-null uint8\n",
      "education_tertiary     45211 non-null uint8\n",
      "education_unknown      45211 non-null uint8\n",
      "loan_yes               45211 non-null uint8\n",
      "contact_telephone      45211 non-null uint8\n",
      "contact_unknown        45211 non-null uint8\n",
      "month_aug              45211 non-null uint8\n",
      "month_dec              45211 non-null uint8\n",
      "month_feb              45211 non-null uint8\n",
      "month_jan              45211 non-null uint8\n",
      "month_jul              45211 non-null uint8\n",
      "month_jun              45211 non-null uint8\n",
      "month_mar              45211 non-null uint8\n",
      "month_may              45211 non-null uint8\n",
      "month_nov              45211 non-null uint8\n",
      "month_oct              45211 non-null uint8\n",
      "month_sep              45211 non-null uint8\n",
      "poutcome_other         45211 non-null uint8\n",
      "poutcome_success       45211 non-null uint8\n",
      "poutcome_unknown       45211 non-null uint8\n",
      "Subscribed_yes         45211 non-null uint8\n",
      "dtypes: int32(1), int64(2), uint8(32)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "# create dataframes on selected features\n",
    "## based on 2 methods 18 features\n",
    "bankPromoModel_hsng218_Df = bankPromo_df.copy()\n",
    "bankPromoModel_hsng218_Df['Target'] = bankPromoModel_hsng218_Df['housing'].apply(lambda resp : 1 if resp == \"yes\" else 0)\n",
    "bankPromoModel_hsng218_Df['Target'] = bankPromoModel_hsng218_Df['Target'].astype(np.int)\n",
    "\n",
    "# Delete the original 'housing' column\n",
    "del bankPromoModel_hsng218_Df['housing']\n",
    "del bankPromoModel_hsng218_Df['default']\n",
    "del bankPromoModel_hsng218_Df['previous']\n",
    "del bankPromoModel_hsng218_Df['marital']\n",
    "del bankPromoModel_hsng218_Df['duration']\n",
    "del bankPromoModel_hsng218_Df['day']\n",
    "del bankPromoModel_hsng218_Df['campaign']\n",
    "del bankPromoModel_hsng218_Df['balance']\n",
    "\n",
    "\n",
    "# Get the unique values(Levels) for categorical variables.\n",
    "# List to hold names of categorical variables\n",
    "categoricalVars218 = list()\n",
    "# List to hold names of numerical variables\n",
    "numericalVars218 = list()\n",
    "\n",
    "for colName in bankPromoModel_hsng218_Df.columns:\n",
    "    if bankPromoModel_hsng218_Df[colName].dtype == np.int64:\n",
    "        numericalVars218.append(colName)\n",
    "    elif bankPromoModel_hsng218_Df[colName].dtype == np.object:\n",
    "        categoricalVars218.append(colName)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# Remove Target column from final categorical Var list\n",
    "#categoricalVars618.remove('Target')\n",
    "\n",
    "print(numericalVars218)\n",
    "print(categoricalVars218)\n",
    "\n",
    "# Convert all categorical variables to corresponding indicator variables\n",
    "for categoricalVar in categoricalVars218:\n",
    "    tmpDf = pd.DataFrame()\n",
    "    # Remove 1st class level to avoid multicollinearity\n",
    "    tmpDf = pd.get_dummies(bankPromoModel_hsng218_Df[categoricalVar], prefix=categoricalVar, drop_first=True)\n",
    "    bankPromoModel_hsng218_Df = pd.concat((bankPromoModel_hsng218_Df, tmpDf), axis=1)\n",
    "\n",
    "# Now remove the original categorical vars since indicator variables are created from them.\n",
    "bankPromoModel_hsng218_Df.drop(categoricalVars218, inplace=True, axis=1)\n",
    "bankPromoModel_hsng218_Df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create 10 Splits Stratified Cross Validation Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Test Split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "if 'Target' in bankPromoModel_hsng218_Df:\n",
    "    y218 = bankPromoModel_hsng218_Df['Target'].values # get the labels we want\n",
    "    del bankPromoModel_hsng218_Df['Target']        # get rid of the class label\n",
    "    X218 = bankPromoModel_hsng218_Df.values           # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.550702</td>\n",
       "      <td>0.085951</td>\n",
       "      <td>0.944477</td>\n",
       "      <td>0.739109</td>\n",
       "      <td>0.578961</td>\n",
       "      <td>0.810300</td>\n",
       "      <td>0.894958</td>\n",
       "      <td>0.729042</td>\n",
       "      <td>0.897180</td>\n",
       "      <td>0.737312</td>\n",
       "      <td>0.997038</td>\n",
       "      <td>0.740915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.441770</td>\n",
       "      <td>0.096944</td>\n",
       "      <td>0.842384</td>\n",
       "      <td>0.745253</td>\n",
       "      <td>0.595578</td>\n",
       "      <td>0.819401</td>\n",
       "      <td>0.736784</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>0.908571</td>\n",
       "      <td>0.751471</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.739137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.300789</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.489116</td>\n",
       "      <td>0.805937</td>\n",
       "      <td>0.617726</td>\n",
       "      <td>0.837935</td>\n",
       "      <td>0.403008</td>\n",
       "      <td>0.765421</td>\n",
       "      <td>0.335149</td>\n",
       "      <td>0.777773</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.836216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.440767</td>\n",
       "      <td>0.099941</td>\n",
       "      <td>0.075350</td>\n",
       "      <td>0.793940</td>\n",
       "      <td>0.513998</td>\n",
       "      <td>0.845366</td>\n",
       "      <td>0.429993</td>\n",
       "      <td>0.772352</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.797150</td>\n",
       "      <td>0.040968</td>\n",
       "      <td>0.790756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.331774</td>\n",
       "      <td>0.088950</td>\n",
       "      <td>0.268366</td>\n",
       "      <td>0.787144</td>\n",
       "      <td>0.664718</td>\n",
       "      <td>0.815946</td>\n",
       "      <td>0.784119</td>\n",
       "      <td>0.741214</td>\n",
       "      <td>0.549080</td>\n",
       "      <td>0.768108</td>\n",
       "      <td>0.177579</td>\n",
       "      <td>0.807147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.199850</td>\n",
       "      <td>0.074965</td>\n",
       "      <td>0.584096</td>\n",
       "      <td>0.781361</td>\n",
       "      <td>0.764440</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.678390</td>\n",
       "      <td>0.751389</td>\n",
       "      <td>0.703653</td>\n",
       "      <td>0.779709</td>\n",
       "      <td>0.499267</td>\n",
       "      <td>0.783019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.121871</td>\n",
       "      <td>0.094946</td>\n",
       "      <td>0.409184</td>\n",
       "      <td>0.788911</td>\n",
       "      <td>0.691436</td>\n",
       "      <td>0.833053</td>\n",
       "      <td>0.618668</td>\n",
       "      <td>0.756550</td>\n",
       "      <td>0.714970</td>\n",
       "      <td>0.775135</td>\n",
       "      <td>0.286606</td>\n",
       "      <td>0.803185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.972302</td>\n",
       "      <td>0.048973</td>\n",
       "      <td>0.888950</td>\n",
       "      <td>0.749460</td>\n",
       "      <td>0.773183</td>\n",
       "      <td>0.816797</td>\n",
       "      <td>0.820173</td>\n",
       "      <td>0.737626</td>\n",
       "      <td>0.881365</td>\n",
       "      <td>0.756383</td>\n",
       "      <td>0.896666</td>\n",
       "      <td>0.742663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.020419</td>\n",
       "      <td>0.064963</td>\n",
       "      <td>0.897564</td>\n",
       "      <td>0.756787</td>\n",
       "      <td>0.833758</td>\n",
       "      <td>0.816321</td>\n",
       "      <td>0.840964</td>\n",
       "      <td>0.736471</td>\n",
       "      <td>0.851812</td>\n",
       "      <td>0.748788</td>\n",
       "      <td>0.948509</td>\n",
       "      <td>0.764959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.177328</td>\n",
       "      <td>0.067977</td>\n",
       "      <td>0.370974</td>\n",
       "      <td>0.795416</td>\n",
       "      <td>0.644534</td>\n",
       "      <td>0.824746</td>\n",
       "      <td>0.624198</td>\n",
       "      <td>0.751241</td>\n",
       "      <td>0.286286</td>\n",
       "      <td>0.777839</td>\n",
       "      <td>0.526814</td>\n",
       "      <td>0.813805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  1.550702    0.085951       0.944477        0.739109  0.578961   0.810300   \n",
       "1  1.441770    0.096944       0.842384        0.745253  0.595578   0.819401   \n",
       "2  1.300789    0.088983       0.489116        0.805937  0.617726   0.837935   \n",
       "3  1.440767    0.099941       0.075350        0.793940  0.513998   0.845366   \n",
       "4  1.331774    0.088950       0.268366        0.787144  0.664718   0.815946   \n",
       "5  1.199850    0.074965       0.584096        0.781361  0.764440   0.828571   \n",
       "6  1.121871    0.094946       0.409184        0.788911  0.691436   0.833053   \n",
       "7  2.972302    0.048973       0.888950        0.749460  0.773183   0.816797   \n",
       "8  1.020419    0.064963       0.897564        0.756787  0.833758   0.816321   \n",
       "9  1.177328    0.067977       0.370974        0.795416  0.644534   0.824746   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.894958        0.729042        0.897180         0.737312   \n",
       "1       0.736784        0.738216        0.908571         0.751471   \n",
       "2       0.403008        0.765421        0.335149         0.777773   \n",
       "3       0.429993        0.772352        0.468750         0.797150   \n",
       "4       0.784119        0.741214        0.549080         0.768108   \n",
       "5       0.678390        0.751389        0.703653         0.779709   \n",
       "6       0.618668        0.756550        0.714970         0.775135   \n",
       "7       0.820173        0.737626        0.881365         0.756383   \n",
       "8       0.840964        0.736471        0.851812         0.748788   \n",
       "9       0.624198        0.751241        0.286286         0.777839   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.997038      0.740915  \n",
       "1     0.785185      0.739137  \n",
       "2     0.904762      0.836216  \n",
       "3     0.040968      0.790756  \n",
       "4     0.177579      0.807147  \n",
       "5     0.499267      0.783019  \n",
       "6     0.286606      0.803185  \n",
       "7     0.896666      0.742663  \n",
       "8     0.948509      0.764959  \n",
       "9     0.526814      0.813805  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           1.455757\n",
       "score_time         0.081259\n",
       "test_F1_Score      0.577046\n",
       "train_F1_Score     0.774332\n",
       "test_AUC           0.667833\n",
       "train_AUC          0.824844\n",
       "test_Accuracy      0.683126\n",
       "train_Accuracy     0.747952\n",
       "test_Precision     0.659682\n",
       "train_Precision    0.766967\n",
       "test_Recall        0.606339\n",
       "train_Recall       0.782180\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for Logistic Regression with Kfold cv object\n",
      "0:00:10.290283\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.683035</td>\n",
       "      <td>0.091948</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.773085</td>\n",
       "      <td>0.822790</td>\n",
       "      <td>0.824528</td>\n",
       "      <td>0.747015</td>\n",
       "      <td>0.745140</td>\n",
       "      <td>0.767043</td>\n",
       "      <td>0.765216</td>\n",
       "      <td>0.782903</td>\n",
       "      <td>0.781119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.558111</td>\n",
       "      <td>0.100942</td>\n",
       "      <td>0.775144</td>\n",
       "      <td>0.773766</td>\n",
       "      <td>0.829510</td>\n",
       "      <td>0.823909</td>\n",
       "      <td>0.750332</td>\n",
       "      <td>0.745582</td>\n",
       "      <td>0.770693</td>\n",
       "      <td>0.765568</td>\n",
       "      <td>0.779647</td>\n",
       "      <td>0.782142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.660052</td>\n",
       "      <td>0.107941</td>\n",
       "      <td>0.779394</td>\n",
       "      <td>0.773131</td>\n",
       "      <td>0.834068</td>\n",
       "      <td>0.823295</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.745091</td>\n",
       "      <td>0.773313</td>\n",
       "      <td>0.764701</td>\n",
       "      <td>0.785573</td>\n",
       "      <td>0.781749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.748003</td>\n",
       "      <td>0.176416</td>\n",
       "      <td>0.777734</td>\n",
       "      <td>0.773685</td>\n",
       "      <td>0.827675</td>\n",
       "      <td>0.824061</td>\n",
       "      <td>0.750111</td>\n",
       "      <td>0.745263</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.764719</td>\n",
       "      <td>0.791116</td>\n",
       "      <td>0.782864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.606099</td>\n",
       "      <td>0.103942</td>\n",
       "      <td>0.778264</td>\n",
       "      <td>0.773096</td>\n",
       "      <td>0.832877</td>\n",
       "      <td>0.823397</td>\n",
       "      <td>0.753649</td>\n",
       "      <td>0.744550</td>\n",
       "      <td>0.770292</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>0.781973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.491657</td>\n",
       "      <td>0.107939</td>\n",
       "      <td>0.775050</td>\n",
       "      <td>0.773234</td>\n",
       "      <td>0.824467</td>\n",
       "      <td>0.824407</td>\n",
       "      <td>0.748784</td>\n",
       "      <td>0.745312</td>\n",
       "      <td>0.778131</td>\n",
       "      <td>0.764716</td>\n",
       "      <td>0.771992</td>\n",
       "      <td>0.781943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.512645</td>\n",
       "      <td>0.086950</td>\n",
       "      <td>0.772781</td>\n",
       "      <td>0.773454</td>\n",
       "      <td>0.819409</td>\n",
       "      <td>0.825066</td>\n",
       "      <td>0.745245</td>\n",
       "      <td>0.745042</td>\n",
       "      <td>0.756955</td>\n",
       "      <td>0.765166</td>\n",
       "      <td>0.789283</td>\n",
       "      <td>0.781923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.498651</td>\n",
       "      <td>0.079954</td>\n",
       "      <td>0.773307</td>\n",
       "      <td>0.774222</td>\n",
       "      <td>0.824163</td>\n",
       "      <td>0.824513</td>\n",
       "      <td>0.744582</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.767134</td>\n",
       "      <td>0.764716</td>\n",
       "      <td>0.779581</td>\n",
       "      <td>0.783967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.853510</td>\n",
       "      <td>0.049978</td>\n",
       "      <td>0.766169</td>\n",
       "      <td>0.774012</td>\n",
       "      <td>0.819647</td>\n",
       "      <td>0.824888</td>\n",
       "      <td>0.740159</td>\n",
       "      <td>0.746025</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.766635</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.781532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.767156</td>\n",
       "      <td>0.774154</td>\n",
       "      <td>0.816886</td>\n",
       "      <td>0.825277</td>\n",
       "      <td>0.740380</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.759027</td>\n",
       "      <td>0.765674</td>\n",
       "      <td>0.775461</td>\n",
       "      <td>0.782824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  1.683035    0.091948       0.774892        0.773085  0.822790   0.824528   \n",
       "1  1.558111    0.100942       0.775144        0.773766  0.829510   0.823909   \n",
       "2  1.660052    0.107941       0.779394        0.773131  0.834068   0.823295   \n",
       "3  1.748003    0.176416       0.777734        0.773685  0.827675   0.824061   \n",
       "4  1.606099    0.103942       0.778264        0.773096  0.832877   0.823397   \n",
       "5  1.491657    0.107939       0.775050        0.773234  0.824467   0.824407   \n",
       "6  1.512645    0.086950       0.772781        0.773454  0.819409   0.825066   \n",
       "7  1.498651    0.079954       0.773307        0.774222  0.824163   0.824513   \n",
       "8  0.853510    0.049978       0.766169        0.774012  0.819647   0.824888   \n",
       "9  0.822529    0.046974       0.767156        0.774154  0.816886   0.825277   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.747015        0.745140        0.767043         0.765216   \n",
       "1       0.750332        0.745582        0.770693         0.765568   \n",
       "2       0.751880        0.745091        0.773313         0.764701   \n",
       "3       0.750111        0.745263        0.764797         0.764719   \n",
       "4       0.753649        0.744550        0.770292         0.764419   \n",
       "5       0.748784        0.745312        0.778131         0.764716   \n",
       "6       0.745245        0.745042        0.756955         0.765166   \n",
       "7       0.744582        0.746000        0.767134         0.764716   \n",
       "8       0.740159        0.746025        0.758173         0.766635   \n",
       "9       0.740380        0.745902        0.759027         0.765674   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.782903      0.781119  \n",
       "1     0.779647      0.782142  \n",
       "2     0.785573      0.781749  \n",
       "3     0.791116      0.782864  \n",
       "4     0.786404      0.781973  \n",
       "5     0.771992      0.781943  \n",
       "6     0.789283      0.781923  \n",
       "7     0.779581      0.783967  \n",
       "8     0.774336      0.781532  \n",
       "9     0.775461      0.782824  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           1.443429\n",
       "score_time         0.095298\n",
       "test_F1_Score      0.773989\n",
       "train_F1_Score     0.773584\n",
       "test_AUC           0.825149\n",
       "train_AUC          0.824334\n",
       "test_Accuracy      0.747214\n",
       "train_Accuracy     0.745391\n",
       "test_Precision     0.766556\n",
       "train_Precision    0.765153\n",
       "test_Recall        0.781630\n",
       "train_Recall       0.782204\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for Logistic Regression with Shuffle cv object\n",
      "0:00:05.943616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#from sklearn import metrics as mt\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "#modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel = make_pipeline(StandardScaler(),  LogisticRegression(penalty='l1', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "start = datetime.now()\n",
    "scores_kfold218 = cross_validate(logisticModel , X218, y=y218 , cv = kfold_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores_kfold218))\n",
    "display(pd.DataFrame(scores_kfold218).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Kfold cv object\")\n",
    "print(end-start)\n",
    "print()\n",
    "\n",
    "start = datetime.now()\n",
    "scores_shuffle218 = cross_validate(logisticModel , X218, y=y218 , cv = shuffle_cv_object , n_jobs = -1 , scoring = scoring)\n",
    "print()\n",
    "display(pd.DataFrame(scores_shuffle218))\n",
    "display(pd.DataFrame(scores_shuffle218).mean())\n",
    "end = datetime.now()\n",
    "print(\"time taken for Logistic Regression with Shuffle cv object\")\n",
    "print(end-start)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "<a id=\"CreateLRModel\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "<a id=\"SVMModel\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "### Simple Random Forest Model Fit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "########## Random Forest ############################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "baseRfModel = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1))\n",
    "scores = cross_validate(baseRfModel, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176114</td>\n",
       "      <td>0.534747</td>\n",
       "      <td>0.896149</td>\n",
       "      <td>0.987041</td>\n",
       "      <td>0.571459</td>\n",
       "      <td>0.999279</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.986679</td>\n",
       "      <td>0.902201</td>\n",
       "      <td>0.994939</td>\n",
       "      <td>0.890178</td>\n",
       "      <td>0.979267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.164129</td>\n",
       "      <td>0.532699</td>\n",
       "      <td>0.612521</td>\n",
       "      <td>0.985981</td>\n",
       "      <td>0.591019</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.479761</td>\n",
       "      <td>0.985598</td>\n",
       "      <td>0.920297</td>\n",
       "      <td>0.994546</td>\n",
       "      <td>0.459012</td>\n",
       "      <td>0.977562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.134430</td>\n",
       "      <td>0.536497</td>\n",
       "      <td>0.468588</td>\n",
       "      <td>0.989164</td>\n",
       "      <td>0.615618</td>\n",
       "      <td>0.999279</td>\n",
       "      <td>0.592126</td>\n",
       "      <td>0.987442</td>\n",
       "      <td>0.398139</td>\n",
       "      <td>0.994372</td>\n",
       "      <td>0.569328</td>\n",
       "      <td>0.984010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.159558</td>\n",
       "      <td>0.532365</td>\n",
       "      <td>0.325622</td>\n",
       "      <td>0.987655</td>\n",
       "      <td>0.555389</td>\n",
       "      <td>0.999319</td>\n",
       "      <td>0.484185</td>\n",
       "      <td>0.986409</td>\n",
       "      <td>0.629050</td>\n",
       "      <td>0.995186</td>\n",
       "      <td>0.219664</td>\n",
       "      <td>0.980237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.105849</td>\n",
       "      <td>0.531151</td>\n",
       "      <td>0.257084</td>\n",
       "      <td>0.989353</td>\n",
       "      <td>0.636202</td>\n",
       "      <td>0.999351</td>\n",
       "      <td>0.762221</td>\n",
       "      <td>0.987442</td>\n",
       "      <td>0.423690</td>\n",
       "      <td>0.994513</td>\n",
       "      <td>0.184524</td>\n",
       "      <td>0.984247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.078768</td>\n",
       "      <td>0.534301</td>\n",
       "      <td>0.593172</td>\n",
       "      <td>0.988580</td>\n",
       "      <td>0.721869</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.654722</td>\n",
       "      <td>0.987122</td>\n",
       "      <td>0.635045</td>\n",
       "      <td>0.994780</td>\n",
       "      <td>0.556479</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.113295</td>\n",
       "      <td>0.535136</td>\n",
       "      <td>0.509861</td>\n",
       "      <td>0.988034</td>\n",
       "      <td>0.675282</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.626189</td>\n",
       "      <td>0.986532</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>0.994505</td>\n",
       "      <td>0.421988</td>\n",
       "      <td>0.981646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.032596</td>\n",
       "      <td>0.530560</td>\n",
       "      <td>0.741019</td>\n",
       "      <td>0.986357</td>\n",
       "      <td>0.765246</td>\n",
       "      <td>0.999155</td>\n",
       "      <td>0.649193</td>\n",
       "      <td>0.985697</td>\n",
       "      <td>0.909419</td>\n",
       "      <td>0.994329</td>\n",
       "      <td>0.625241</td>\n",
       "      <td>0.978513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.059316</td>\n",
       "      <td>0.537769</td>\n",
       "      <td>0.866192</td>\n",
       "      <td>0.985505</td>\n",
       "      <td>0.813121</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.804689</td>\n",
       "      <td>0.984591</td>\n",
       "      <td>0.871873</td>\n",
       "      <td>0.993845</td>\n",
       "      <td>0.860584</td>\n",
       "      <td>0.977303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.035465</td>\n",
       "      <td>0.537426</td>\n",
       "      <td>0.354954</td>\n",
       "      <td>0.988036</td>\n",
       "      <td>0.635451</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.641451</td>\n",
       "      <td>0.985869</td>\n",
       "      <td>0.285531</td>\n",
       "      <td>0.994180</td>\n",
       "      <td>0.468980</td>\n",
       "      <td>0.981968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  1.176114    0.534747       0.896149        0.987041  0.571459   0.999279   \n",
       "1  1.164129    0.532699       0.612521        0.985981  0.591019   0.999197   \n",
       "2  1.134430    0.536497       0.468588        0.989164  0.615618   0.999279   \n",
       "3  1.159558    0.532365       0.325622        0.987655  0.555389   0.999319   \n",
       "4  1.105849    0.531151       0.257084        0.989353  0.636202   0.999351   \n",
       "5  1.078768    0.534301       0.593172        0.988580  0.721869   0.999325   \n",
       "6  1.113295    0.535136       0.509861        0.988034  0.675282   0.999286   \n",
       "7  1.032596    0.530560       0.741019        0.986357  0.765246   0.999155   \n",
       "8  1.059316    0.537769       0.866192        0.985505  0.813121   0.999079   \n",
       "9  1.035465    0.537426       0.354954        0.988036  0.635451   0.999086   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.815126        0.986679        0.902201         0.994939   \n",
       "1       0.479761        0.985598        0.920297         0.994546   \n",
       "2       0.592126        0.987442        0.398139         0.994372   \n",
       "3       0.484185        0.986409        0.629050         0.995186   \n",
       "4       0.762221        0.987442        0.423690         0.994513   \n",
       "5       0.654722        0.987122        0.635045         0.994780   \n",
       "6       0.626189        0.986532        0.643956         0.994505   \n",
       "7       0.649193        0.985697        0.909419         0.994329   \n",
       "8       0.804689        0.984591        0.871873         0.993845   \n",
       "9       0.641451        0.985869        0.285531         0.994180   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.890178      0.979267  \n",
       "1     0.459012      0.977562  \n",
       "2     0.569328      0.984010  \n",
       "3     0.219664      0.980237  \n",
       "4     0.184524      0.984247  \n",
       "5     0.556479      0.982456  \n",
       "6     0.421988      0.981646  \n",
       "7     0.625241      0.978513  \n",
       "8     0.860584      0.977303  \n",
       "9     0.468980      0.981968  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## Random Forest ############################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "baseRfModel = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1))\n",
    "scores = cross_validate(baseRfModel, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base model is overfitting as the training accuracy is 99.9%. To avoid overfitting added hyper parameter criterion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'randomforestclassifier__max_features': ['auto', 'log2', 8, 9, 10], 'randomforestclassifier__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'randomforestclassifier__min_samples_split': [2, 12, 22, 32, 42, 52, 62, 72, 82, 92], 'randomforestclassifier__min_samples_leaf': [1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97], 'randomforestclassifier__class_weight': [None, 'balanced', 'balanced_subsample'], 'randomforestclassifier__bootstrap': [True, False], 'randomforestclassifier__criterion': ['gini', 'entropy']}\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# Create randomized grid\n",
    "#################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2', 8, 9, 10]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [x for x in np.arange(2, 101, 10)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [x for x in np.arange(1, 101, 4)]\n",
    "\n",
    "#Class weights\n",
    "class_weight = [None, 'balanced', 'balanced_subsample']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "              'randomforestclassifier__max_features': max_features,\n",
    "              'randomforestclassifier__max_depth': max_depth,\n",
    "              'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "              'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "              'randomforestclassifier__class_weight': class_weight,\n",
    "              'randomforestclassifier__bootstrap': bootstrap,\n",
    "              'randomforestclassifier__criterion': criterion}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Grid Search for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=-1)]: Done 885 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1330 tasks      | elapsed: 65.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1857 tasks      | elapsed: 94.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 99.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__n_estimators': 200, 'randomforestclassifier__min_samples_split': 82, 'randomforestclassifier__min_samples_leaf': 25, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__max_depth': 30, 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__bootstrap': False} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#################################\n",
    "# Random Search Training\n",
    "#################################\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "#rf = RandomForestClassifier() #Originally was this\n",
    "rf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_randomgrid = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                                   n_iter = 200, \n",
    "                                   cv = kfold_cv_object,\n",
    "                                   verbose=2, \n",
    "                                   random_state=999, \n",
    "                                   n_jobs = -1,\n",
    "                                   scoring=scoring,\n",
    "                                   refit='Accuracy', \\\n",
    "                                   return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_randomgrid.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rf_randomgrid.best_params_, rf_randomgrid.best_score_))\n",
    "#rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.173242</td>\n",
       "      <td>1.130251</td>\n",
       "      <td>0.945183</td>\n",
       "      <td>0.794560</td>\n",
       "      <td>0.632266</td>\n",
       "      <td>0.874154</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.795448</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.828145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.763592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.118589</td>\n",
       "      <td>1.212926</td>\n",
       "      <td>0.854148</td>\n",
       "      <td>0.793773</td>\n",
       "      <td>0.597230</td>\n",
       "      <td>0.876642</td>\n",
       "      <td>0.753816</td>\n",
       "      <td>0.796854</td>\n",
       "      <td>0.910081</td>\n",
       "      <td>0.837175</td>\n",
       "      <td>0.804691</td>\n",
       "      <td>0.754649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.784884</td>\n",
       "      <td>1.416365</td>\n",
       "      <td>0.499487</td>\n",
       "      <td>0.821021</td>\n",
       "      <td>0.641772</td>\n",
       "      <td>0.885518</td>\n",
       "      <td>0.460960</td>\n",
       "      <td>0.803219</td>\n",
       "      <td>0.353386</td>\n",
       "      <td>0.873069</td>\n",
       "      <td>0.851541</td>\n",
       "      <td>0.774829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.335069</td>\n",
       "      <td>0.958800</td>\n",
       "      <td>0.130249</td>\n",
       "      <td>0.821248</td>\n",
       "      <td>0.599030</td>\n",
       "      <td>0.892708</td>\n",
       "      <td>0.459412</td>\n",
       "      <td>0.814008</td>\n",
       "      <td>0.740891</td>\n",
       "      <td>0.879318</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>0.770373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.360055</td>\n",
       "      <td>0.961714</td>\n",
       "      <td>0.099815</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.683090</td>\n",
       "      <td>0.881721</td>\n",
       "      <td>0.784561</td>\n",
       "      <td>0.795675</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.879599</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.759265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.212106</td>\n",
       "      <td>1.101879</td>\n",
       "      <td>0.603139</td>\n",
       "      <td>0.817914</td>\n",
       "      <td>0.776542</td>\n",
       "      <td>0.887913</td>\n",
       "      <td>0.686795</td>\n",
       "      <td>0.806955</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.879725</td>\n",
       "      <td>0.526161</td>\n",
       "      <td>0.764219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.162438</td>\n",
       "      <td>1.108456</td>\n",
       "      <td>0.544082</td>\n",
       "      <td>0.824281</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>0.666003</td>\n",
       "      <td>0.811403</td>\n",
       "      <td>0.733116</td>\n",
       "      <td>0.872679</td>\n",
       "      <td>0.432549</td>\n",
       "      <td>0.780969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.209686</td>\n",
       "      <td>1.110232</td>\n",
       "      <td>0.795808</td>\n",
       "      <td>0.797653</td>\n",
       "      <td>0.788606</td>\n",
       "      <td>0.878692</td>\n",
       "      <td>0.706923</td>\n",
       "      <td>0.798280</td>\n",
       "      <td>0.902797</td>\n",
       "      <td>0.848660</td>\n",
       "      <td>0.711491</td>\n",
       "      <td>0.752430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.223480</td>\n",
       "      <td>1.038435</td>\n",
       "      <td>0.898419</td>\n",
       "      <td>0.802842</td>\n",
       "      <td>0.856661</td>\n",
       "      <td>0.876029</td>\n",
       "      <td>0.842292</td>\n",
       "      <td>0.798820</td>\n",
       "      <td>0.852623</td>\n",
       "      <td>0.845568</td>\n",
       "      <td>0.949413</td>\n",
       "      <td>0.764226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.181271</td>\n",
       "      <td>1.123418</td>\n",
       "      <td>0.371585</td>\n",
       "      <td>0.817368</td>\n",
       "      <td>0.643284</td>\n",
       "      <td>0.880685</td>\n",
       "      <td>0.643884</td>\n",
       "      <td>0.796977</td>\n",
       "      <td>0.295469</td>\n",
       "      <td>0.878028</td>\n",
       "      <td>0.500526</td>\n",
       "      <td>0.764548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  8.173242    1.130251       0.945183        0.794560  0.632266   0.874154   \n",
       "1  8.118589    1.212926       0.854148        0.793773  0.597230   0.876642   \n",
       "2  7.784884    1.416365       0.499487        0.821021  0.641772   0.885518   \n",
       "3  8.335069    0.958800       0.130249        0.821248  0.599030   0.892708   \n",
       "4  8.360055    0.961714       0.099815        0.815014  0.683090   0.881721   \n",
       "5  8.212106    1.101879       0.603139        0.817914  0.776542   0.887913   \n",
       "6  8.162438    1.108456       0.544082        0.824281  0.731959   0.888828   \n",
       "7  8.209686    1.110232       0.795808        0.797653  0.788606   0.878692   \n",
       "8  8.223480    1.038435       0.898419        0.802842  0.856661   0.876029   \n",
       "9  8.181271    1.123418       0.371585        0.817368  0.643284   0.880685   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.896064        0.795448        0.896064         0.828145   \n",
       "1       0.753816        0.796854        0.910081         0.837175   \n",
       "2       0.460960        0.803219        0.353386         0.873069   \n",
       "3       0.459412        0.814008        0.740891         0.879318   \n",
       "4       0.784561        0.795675        0.729730         0.879599   \n",
       "5       0.686795        0.806955        0.706500         0.879725   \n",
       "6       0.666003        0.811403        0.733116         0.872679   \n",
       "7       0.706923        0.798280        0.902797         0.848660   \n",
       "8       0.842292        0.798820        0.852623         0.845568   \n",
       "9       0.643884        0.796977        0.295469         0.878028   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     1.000000      0.763592  \n",
       "1     0.804691      0.754649  \n",
       "2     0.851541      0.774829  \n",
       "3     0.071401      0.770373  \n",
       "4     0.053571      0.759265  \n",
       "5     0.526161      0.764219  \n",
       "6     0.432549      0.780969  \n",
       "7     0.711491      0.752430  \n",
       "8     0.949413      0.764226  \n",
       "9     0.500526      0.764548  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574191</td>\n",
       "      <td>0.695044</td>\n",
       "      <td>0.690071</td>\n",
       "      <td>0.712066</td>\n",
       "      <td>0.590134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.574191  0.695044       0.690071        0.712066     0.590134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810567</td>\n",
       "      <td>0.882289</td>\n",
       "      <td>0.801764</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.76491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.810567   0.882289        0.801764         0.862197       0.76491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 200, min_samples_split = 82, min_samples_leaf = 25, \\\n",
    "                                                                         max_features = 'log2', max_depth = 30, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "display(pd.DataFrame(scores))\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above output, the training accuracy is around 80% and is not overfitted as seen in the base model. We will now proceed with GridSearch using the parameters from random grid search. **We split the grid search into five sub grids to speed the grid search process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [200, 202, 204, 206], 'randomforestclassifier__max_features': ['log2'], 'randomforestclassifier__max_depth': [27, 28], 'randomforestclassifier__min_samples_split': [81, 83, 85], 'randomforestclassifier__min_samples_leaf': [18, 20, 22], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__criterion': ['entropy'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [200, 202, 204, 206]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [27,28]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [81,83,85]\n",
    "\n",
    "min_samples_leaf = [18,20,22]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 14.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 28, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 22, 'randomforestclassifier__min_samples_split': 83, 'randomforestclassifier__n_estimators': 200} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [201, 203, 205, 207]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [25,26]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [80,82,84]\n",
    "\n",
    "min_samples_leaf = [24,25,26]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 14.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 25, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 25, 'randomforestclassifier__min_samples_split': 80, 'randomforestclassifier__n_estimators': 207} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [191, 192, 193, 194], 'randomforestclassifier__max_features': ['log2'], 'randomforestclassifier__max_depth': [29, 30], 'randomforestclassifier__min_samples_split': [76, 78, 86], 'randomforestclassifier__min_samples_leaf': [19, 21, 23], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__criterion': ['entropy'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [191, 192, 193, 194]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [29,30]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [76,78,86]\n",
    "\n",
    "min_samples_leaf = [19,21,23]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 14.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 29, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 19, 'randomforestclassifier__min_samples_split': 76, 'randomforestclassifier__n_estimators': 194} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [195, 196, 197, 198], 'randomforestclassifier__max_features': ['log2'], 'randomforestclassifier__max_depth': [31, 32], 'randomforestclassifier__min_samples_split': [77, 79, 87], 'randomforestclassifier__min_samples_leaf': [27, 28, 29], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__criterion': ['entropy'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [195, 196, 197, 198]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [31,32]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [77,79,87]\n",
    "\n",
    "min_samples_leaf = [27,28,29]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 32, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 27, 'randomforestclassifier__min_samples_split': 79, 'randomforestclassifier__n_estimators': 197} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [191, 199, 208, 209], 'randomforestclassifier__max_features': ['log2'], 'randomforestclassifier__max_depth': [33, 34], 'randomforestclassifier__min_samples_split': [88, 89, 90], 'randomforestclassifier__min_samples_leaf': [30, 31, 32], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__criterion': ['entropy'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [191,199,208,209]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [33,34]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [88,89,90]\n",
    "\n",
    "min_samples_leaf = [30,31,32]\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__criterion' : criterion,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 34, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_leaf': 30, 'randomforestclassifier__min_samples_split': 88, 'randomforestclassifier__n_estimators': 191} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = kfold_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='Accuracy', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571489</td>\n",
       "      <td>0.691526</td>\n",
       "      <td>0.688301</td>\n",
       "      <td>0.717623</td>\n",
       "      <td>0.587227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.571489  0.691526       0.688301        0.717623     0.587227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.80734</td>\n",
       "      <td>0.879171</td>\n",
       "      <td>0.798636</td>\n",
       "      <td>0.860085</td>\n",
       "      <td>0.76085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0         0.80734   0.879171        0.798636         0.860085       0.76085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from first Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 191, min_samples_split = 88, min_samples_leaf = 30, \\\n",
    "                                                                         max_features = 'log2', max_depth = 34, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577149</td>\n",
       "      <td>0.694355</td>\n",
       "      <td>0.690513</td>\n",
       "      <td>0.714612</td>\n",
       "      <td>0.593358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.577149  0.694355       0.690513        0.714612     0.593358"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809876</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.801027</td>\n",
       "      <td>0.861577</td>\n",
       "      <td>0.764184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.809876   0.881481        0.801027         0.861577      0.764184"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from second Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 197, min_samples_split = 79, min_samples_leaf = 27, \\\n",
    "                                                                         max_features = 'log2', max_depth = 32, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577023</td>\n",
       "      <td>0.695651</td>\n",
       "      <td>0.694627</td>\n",
       "      <td>0.717628</td>\n",
       "      <td>0.584089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.577023  0.695651       0.694627        0.717628     0.584089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814803</td>\n",
       "      <td>0.887103</td>\n",
       "      <td>0.805969</td>\n",
       "      <td>0.865543</td>\n",
       "      <td>0.769817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.814803   0.887103        0.805969         0.865543      0.769817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from third Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 194, min_samples_split = 76, min_samples_leaf = 19, \\\n",
    "                                                                         max_features = 'log2', max_depth = 29, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.578606</td>\n",
       "      <td>0.695207</td>\n",
       "      <td>0.691995</td>\n",
       "      <td>0.715741</td>\n",
       "      <td>0.58809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.578606  0.695207       0.691995        0.715741      0.58809"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810158</td>\n",
       "      <td>0.882294</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.861934</td>\n",
       "      <td>0.764393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.810158   0.882294        0.801361         0.861934      0.764393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from fourth Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 207, min_samples_split = 80, min_samples_leaf = 25, \\\n",
    "                                                                         max_features = 'log2', max_depth = 25, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Test Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.580179</td>\n",
       "      <td>0.696036</td>\n",
       "      <td>0.693322</td>\n",
       "      <td>0.71494</td>\n",
       "      <td>0.590794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_F1_Score  test_AUC  test_Accuracy  test_Precision  test_Recall\n",
       "0       0.580179  0.696036       0.693322         0.71494     0.590794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean values for Performance Metrices on Training Set are .......\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811959</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.803089</td>\n",
       "      <td>0.863058</td>\n",
       "      <td>0.766726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_F1_Score  train_AUC  train_Accuracy  train_Precision  train_Recall\n",
       "0        0.811959   0.883871        0.803089         0.863058      0.766726"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model using parameter from fourth Grid Search\n",
    "rfRandomGridEst = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 200, min_samples_split = 83, min_samples_leaf = 22, \\\n",
    "                                                                         max_features = 'log2', max_depth = 28, class_weight = \"balanced\", \\\n",
    "                                                                         criterion = 'entropy', bootstrap = False,random_state=999, n_jobs=-1))\n",
    "\n",
    "scores = cross_validate(rfRandomGridEst, X, y=y, cv=kfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "#display(pd.DataFrame(scores).mean())\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Test Set are .......\")\n",
    "testCol = ['test_F1_Score', 'test_AUC', 'test_Accuracy', 'test_Precision', 'test_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[testCol].mean()).T)\n",
    "\n",
    "print(\"\\n Mean values for Performance Metrices on Training Set are .......\")\n",
    "trainCol = ['train_F1_Score', 'train_AUC', 'train_Accuracy', 'train_Precision', 'train_Recall' ]\n",
    "display(pd.DataFrame(pd.DataFrame(scores)[trainCol].mean()).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was fitted with best parameter from each grid search to compare accuracy and AuC. \n",
    "The parameter set that gives the highes accuracy is as below\n",
    "n_estimators = 194 \n",
    "min_samples_split = 76\n",
    "min_samples_leaf = 19\n",
    "max_features = 'log2'\n",
    "max_depth = 29\n",
    "class_weight = \"balanced\"\n",
    "criterion = 'entropy' \n",
    "bootstrap = False\n",
    "random_state=999, n_jobs=-1\n",
    "\n",
    "The metrics are \n",
    "\ttest_F1_Score\ttest_AUC\ttest_Accuracy\ttest_Precision\ttest_Recall\n",
    "0\t0.577023\t0.695651\t0.694627\t0.717628\t0.584089\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment of Models for Task 1 and Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models that we have derived, for both home loans and subscription to term deposits,  are of interest to the bank.  Banks, similar to other businesses, have a business case to increase customer base (or increase what current customers use the bank for) without increasing (or decrease) their customer acquisition cost.  We have focused on building predictive models for existing bank customers and would not affect the acquisiton cost for new customers.\n",
    "\n",
    "In order to benefit the bank's sales, the banks could use these models to increase probability of the customers they phone that ultimately will subscribe to a term deposit or invest in a home.  This reduces the number of phone calls, reduces the hours that are paid to the bankers to make those phone calls and increases the probaility of the banks earning interest on the term deposits or home loans.\n",
    "\n",
    "We would encourage the bankers to continue to enter the data in order to refine the model at a later date.  Market changes could effect the models' accuracy and continuing to collect data will make it simplier to refine for the next campaign.  Since the models do not need to be used for each phone call, the use of the model can be deployed to a few people in the bank and then the list of more likely candidates be distributed to the bankers that will be contacting the existing customers.  The use of the models could also be added to the process during signing up new customers.  The bank could run the model on the attributes of the new customer and then make offers on the spot if the model shows the determined level of probability. \n",
    "\n",
    "The attribute that we believe would refine the models even further and increase the models' performance is income.  Income is important to home loans as it shows purchasing power on average homes in the neighborhood.  Income is important to term deposits as it is an indicator on disposable income of the customers to save more. \n",
    "\n",
    "The model could be refined in any time intervals, but at a minimum the model should be updated significant change in the market or national interst rate adjustments.\n",
    "\n",
    "Note:  We have no evidence that these models can be extrapolated to other banks in Portugal or other countries.  (Despite us not knowing the randomness of the sample or the calls, we are going to assume that they were random in this case and we can use the model to predict the subscribe or housing outcomes to the entire bank population).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
