{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "<a id=\"top\"></a>\n",
    "# DS 7331 Data Mining: Lab 2 iPython Notebook\n",
    "Created On: February 11, 2019\n",
    "### Authors:  \n",
    "- Arora, Tanvi                \n",
    "- Chandna, Rajat\n",
    "- Henderson Kuns, Nicol\n",
    "- Ramasundaram, Kumar\n",
    "- Vasquez, James\n",
    "LRInterpertFeat\n",
    "\n",
    "# Logisitic Regression and Support Vector Machines\n",
    "\n",
    "## Contents\n",
    "* <a href=\"#DataPrep\">Data Prepping</a>\n",
    "    * <a href=\"#onehotencode\">One Hot Encoding</a>\n",
    "    * <a href=\"#Perform8020split\">Perform 80/20 split</a>  \n",
    "    * <a href=\"#PrepTestData\">Prep Test Data</a>    \n",
    "* <a href=\"#CreateLRModel\">Create Models</a>\n",
    "    * <a href=\"#CreateLRModel\">Simple Logistic Regression Model</a>  \n",
    "    * <a href=\"#LRGridSearch\">Grid Search</a>   \n",
    "    * <a href=\"#LRInterpertFeat\">Feature Interpertation</a>   \n",
    "* <a href=\"#SVMModel\">Simple SVM Model</a>\n",
    "    * <a href=\"#SVMRBF\">RBF Grid Search</a>   \n",
    "    * <a href=\"#SVMPOLY\">Poly Grid Search</a>   \n",
    "    * <a href=\"#SVMFINAL\">Final SVM Model on Validation Dataset</a>\n",
    "    * <a href=\"#SVMFINAL_Test\">Final SVM Model on Additional Test Dataset</a> \n",
    "* <a href=\"#MODELADV\">Model Advantages</a>\n",
    "* <a href=\"#INTVECT\">Interpret Support Vector</a>\n",
    "* <a href=\"#ECPWORK\">Exceptionnal Work</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"DataPrep\"></a>\n",
    "### Getting Dataset Ready for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "\n",
    "# To display plots inside the iPython Notebook itself\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n",
      "\n",
      "58;\"management\";\"married\";\"tertiary\";\"no\";2143;\"yes\";\"no\";\"unknown\";5;\"may\";261;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "44;\"technician\";\"single\";\"secondary\";\"no\";29;\"yes\";\"no\";\"unknown\";5;\"may\";151;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "33;\"entrepreneur\";\"married\";\"secondary\";\"no\";2;\"yes\";\"yes\";\"unknown\";5;\"may\";76;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "47;\"blue-collar\";\"married\";\"unknown\";\"no\";1506;\"yes\";\"no\";\"unknown\";5;\"may\";92;1;-1;0;\"unknown\";\"no\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To verify how data is orgainzed in file(to find the delimiter) and then\n",
    "# use corresponding function to open the file. eg\n",
    "# data could be in .csv. .tsv, excel format etc.\n",
    "pathOfDataFile = \"data/bank-full.csv\"\n",
    "firstFewLines = list()\n",
    "noOfLinesToView = 5\n",
    "\n",
    "with open(pathOfDataFile) as dataFile:\n",
    "    firstFewLines = [next(dataFile) for i in range(noOfLinesToView)]\n",
    "    for line in firstFewLines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>Subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>231</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>447</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "5   35    management  married   tertiary      no      231     yes   no   \n",
       "6   28    management   single   tertiary      no      447     yes  yes   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome Subscribed  \n",
       "0  unknown    5   may       261         1     -1         0  unknown         no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown         no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown         no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown         no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown         no  \n",
       "5  unknown    5   may       139         1     -1         0  unknown         no  \n",
       "6  unknown    5   may       217         1     -1         0  unknown         no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the semi-colon delimited data file into pandas dataFrame\n",
    "bankPromo_df = pd.read_csv(pathOfDataFile, sep = \";\")\n",
    "\n",
    "# Rename the Target/Final Outcome column from \"y\" to \"Subscribed\" as based on data description.\n",
    "bankPromo_df = bankPromo_df.rename(columns={\"y\":\"Subscribed\"})\n",
    "\n",
    "bankPromo_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      "age           45211 non-null int64\n",
      "job           45211 non-null object\n",
      "marital       45211 non-null object\n",
      "education     45211 non-null object\n",
      "default       45211 non-null object\n",
      "balance       45211 non-null int64\n",
      "housing       45211 non-null object\n",
      "loan          45211 non-null object\n",
      "contact       45211 non-null object\n",
      "day           45211 non-null int64\n",
      "month         45211 non-null object\n",
      "duration      45211 non-null int64\n",
      "campaign      45211 non-null int64\n",
      "pdays         45211 non-null int64\n",
      "previous      45211 non-null int64\n",
      "poutcome      45211 non-null object\n",
      "Subscribed    45211 non-null object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "bankPromo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
      "['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values(Levels) for categorical variables.\n",
    "# List to hold names of categorical variables\n",
    "categoricalVars = list()\n",
    "# List to hold names of numerical variables\n",
    "numericalVars = list()\n",
    "\n",
    "for colName in bankPromo_df.columns:\n",
    "    if bankPromo_df[colName].dtype == np.int64:\n",
    "        numericalVars.append(colName)\n",
    "    elif bankPromo_df[colName].dtype == np.object:\n",
    "        categoricalVars.append(colName)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# Remove Target column from final categorical Var list\n",
    "categoricalVars.remove('Subscribed')\n",
    "\n",
    "print(numericalVars)\n",
    "print(categoricalVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "<a id=\"onehotencode\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "### Perform One Hot Encoding for categorical variables in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of original data frame\n",
    "bankPromoModel_Df = bankPromo_df.copy()\n",
    "bankPromoModel_Df['Target'] = bankPromoModel_Df['Subscribed'].apply(lambda resp : 1 if resp == \"yes\" else 0)\n",
    "bankPromoModel_Df['Target'] = bankPromoModel_Df['Target'].astype(np.int)\n",
    "# Delete the original 'Subscribed' column\n",
    "del bankPromoModel_Df['Subscribed']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the pDays feature as it had high correlation with \"previous\" feature\n",
    "del bankPromoModel_Df['pdays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 42 columns):\n",
      "age                    45211 non-null int64\n",
      "balance                45211 non-null int64\n",
      "day                    45211 non-null int64\n",
      "duration               45211 non-null int64\n",
      "campaign               45211 non-null int64\n",
      "previous               45211 non-null int64\n",
      "Target                 45211 non-null int64\n",
      "job_blue-collar        45211 non-null uint8\n",
      "job_entrepreneur       45211 non-null uint8\n",
      "job_housemaid          45211 non-null uint8\n",
      "job_management         45211 non-null uint8\n",
      "job_retired            45211 non-null uint8\n",
      "job_self-employed      45211 non-null uint8\n",
      "job_services           45211 non-null uint8\n",
      "job_student            45211 non-null uint8\n",
      "job_technician         45211 non-null uint8\n",
      "job_unemployed         45211 non-null uint8\n",
      "job_unknown            45211 non-null uint8\n",
      "marital_married        45211 non-null uint8\n",
      "marital_single         45211 non-null uint8\n",
      "education_secondary    45211 non-null uint8\n",
      "education_tertiary     45211 non-null uint8\n",
      "education_unknown      45211 non-null uint8\n",
      "default_yes            45211 non-null uint8\n",
      "housing_yes            45211 non-null uint8\n",
      "loan_yes               45211 non-null uint8\n",
      "contact_telephone      45211 non-null uint8\n",
      "contact_unknown        45211 non-null uint8\n",
      "month_aug              45211 non-null uint8\n",
      "month_dec              45211 non-null uint8\n",
      "month_feb              45211 non-null uint8\n",
      "month_jan              45211 non-null uint8\n",
      "month_jul              45211 non-null uint8\n",
      "month_jun              45211 non-null uint8\n",
      "month_mar              45211 non-null uint8\n",
      "month_may              45211 non-null uint8\n",
      "month_nov              45211 non-null uint8\n",
      "month_oct              45211 non-null uint8\n",
      "month_sep              45211 non-null uint8\n",
      "poutcome_other         45211 non-null uint8\n",
      "poutcome_success       45211 non-null uint8\n",
      "poutcome_unknown       45211 non-null uint8\n",
      "dtypes: int64(7), uint8(35)\n",
      "memory usage: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Covert all categorical variables to corresponding indicator variables\n",
    "for categoricalVar in categoricalVars:\n",
    "    tmpDf = pd.DataFrame()\n",
    "    # Remove 1st class level to avoid multicollinearity\n",
    "    tmpDf = pd.get_dummies(bankPromoModel_Df[categoricalVar], prefix=categoricalVar, drop_first=True)\n",
    "    bankPromoModel_Df = pd.concat((bankPromoModel_Df, tmpDf), axis=1)\n",
    "\n",
    "# Now remove the original categorical vars since indicator variables are created from them.\n",
    "bankPromoModel_Df.drop(categoricalVars, inplace=True, axis=1)\n",
    "bankPromoModel_Df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________\n",
    "<a id=\"Perform8020split\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "### Create 10 Splits Stratified Cross Validation Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=10, random_state=999, test_size=0.2,\n",
      "            train_size=None)\n"
     ]
    }
   ],
   "source": [
    "# Training and Test Split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "if 'Target' in bankPromoModel_Df:\n",
    "    y = bankPromoModel_Df['Target'].values # get the labels we want\n",
    "    del bankPromoModel_Df['Target']        # get rid of the class label\n",
    "    X = bankPromoModel_Df.values           # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# To use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 10\n",
    "stratified_cv_object = StratifiedShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2, random_state=999)\n",
    "                         \n",
    "print(stratified_cv_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=999, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "# Training and Test Split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if 'Target' in bankPromoModel_Df:\n",
    "    y = bankPromoModel_Df['Target'].values # get the labels we want\n",
    "    del bankPromoModel_Df['Target']        # get rid of the class label\n",
    "    X = bankPromoModel_Df.values           # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# To use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 10\n",
    "stratifiedKfold_cv_object = StratifiedKFold(n_splits=num_cv_iterations, random_state=999)\n",
    "                         \n",
    "print(stratifiedKfold_cv_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "<a id=\"PrepTestData\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "### Getting ready Additional Test Dataset(with 10% instances) for final model fitting and evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      "age           4521 non-null int64\n",
      "job           4521 non-null object\n",
      "marital       4521 non-null object\n",
      "education     4521 non-null object\n",
      "default       4521 non-null object\n",
      "balance       4521 non-null int64\n",
      "housing       4521 non-null object\n",
      "loan          4521 non-null object\n",
      "contact       4521 non-null object\n",
      "day           4521 non-null int64\n",
      "month         4521 non-null object\n",
      "duration      4521 non-null int64\n",
      "campaign      4521 non-null int64\n",
      "pdays         4521 non-null int64\n",
      "previous      4521 non-null int64\n",
      "poutcome      4521 non-null object\n",
      "Subscribed    4521 non-null object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 600.5+ KB\n"
     ]
    }
   ],
   "source": [
    "pathOfAdditionalDataFile = \"data/bank.csv\"\n",
    "\n",
    "# Import the semi-colon delimited data file into pandas dataFrame\n",
    "bankPromoAdditional_df = pd.read_csv(pathOfAdditionalDataFile, sep = \";\")\n",
    "\n",
    "# Rename the Target/Final Outcome column from \"y\" to \"Subscribed\" as based on data description.\n",
    "bankPromoAdditional_df = bankPromoAdditional_df.rename(columns={\"y\":\"Subscribed\"})\n",
    "\n",
    "bankPromoAdditional_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankPromoAdditional_df['Target'] = bankPromoAdditional_df['Subscribed'].apply(lambda resp : 1 if resp == \"yes\" else 0)\n",
    "bankPromoAdditional_df['Target'] = bankPromoAdditional_df['Target'].astype(np.int)\n",
    "# Delete the original 'Subscribed' column\n",
    "del bankPromoAdditional_df['Subscribed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pDays\n",
    "del bankPromoAdditional_df['pdays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 41 columns):\n",
      "age                    4521 non-null int64\n",
      "balance                4521 non-null int64\n",
      "day                    4521 non-null int64\n",
      "duration               4521 non-null int64\n",
      "campaign               4521 non-null int64\n",
      "previous               4521 non-null int64\n",
      "job_blue-collar        4521 non-null uint8\n",
      "job_entrepreneur       4521 non-null uint8\n",
      "job_housemaid          4521 non-null uint8\n",
      "job_management         4521 non-null uint8\n",
      "job_retired            4521 non-null uint8\n",
      "job_self-employed      4521 non-null uint8\n",
      "job_services           4521 non-null uint8\n",
      "job_student            4521 non-null uint8\n",
      "job_technician         4521 non-null uint8\n",
      "job_unemployed         4521 non-null uint8\n",
      "job_unknown            4521 non-null uint8\n",
      "marital_married        4521 non-null uint8\n",
      "marital_single         4521 non-null uint8\n",
      "education_secondary    4521 non-null uint8\n",
      "education_tertiary     4521 non-null uint8\n",
      "education_unknown      4521 non-null uint8\n",
      "default_yes            4521 non-null uint8\n",
      "housing_yes            4521 non-null uint8\n",
      "loan_yes               4521 non-null uint8\n",
      "contact_telephone      4521 non-null uint8\n",
      "contact_unknown        4521 non-null uint8\n",
      "month_aug              4521 non-null uint8\n",
      "month_dec              4521 non-null uint8\n",
      "month_feb              4521 non-null uint8\n",
      "month_jan              4521 non-null uint8\n",
      "month_jul              4521 non-null uint8\n",
      "month_jun              4521 non-null uint8\n",
      "month_mar              4521 non-null uint8\n",
      "month_may              4521 non-null uint8\n",
      "month_nov              4521 non-null uint8\n",
      "month_oct              4521 non-null uint8\n",
      "month_sep              4521 non-null uint8\n",
      "poutcome_other         4521 non-null uint8\n",
      "poutcome_success       4521 non-null uint8\n",
      "poutcome_unknown       4521 non-null uint8\n",
      "dtypes: int64(6), uint8(35)\n",
      "memory usage: 366.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Covert all categorical variables to corresponding indicator variables\n",
    "for categoricalVar in categoricalVars:\n",
    "    tmpDf = pd.DataFrame()\n",
    "    # Remove 1st class level to avoid multicollinearity\n",
    "    tmpDf = pd.get_dummies(bankPromoAdditional_df[categoricalVar], prefix=categoricalVar, drop_first=True)\n",
    "    bankPromoAdditional_df = pd.concat((bankPromoAdditional_df, tmpDf), axis=1)\n",
    "\n",
    "# Now remove the original categorical vars since indicator variables are created from them.\n",
    "bankPromoAdditional_df.drop(categoricalVars, inplace=True, axis=1)\n",
    "\n",
    "if 'Target' in bankPromoAdditional_df:\n",
    "    y_Final = bankPromoAdditional_df['Target'].values # get the labels we want\n",
    "    del bankPromoAdditional_df['Target']        # get rid of the class label\n",
    "    X_Final = bankPromoAdditional_df.values\n",
    "\n",
    "bankPromoAdditional_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "<a id=\"CreateLRModel\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "# Create Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "<a id=\"SVMModel\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "### Simple SVM Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.997428</td>\n",
       "      <td>29.277847</td>\n",
       "      <td>0.442489</td>\n",
       "      <td>0.536374</td>\n",
       "      <td>0.905848</td>\n",
       "      <td>0.943094</td>\n",
       "      <td>0.901913</td>\n",
       "      <td>0.917358</td>\n",
       "      <td>0.660413</td>\n",
       "      <td>0.780235</td>\n",
       "      <td>0.332703</td>\n",
       "      <td>0.408650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.573726</td>\n",
       "      <td>29.793940</td>\n",
       "      <td>0.409762</td>\n",
       "      <td>0.533934</td>\n",
       "      <td>0.908474</td>\n",
       "      <td>0.942348</td>\n",
       "      <td>0.898374</td>\n",
       "      <td>0.917026</td>\n",
       "      <td>0.639279</td>\n",
       "      <td>0.778533</td>\n",
       "      <td>0.301512</td>\n",
       "      <td>0.406287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.945217</td>\n",
       "      <td>29.854525</td>\n",
       "      <td>0.460468</td>\n",
       "      <td>0.522341</td>\n",
       "      <td>0.910840</td>\n",
       "      <td>0.942594</td>\n",
       "      <td>0.905673</td>\n",
       "      <td>0.916058</td>\n",
       "      <td>0.695985</td>\n",
       "      <td>0.781176</td>\n",
       "      <td>0.344045</td>\n",
       "      <td>0.392342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.975717</td>\n",
       "      <td>29.032582</td>\n",
       "      <td>0.442467</td>\n",
       "      <td>0.534931</td>\n",
       "      <td>0.903748</td>\n",
       "      <td>0.942832</td>\n",
       "      <td>0.903019</td>\n",
       "      <td>0.917358</td>\n",
       "      <td>0.675728</td>\n",
       "      <td>0.782787</td>\n",
       "      <td>0.328922</td>\n",
       "      <td>0.406287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.551564</td>\n",
       "      <td>29.336625</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.526694</td>\n",
       "      <td>0.905101</td>\n",
       "      <td>0.943542</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.916169</td>\n",
       "      <td>0.648115</td>\n",
       "      <td>0.775632</td>\n",
       "      <td>0.341210</td>\n",
       "      <td>0.398724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.740093</td>\n",
       "      <td>29.887593</td>\n",
       "      <td>0.443450</td>\n",
       "      <td>0.525689</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.940267</td>\n",
       "      <td>0.903682</td>\n",
       "      <td>0.916280</td>\n",
       "      <td>0.684418</td>\n",
       "      <td>0.779378</td>\n",
       "      <td>0.327977</td>\n",
       "      <td>0.396597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56.034785</td>\n",
       "      <td>30.636996</td>\n",
       "      <td>0.434286</td>\n",
       "      <td>0.535808</td>\n",
       "      <td>0.900787</td>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.901471</td>\n",
       "      <td>0.917026</td>\n",
       "      <td>0.661509</td>\n",
       "      <td>0.775291</td>\n",
       "      <td>0.323251</td>\n",
       "      <td>0.409359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55.871675</td>\n",
       "      <td>29.466311</td>\n",
       "      <td>0.431423</td>\n",
       "      <td>0.527187</td>\n",
       "      <td>0.909024</td>\n",
       "      <td>0.941691</td>\n",
       "      <td>0.902355</td>\n",
       "      <td>0.916335</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.316635</td>\n",
       "      <td>0.398724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52.515114</td>\n",
       "      <td>30.386943</td>\n",
       "      <td>0.458831</td>\n",
       "      <td>0.529183</td>\n",
       "      <td>0.901194</td>\n",
       "      <td>0.943467</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.916363</td>\n",
       "      <td>0.684803</td>\n",
       "      <td>0.774840</td>\n",
       "      <td>0.344991</td>\n",
       "      <td>0.401796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56.857944</td>\n",
       "      <td>30.009609</td>\n",
       "      <td>0.434069</td>\n",
       "      <td>0.529936</td>\n",
       "      <td>0.901098</td>\n",
       "      <td>0.942322</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>0.916860</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>0.782548</td>\n",
       "      <td>0.325142</td>\n",
       "      <td>0.400615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  55.997428   29.277847       0.442489        0.536374  0.905848   0.943094   \n",
       "1  55.573726   29.793940       0.409762        0.533934  0.908474   0.942348   \n",
       "2  53.945217   29.854525       0.460468        0.522341  0.910840   0.942594   \n",
       "3  53.975717   29.032582       0.442467        0.534931  0.903748   0.942832   \n",
       "4  53.551564   29.336625       0.447059        0.526694  0.905101   0.943542   \n",
       "5  56.740093   29.887593       0.443450        0.525689  0.911227   0.940267   \n",
       "6  56.034785   30.636996       0.434286        0.535808  0.900787   0.944734   \n",
       "7  55.871675   29.466311       0.431423        0.527187  0.909024   0.941691   \n",
       "8  52.515114   30.386943       0.458831        0.529183  0.901194   0.943467   \n",
       "9  56.857944   30.009609       0.434069        0.529936  0.901098   0.942322   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.901913        0.917358        0.660413         0.780235   \n",
       "1       0.898374        0.917026        0.639279         0.778533   \n",
       "2       0.905673        0.916058        0.695985         0.781176   \n",
       "3       0.903019        0.917358        0.675728         0.782787   \n",
       "4       0.901250        0.916169        0.648115         0.775632   \n",
       "5       0.903682        0.916280        0.684418         0.779378   \n",
       "6       0.901471        0.917026        0.661509         0.775291   \n",
       "7       0.902355        0.916335        0.676768         0.777778   \n",
       "8       0.904788        0.916363        0.684803         0.774840   \n",
       "9       0.900807        0.916860        0.652751         0.782548   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.332703      0.408650  \n",
       "1     0.301512      0.406287  \n",
       "2     0.344045      0.392342  \n",
       "3     0.328922      0.406287  \n",
       "4     0.341210      0.398724  \n",
       "5     0.327977      0.396597  \n",
       "6     0.323251      0.409359  \n",
       "7     0.316635      0.398724  \n",
       "8     0.344991      0.401796  \n",
       "9     0.325142      0.400615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.547299</td>\n",
       "      <td>16.551178</td>\n",
       "      <td>0.026119</td>\n",
       "      <td>0.540348</td>\n",
       "      <td>0.889240</td>\n",
       "      <td>0.944899</td>\n",
       "      <td>0.884564</td>\n",
       "      <td>0.917545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776684</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.414286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.267283</td>\n",
       "      <td>16.542563</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.546727</td>\n",
       "      <td>0.370369</td>\n",
       "      <td>0.942571</td>\n",
       "      <td>0.819770</td>\n",
       "      <td>0.918823</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.788287</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.418487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.679508</td>\n",
       "      <td>16.518146</td>\n",
       "      <td>0.051690</td>\n",
       "      <td>0.559631</td>\n",
       "      <td>0.455206</td>\n",
       "      <td>0.945343</td>\n",
       "      <td>0.788985</td>\n",
       "      <td>0.920324</td>\n",
       "      <td>0.054507</td>\n",
       "      <td>0.791699</td>\n",
       "      <td>0.049149</td>\n",
       "      <td>0.432773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.234187</td>\n",
       "      <td>16.177203</td>\n",
       "      <td>0.050304</td>\n",
       "      <td>0.569840</td>\n",
       "      <td>0.393581</td>\n",
       "      <td>0.947252</td>\n",
       "      <td>0.757797</td>\n",
       "      <td>0.922045</td>\n",
       "      <td>0.046474</td>\n",
       "      <td>0.803749</td>\n",
       "      <td>0.054820</td>\n",
       "      <td>0.441387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.293430</td>\n",
       "      <td>16.650535</td>\n",
       "      <td>0.144304</td>\n",
       "      <td>0.555252</td>\n",
       "      <td>0.580249</td>\n",
       "      <td>0.942971</td>\n",
       "      <td>0.850476</td>\n",
       "      <td>0.920079</td>\n",
       "      <td>0.218391</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.107750</td>\n",
       "      <td>0.426471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74.162877</td>\n",
       "      <td>16.490273</td>\n",
       "      <td>0.197415</td>\n",
       "      <td>0.559253</td>\n",
       "      <td>0.503552</td>\n",
       "      <td>0.944690</td>\n",
       "      <td>0.848927</td>\n",
       "      <td>0.919931</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.785334</td>\n",
       "      <td>0.158790</td>\n",
       "      <td>0.434244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70.751371</td>\n",
       "      <td>16.391119</td>\n",
       "      <td>0.166983</td>\n",
       "      <td>0.553717</td>\n",
       "      <td>0.575662</td>\n",
       "      <td>0.946234</td>\n",
       "      <td>0.805795</td>\n",
       "      <td>0.919145</td>\n",
       "      <td>0.167619</td>\n",
       "      <td>0.781394</td>\n",
       "      <td>0.166352</td>\n",
       "      <td>0.428782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63.744324</td>\n",
       "      <td>14.995524</td>\n",
       "      <td>0.032051</td>\n",
       "      <td>0.618125</td>\n",
       "      <td>0.208879</td>\n",
       "      <td>0.955003</td>\n",
       "      <td>0.398806</td>\n",
       "      <td>0.927820</td>\n",
       "      <td>0.019746</td>\n",
       "      <td>0.810986</td>\n",
       "      <td>0.085066</td>\n",
       "      <td>0.499370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73.711308</td>\n",
       "      <td>17.453439</td>\n",
       "      <td>0.260456</td>\n",
       "      <td>0.543772</td>\n",
       "      <td>0.609869</td>\n",
       "      <td>0.942091</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.918801</td>\n",
       "      <td>0.261950</td>\n",
       "      <td>0.793312</td>\n",
       "      <td>0.258979</td>\n",
       "      <td>0.413655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64.364488</td>\n",
       "      <td>14.171050</td>\n",
       "      <td>0.292779</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>0.723169</td>\n",
       "      <td>0.954828</td>\n",
       "      <td>0.525442</td>\n",
       "      <td>0.935219</td>\n",
       "      <td>0.177246</td>\n",
       "      <td>0.854521</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.537912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  68.547299   16.551178       0.026119        0.540348  0.889240   0.944899   \n",
       "1  82.267283   16.542563       0.007308        0.546727  0.370369   0.942571   \n",
       "2  71.679508   16.518146       0.051690        0.559631  0.455206   0.945343   \n",
       "3  70.234187   16.177203       0.050304        0.569840  0.393581   0.947252   \n",
       "4  76.293430   16.650535       0.144304        0.555252  0.580249   0.942971   \n",
       "5  74.162877   16.490273       0.197415        0.559253  0.503552   0.944690   \n",
       "6  70.751371   16.391119       0.166983        0.553717  0.575662   0.946234   \n",
       "7  63.744324   14.995524       0.032051        0.618125  0.208879   0.955003   \n",
       "8  73.711308   17.453439       0.260456        0.543772  0.609869   0.942091   \n",
       "9  64.364488   14.171050       0.292779        0.660222  0.723169   0.954828   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.884564        0.917545        1.000000         0.776684   \n",
       "1       0.819770        0.918823        0.010274         0.788287   \n",
       "2       0.788985        0.920324        0.054507         0.791699   \n",
       "3       0.757797        0.922045        0.046474         0.803749   \n",
       "4       0.850476        0.920079        0.218391         0.795455   \n",
       "5       0.848927        0.919931        0.260870         0.785334   \n",
       "6       0.805795        0.919145        0.167619         0.781394   \n",
       "7       0.398806        0.927820        0.019746         0.810986   \n",
       "8       0.827914        0.918801        0.261950         0.793312   \n",
       "9       0.525442        0.935219        0.177246         0.854521   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.013233      0.414286  \n",
       "1     0.005671      0.418487  \n",
       "2     0.049149      0.432773  \n",
       "3     0.054820      0.441387  \n",
       "4     0.107750      0.426471  \n",
       "5     0.158790      0.434244  \n",
       "6     0.166352      0.428782  \n",
       "7     0.085066      0.499370  \n",
       "8     0.258979      0.413655  \n",
       "9     0.840909      0.537912  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run SVM model\n",
    "\n",
    "svmModel = make_pipeline(StandardScaler(), SVC(C=1.0, kernel='rbf', degree=3 , gamma='auto', random_state=999))\n",
    "scores = cross_validate(svmModel, X, y=y, cv=stratified_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "print()\n",
    "display(pd.DataFrame(scores))\n",
    "\n",
    "scores = cross_validate(svmModel, X, y=y, cv=stratifiedKfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For class balance\n",
    "\n",
    "svmModel = make_pipeline(StandardScaler(), SVC(C=1.0, kernel='rbf', degree=3 , gamma='auto',class_weight=\"balanced\", random_state=999))\n",
    "\n",
    "scores = cross_validate(svmModel, X, y=y, cv=stratified_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "display(pd.DataFrame(scores))\n",
    "\n",
    "scores = cross_validate(svmModel, X, y=y, cv=stratifiedKfold_cv_object, n_jobs=-1, scoring=scoring)\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "<a id=\"SVMRBF\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "### Tuning The Model Hyper Parameters for SVM Using Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "param_grid = {\n",
    "     'svc__kernel' : ['poly', 'rbf'],\n",
    "    'svc__C' : np.logspace(-10, 2, 5),\n",
    "    'svc__degree' : [1,2,3],\n",
    "    'svc__gamma': np.logspace(-9, 3, 5)}\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "grid = GridSearchCV(make_pipeline(StandardScaler(), SVC(class_weight='balanced', random_state=999)), \\\n",
    "                   param_grid = param_grid, cv = stratified_cv_object, \\\n",
    "                   verbose=False, n_jobs=-1, scoring=scoring, refit='F1_Score', \\\n",
    "                   return_train_score=True)\n",
    "\n",
    "grid.fit(X, y=y)\n",
    "\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.455259</td>\n",
       "      <td>0.670275</td>\n",
       "      <td>0.441088</td>\n",
       "      <td>0.963994</td>\n",
       "      <td>0.887794</td>\n",
       "      <td>0.999714</td>\n",
       "      <td>0.897711</td>\n",
       "      <td>0.991844</td>\n",
       "      <td>0.611390</td>\n",
       "      <td>0.996719</td>\n",
       "      <td>0.344991</td>\n",
       "      <td>0.933349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.543636</td>\n",
       "      <td>0.432030</td>\n",
       "      <td>0.968424</td>\n",
       "      <td>0.888017</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>0.898817</td>\n",
       "      <td>0.992811</td>\n",
       "      <td>0.629295</td>\n",
       "      <td>0.996003</td>\n",
       "      <td>0.328922</td>\n",
       "      <td>0.942330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.320733</td>\n",
       "      <td>0.543752</td>\n",
       "      <td>0.454159</td>\n",
       "      <td>0.962628</td>\n",
       "      <td>0.892616</td>\n",
       "      <td>0.999738</td>\n",
       "      <td>0.900586</td>\n",
       "      <td>0.991539</td>\n",
       "      <td>0.634975</td>\n",
       "      <td>0.995957</td>\n",
       "      <td>0.353497</td>\n",
       "      <td>0.931458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.244978</td>\n",
       "      <td>0.540238</td>\n",
       "      <td>0.426980</td>\n",
       "      <td>0.964416</td>\n",
       "      <td>0.892466</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.897600</td>\n",
       "      <td>0.991927</td>\n",
       "      <td>0.618280</td>\n",
       "      <td>0.995472</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.935240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.227350</td>\n",
       "      <td>0.539349</td>\n",
       "      <td>0.446301</td>\n",
       "      <td>0.967860</td>\n",
       "      <td>0.889007</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.897379</td>\n",
       "      <td>0.992701</td>\n",
       "      <td>0.605178</td>\n",
       "      <td>0.997991</td>\n",
       "      <td>0.353497</td>\n",
       "      <td>0.939494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226471</td>\n",
       "      <td>0.538469</td>\n",
       "      <td>0.424090</td>\n",
       "      <td>0.965534</td>\n",
       "      <td>0.890089</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>0.898485</td>\n",
       "      <td>0.992175</td>\n",
       "      <td>0.630597</td>\n",
       "      <td>0.995980</td>\n",
       "      <td>0.319471</td>\n",
       "      <td>0.936894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.231513</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.436881</td>\n",
       "      <td>0.970923</td>\n",
       "      <td>0.889342</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.899370</td>\n",
       "      <td>0.993364</td>\n",
       "      <td>0.632616</td>\n",
       "      <td>0.996023</td>\n",
       "      <td>0.333648</td>\n",
       "      <td>0.947057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.205409</td>\n",
       "      <td>0.540837</td>\n",
       "      <td>0.444170</td>\n",
       "      <td>0.965526</td>\n",
       "      <td>0.893627</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>0.900365</td>\n",
       "      <td>0.992175</td>\n",
       "      <td>0.639432</td>\n",
       "      <td>0.996229</td>\n",
       "      <td>0.340265</td>\n",
       "      <td>0.936658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264353</td>\n",
       "      <td>0.538117</td>\n",
       "      <td>0.454600</td>\n",
       "      <td>0.969167</td>\n",
       "      <td>0.887864</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.899701</td>\n",
       "      <td>0.992977</td>\n",
       "      <td>0.624793</td>\n",
       "      <td>0.996257</td>\n",
       "      <td>0.357278</td>\n",
       "      <td>0.943512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.249046</td>\n",
       "      <td>0.541407</td>\n",
       "      <td>0.435474</td>\n",
       "      <td>0.965635</td>\n",
       "      <td>0.895221</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.897932</td>\n",
       "      <td>0.992203</td>\n",
       "      <td>0.616984</td>\n",
       "      <td>0.996730</td>\n",
       "      <td>0.336484</td>\n",
       "      <td>0.936422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  1.455259    0.670275       0.441088        0.963994  0.887794   0.999714   \n",
       "1  0.319000    0.543636       0.432030        0.968424  0.888017   0.999747   \n",
       "2  0.320733    0.543752       0.454159        0.962628  0.892616   0.999738   \n",
       "3  0.244978    0.540238       0.426980        0.964416  0.892466   0.999737   \n",
       "4  0.227350    0.539349       0.446301        0.967860  0.889007   0.999801   \n",
       "5  0.226471    0.538469       0.424090        0.965534  0.890089   0.999742   \n",
       "6  0.231513    0.540741       0.436881        0.970923  0.889342   0.999798   \n",
       "7  0.205409    0.540837       0.444170        0.965526  0.893627   0.999672   \n",
       "8  0.264353    0.538117       0.454600        0.969167  0.887864   0.999763   \n",
       "9  0.249046    0.541407       0.435474        0.965635  0.895221   0.999768   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.897711        0.991844        0.611390         0.996719   \n",
       "1       0.898817        0.992811        0.629295         0.996003   \n",
       "2       0.900586        0.991539        0.634975         0.995957   \n",
       "3       0.897600        0.991927        0.618280         0.995472   \n",
       "4       0.897379        0.992701        0.605178         0.997991   \n",
       "5       0.898485        0.992175        0.630597         0.995980   \n",
       "6       0.899370        0.993364        0.632616         0.996023   \n",
       "7       0.900365        0.992175        0.639432         0.996229   \n",
       "8       0.899701        0.992977        0.624793         0.996257   \n",
       "9       0.897932        0.992203        0.616984         0.996730   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.344991      0.933349  \n",
       "1     0.328922      0.942330  \n",
       "2     0.353497      0.931458  \n",
       "3     0.326087      0.935240  \n",
       "4     0.353497      0.939494  \n",
       "5     0.319471      0.936894  \n",
       "6     0.333648      0.947057  \n",
       "7     0.340265      0.936658  \n",
       "8     0.357278      0.943512  \n",
       "9     0.336484      0.936422  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## Random Forest ############################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "baseRfModel = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1))\n",
    "scores = cross_validate(baseRfModel, X, y=y, cv=stratified_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "display(pd.DataFrame(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "baseRfModel = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1, class_weight='balanced'))\n",
    "scores = cross_validate(baseRfModel, X, y=y, cv=stratified_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "baseRfModel = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1, class_weight='balanced_subsample'))\n",
    "scores = cross_validate(baseRfModel, X, y=y, cv=stratified_cv_object, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'randomforestclassifier__max_features': ['auto', 'log2', 8, 9, 10], 'randomforestclassifier__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'randomforestclassifier__min_samples_split': [2, 5, 10, 15], 'randomforestclassifier__min_samples_leaf': [1, 2, 4], 'randomforestclassifier__class_weight': ['balanced', 'balanced_subsample'], 'randomforestclassifier__bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# Create randomized grid\n",
    "#################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2', 8, 9, 10]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "#Class weights\n",
    "class_weight = ['balanced', 'balanced_subsample']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "               'randomforestclassifier__max_features': max_features,\n",
    "               'randomforestclassifier__max_depth': max_depth,\n",
    "               'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "               'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforestclassifier__class_weight': class_weight,\n",
    "               'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 45.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__n_estimators': 1200, 'randomforestclassifier__min_samples_split': 10, 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__max_depth': 50, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__bootstrap': False} with a score of 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#################################\n",
    "# Random Search Training\n",
    "#################################\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "#rf = RandomForestClassifier() #Originally was this\n",
    "rf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_randomgrid = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                                   n_iter = 100, \n",
    "                                   cv = stratified_cv_object,\n",
    "                                   verbose=2, \n",
    "                                   random_state=999, \n",
    "                                   n_jobs = -1,\n",
    "                                   scoring=scoring,\n",
    "                                   refit='F1_Score', \\\n",
    "                                   return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_randomgrid.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rf_randomgrid.best_params_, rf_randomgrid.best_score_))\n",
    "#rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [1209, 1211, 1213, 1207], 'randomforestclassifier__max_features': ['auto'], 'randomforestclassifier__max_depth': [49, 51], 'randomforestclassifier__min_samples_split': [3, 4, 17], 'randomforestclassifier__min_samples_leaf': [2, 4, 6], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 1 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [1209, 1211, 1213, 1207]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [49,51]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [3,4,17]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2,4,6]\n",
    "\n",
    "#Class weights\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 47.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__max_depth': 49, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__min_samples_split': 17, 'randomforestclassifier__n_estimators': 1209} with a score of 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = stratified_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='F1_Score', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [1190, 1175, 1150, 1125], 'randomforestclassifier__max_features': ['auto'], 'randomforestclassifier__max_depth': [45, 55], 'randomforestclassifier__min_samples_split': [2, 25, 30], 'randomforestclassifier__min_samples_leaf': [11, 12, 14], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 2 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [1190, 1175, 1150, 1125]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [45,55]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,25,30]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [11,12,14]\n",
    "\n",
    "#Class weights\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 41.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__max_depth': 45, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 11, 'randomforestclassifier__min_samples_split': 25, 'randomforestclassifier__n_estimators': 1190} with a score of 0.58\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = stratified_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='F1_Score', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [1192, 1194, 1196, 1198], 'randomforestclassifier__max_features': ['auto'], 'randomforestclassifier__max_depth': [48, 50], 'randomforestclassifier__min_samples_split': [9, 11, 13], 'randomforestclassifier__min_samples_leaf': [1, 4, 7], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 3 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [1192, 1194, 1196, 1198]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [48,50]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split =  [9,11,13]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,4,7]\n",
    "\n",
    "#Class weights\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 122.3min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 273.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 491.4min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 548.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__max_depth': 48, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 13, 'randomforestclassifier__n_estimators': 1196} with a score of 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = stratified_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='F1_Score', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [1210, 1225, 1250, 1275], 'randomforestclassifier__max_features': ['auto'], 'randomforestclassifier__max_depth': [49, 51], 'randomforestclassifier__min_samples_split': [5, 15, 20], 'randomforestclassifier__min_samples_leaf': [8, 9, 10], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 4 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [1210, 1225, 1250, 1275]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [49,51]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5,15,20]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [8,9,10]\n",
    "\n",
    "#Class weights\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 71.3min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 165.5min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 296.8min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 336.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__max_depth': 49, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 8, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 1250} with a score of 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = stratified_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='F1_Score', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': [1202, 1204, 1206, 1208], 'randomforestclassifier__max_features': ['auto'], 'randomforestclassifier__max_depth': [50, 52], 'randomforestclassifier__min_samples_split': [8, 10, 12], 'randomforestclassifier__min_samples_leaf': [1, 2, 3], 'randomforestclassifier__class_weight': ['balanced'], 'randomforestclassifier__bootstrap': [False]}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# Create Smaller grid 5 based upon Random Grid CV results\n",
    "#######################################################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [1202, 1204, 1206, 1208]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [50,52]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [8,10,12]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,3]\n",
    "\n",
    "#Class weights\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "\n",
    "# Create the random grid\n",
    "subGrid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "        'randomforestclassifier__max_features': max_features,\n",
    "        'randomforestclassifier__max_depth': max_depth,\n",
    "        'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "        'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "        'randomforestclassifier__class_weight': class_weight,\n",
    "        'randomforestclassifier__bootstrap': bootstrap}\n",
    "\n",
    "print(subGrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed: 46.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed: 85.8min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 100.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'randomforestclassifier__bootstrap': False, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__max_depth': 50, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__min_samples_split': 10, 'randomforestclassifier__n_estimators': 1206} with a score of 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#################################\n",
    "# Sub Grid Search\n",
    "#################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "rfSubGridEstimator = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=999, n_jobs=-1)) \n",
    "\n",
    "rfSubGridModel = GridSearchCV(estimator = rfSubGridEstimator, \n",
    "                              param_grid= subGrid,  \n",
    "                              cv = stratified_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='F1_Score', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rfSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (rfSubGridModel.best_params_, rfSubGridModel.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_F1_Score</th>\n",
       "      <th>train_F1_Score</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>train_AUC</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>train_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.165820</td>\n",
       "      <td>0.147896</td>\n",
       "      <td>0.477972</td>\n",
       "      <td>0.497419</td>\n",
       "      <td>0.922039</td>\n",
       "      <td>0.930914</td>\n",
       "      <td>0.904346</td>\n",
       "      <td>0.908483</td>\n",
       "      <td>0.661102</td>\n",
       "      <td>0.695541</td>\n",
       "      <td>0.374291</td>\n",
       "      <td>0.387143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.179397</td>\n",
       "      <td>0.144644</td>\n",
       "      <td>0.460695</td>\n",
       "      <td>0.512528</td>\n",
       "      <td>0.921989</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.902134</td>\n",
       "      <td>0.910169</td>\n",
       "      <td>0.648370</td>\n",
       "      <td>0.701726</td>\n",
       "      <td>0.357278</td>\n",
       "      <td>0.403687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.347942</td>\n",
       "      <td>0.164581</td>\n",
       "      <td>0.507126</td>\n",
       "      <td>0.489957</td>\n",
       "      <td>0.924644</td>\n",
       "      <td>0.930365</td>\n",
       "      <td>0.908216</td>\n",
       "      <td>0.907321</td>\n",
       "      <td>0.682109</td>\n",
       "      <td>0.687740</td>\n",
       "      <td>0.403592</td>\n",
       "      <td>0.380525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.168341</td>\n",
       "      <td>0.149330</td>\n",
       "      <td>0.469660</td>\n",
       "      <td>0.500827</td>\n",
       "      <td>0.924256</td>\n",
       "      <td>0.931075</td>\n",
       "      <td>0.903351</td>\n",
       "      <td>0.908179</td>\n",
       "      <td>0.655932</td>\n",
       "      <td>0.687861</td>\n",
       "      <td>0.365784</td>\n",
       "      <td>0.393760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.198545</td>\n",
       "      <td>0.158289</td>\n",
       "      <td>0.483568</td>\n",
       "      <td>0.504308</td>\n",
       "      <td>0.920983</td>\n",
       "      <td>0.930557</td>\n",
       "      <td>0.902687</td>\n",
       "      <td>0.909340</td>\n",
       "      <td>0.637771</td>\n",
       "      <td>0.699664</td>\n",
       "      <td>0.389414</td>\n",
       "      <td>0.394233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.241407</td>\n",
       "      <td>0.160050</td>\n",
       "      <td>0.483557</td>\n",
       "      <td>0.500831</td>\n",
       "      <td>0.928431</td>\n",
       "      <td>0.929023</td>\n",
       "      <td>0.906226</td>\n",
       "      <td>0.908676</td>\n",
       "      <td>0.679795</td>\n",
       "      <td>0.694468</td>\n",
       "      <td>0.375236</td>\n",
       "      <td>0.391633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.236522</td>\n",
       "      <td>0.178961</td>\n",
       "      <td>0.457846</td>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.919940</td>\n",
       "      <td>0.930568</td>\n",
       "      <td>0.902577</td>\n",
       "      <td>0.909119</td>\n",
       "      <td>0.656085</td>\n",
       "      <td>0.691403</td>\n",
       "      <td>0.351607</td>\n",
       "      <td>0.402978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.310461</td>\n",
       "      <td>0.494365</td>\n",
       "      <td>0.479369</td>\n",
       "      <td>0.498946</td>\n",
       "      <td>0.920590</td>\n",
       "      <td>0.930127</td>\n",
       "      <td>0.905120</td>\n",
       "      <td>0.907985</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.687267</td>\n",
       "      <td>0.373346</td>\n",
       "      <td>0.391633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.149833</td>\n",
       "      <td>0.161080</td>\n",
       "      <td>0.483262</td>\n",
       "      <td>0.506100</td>\n",
       "      <td>0.918979</td>\n",
       "      <td>0.930944</td>\n",
       "      <td>0.906115</td>\n",
       "      <td>0.909340</td>\n",
       "      <td>0.678632</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.375236</td>\n",
       "      <td>0.397069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.185220</td>\n",
       "      <td>0.164816</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.502187</td>\n",
       "      <td>0.920090</td>\n",
       "      <td>0.930367</td>\n",
       "      <td>0.902687</td>\n",
       "      <td>0.908731</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.378072</td>\n",
       "      <td>0.393524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_F1_Score  train_F1_Score  test_AUC  train_AUC  \\\n",
       "0  4.165820    0.147896       0.477972        0.497419  0.922039   0.930914   \n",
       "1  4.179397    0.144644       0.460695        0.512528  0.921989   0.931250   \n",
       "2  4.347942    0.164581       0.507126        0.489957  0.924644   0.930365   \n",
       "3  4.168341    0.149330       0.469660        0.500827  0.924256   0.931075   \n",
       "4  4.198545    0.158289       0.483568        0.504308  0.920983   0.930557   \n",
       "5  4.241407    0.160050       0.483557        0.500831  0.928431   0.929023   \n",
       "6  4.236522    0.178961       0.457846        0.509183  0.919940   0.930568   \n",
       "7  4.310461    0.494365       0.479369        0.498946  0.920590   0.930127   \n",
       "8  4.149833    0.161080       0.483262        0.506100  0.918979   0.930944   \n",
       "9  4.185220    0.164816       0.476190        0.502187  0.920090   0.930367   \n",
       "\n",
       "   test_Accuracy  train_Accuracy  test_Precision  train_Precision  \\\n",
       "0       0.904346        0.908483        0.661102         0.695541   \n",
       "1       0.902134        0.910169        0.648370         0.701726   \n",
       "2       0.908216        0.907321        0.682109         0.687740   \n",
       "3       0.903351        0.908179        0.655932         0.687861   \n",
       "4       0.902687        0.909340        0.637771         0.699664   \n",
       "5       0.906226        0.908676        0.679795         0.694468   \n",
       "6       0.902577        0.909119        0.656085         0.691403   \n",
       "7       0.905120        0.907985        0.669492         0.687267   \n",
       "8       0.906115        0.909340        0.678632         0.697674   \n",
       "9       0.902687        0.908731        0.643087         0.693750   \n",
       "\n",
       "   test_Recall  train_Recall  \n",
       "0     0.374291      0.387143  \n",
       "1     0.357278      0.403687  \n",
       "2     0.403592      0.380525  \n",
       "3     0.365784      0.393760  \n",
       "4     0.389414      0.394233  \n",
       "5     0.375236      0.391633  \n",
       "6     0.351607      0.402978  \n",
       "7     0.373346      0.391633  \n",
       "8     0.375236      0.397069  \n",
       "9     0.378072      0.393524  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Start XGBoost ####\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "#class xgboost.XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, \n",
    "#                            silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1,\n",
    "#                            nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1,\n",
    "#                            colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, \n",
    "#                            scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
    "\n",
    "xgb_baseModel = XGBClassifier(n_jobs=-1, random_state=999)\n",
    "scores = cross_validate(xgb_baseModel, X, y=y, cv=stratified_cv_object, n_jobs=-1, scoring=scoring)\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470, 490, 510, 530, 550, 570, 590, 610, 630, 650, 670, 690, 710, 730, 750, 770, 790, 810, 830, 850, 870, 890, 910, 930, 950, 970, 990], 'learning_rate': [0.05, 0.1, 0.15000000000000002, 0.2, 0.25, 0.3, 0.35000000000000003, 0.4, 0.45, 0.5, 0.55, 0.6000000000000001, 0.6500000000000001, 0.7000000000000001, 0.7500000000000001, 0.8, 0.8500000000000001, 0.9000000000000001, 0.9500000000000001, 1.0, 1.05, 1.1, 1.1500000000000001, 1.2000000000000002, 1.2500000000000002, 1.3, 1.35, 1.4000000000000001, 1.4500000000000002, 1.5000000000000002, 1.55, 1.6, 1.6500000000000001, 1.7000000000000002, 1.7500000000000002, 1.8, 1.85, 1.9000000000000001, 1.9500000000000002, 2.0, 2.05, 2.1, 2.15, 2.1999999999999997, 2.25, 2.3, 2.35, 2.4, 2.45, 2.5, 2.55, 2.6, 2.65, 2.7, 2.75, 2.8, 2.85, 2.9, 2.95]}\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# Create randomized grid for Boosting Params only for now with default tree params\n",
    "#####################################################################################\n",
    "\n",
    "# Number of boosted trees to fit.\n",
    "n_estimators = [int(x) for x in np.arange(10, 1000, 20)]\n",
    "\n",
    "# Boosting learning rate (xgb’s “eta”)\n",
    "learning_rate = [x for x in np.arange(0.05, 3, 0.05)]\n",
    "\n",
    "\n",
    "# Create the random grid for boosting params\n",
    "random_grid_boosting = {'n_estimators': n_estimators,\n",
    "              'learning_rate': learning_rate}\n",
    "\n",
    "print(random_grid_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 250 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 885 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1330 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1857 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed: 31.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'n_estimators': 770, 'learning_rate': 0.35000000000000003} with a score of 0.55\n"
     ]
    }
   ],
   "source": [
    "# Finding optimal value of n_estimators param based upon leaning rate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#################################\n",
    "# Random Search Training\n",
    "#################################\n",
    "\n",
    "# Use the random grid to search for best hyperparameters for Boosting while keeping tree \n",
    "# parameters to default values\n",
    "\n",
    "xgbEstimator = XGBClassifier(n_jobs=-1, random_state=999)\n",
    "\n",
    "# Perform Random Grid search using Stratified Shuffle Split CV Object.\n",
    "xgb_randomgrid = RandomizedSearchCV(estimator = xgbEstimator, param_distributions = random_grid_boosting, \n",
    "                                   n_iter = 250, \n",
    "                                   cv = stratified_cv_object,\n",
    "                                   verbose=2, \n",
    "                                   random_state=999, \n",
    "                                   n_jobs = -1,\n",
    "                                   scoring=scoring,\n",
    "                                   refit='F1_Score', \\\n",
    "                                   return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_randomgrid.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (xgb_randomgrid.best_params_, xgb_randomgrid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [750, 753, 756, 759, 762, 765, 768, 771, 774, 777], 'learning_rate': [0.28, 0.30000000000000004, 0.32000000000000006, 0.3400000000000001, 0.3600000000000001, 0.3800000000000001]}\n"
     ]
    }
   ],
   "source": [
    "## Running Grid Search for boosting parameters in vicinity of values found during Random Grid Search\n",
    "# Number of boosted trees to fit.\n",
    "\n",
    "n_estimators = [int(x) for x in np.arange(750, 780, 3)]\n",
    "\n",
    "# Boosting learning rate (xgb’s “eta”)\n",
    "learning_rate = [x for x in np.arange(0.28, 0.40, 0.02)]\n",
    "\n",
    "\n",
    "# Create the random grid for boosting params\n",
    "sub_grid_boosting = {'n_estimators': n_estimators,\n",
    "              'learning_rate': learning_rate}\n",
    "\n",
    "print(sub_grid_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 12.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'learning_rate': 0.30000000000000004, 'n_estimators': 771} with a score of 0.55\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# Sub Grid Search for boosting params\n",
    "######################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "xgbSubGridEstimator = XGBClassifier(n_jobs=-1, random_state=999)\n",
    "\n",
    "xgbSubGridModel = GridSearchCV(estimator = xgbSubGridEstimator, \n",
    "                              param_grid = sub_grid_boosting,  \n",
    "                              cv = stratified_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='F1_Score', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "xgbSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (xgbSubGridModel.best_params_, xgbSubGridModel.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [3, 4, 5, 6, 7, 8, 9, 10], 'min_child_weight': [1, 2, 3, 4, 5, 6]}\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Create randomized grid for 2 Important Tree Params using Boosting Params obtained \n",
    "# via Grid Search\n",
    "########################################################################################\n",
    "\n",
    "# Maximum tree depth for base learners.\n",
    "max_depth = [int(x) for x in np.arange(3, 11)]\n",
    "\n",
    "# Minimum sum of instance weight(hessian) needed in a child.\n",
    "min_child_weight = [int(x) for x in np.arange(1, 7)]\n",
    "\n",
    "\n",
    "# Create the random grid for boosting params\n",
    "sub_grid_tree = {'max_depth': max_depth,\n",
    "              'min_child_weight': min_child_weight}\n",
    "\n",
    "print(sub_grid_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 17.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'max_depth': 5, 'min_child_weight': 1} with a score of 0.55\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# Sub Grid Search for 2max_depth and min_child_weight params\n",
    "############################################################\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "xgbSubGridEstimator = XGBClassifier(learning_rate = 0.30, n_estimators = 771, n_jobs=-1, random_state=999)\n",
    "\n",
    "xgbSubGridModel = GridSearchCV(estimator = xgbSubGridEstimator, \n",
    "                              param_grid = sub_grid_tree,  \n",
    "                              cv = stratified_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='F1_Score', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "xgbSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (xgbSubGridModel.best_params_, xgbSubGridModel.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  70 | elapsed:  1.6min remaining:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  70 | elapsed:  1.8min remaining:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'gamma': 0.0} with a score of 0.55\n"
     ]
    }
   ],
   "source": [
    "## Tune gamma parameter value\n",
    "gamma_vals = {\n",
    " 'gamma':[i/10.0 for i in range(0,7)]\n",
    "}\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "xgbSubGridEstimator = XGBClassifier(learning_rate = 0.30, n_estimators = 771, max_depth = 5, \\\n",
    "                                    min_child_weight = 1, n_jobs=-1, random_state=999)\n",
    "\n",
    "xgbSubGridModel = GridSearchCV(estimator = xgbSubGridEstimator, \n",
    "                              param_grid = gamma_vals,  \n",
    "                              cv = stratified_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='F1_Score', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "xgbSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (xgbSubGridModel.best_params_, xgbSubGridModel.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 49 candidates, totalling 490 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 490 out of 490 | elapsed: 12.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'colsample_bytree': 0.9, 'subsample': 0.8} with a score of 0.54\n"
     ]
    }
   ],
   "source": [
    "## Tune Subsample and colsample_bytree tree params\n",
    "param_test_2vars = {\n",
    " 'subsample':[i/10.0 for i in range(3,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(3,10)]\n",
    "}\n",
    "\n",
    "scoring = {'F1_Score': 'f1', 'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Precision': 'precision', \\\n",
    "          'Recall': 'recall'}\n",
    "\n",
    "xgbSubGridEstimator = XGBClassifier(learning_rate = 0.30, n_estimators = 771, max_depth = 5, \\\n",
    "                                    min_child_weight = 1, gamma = 0, n_jobs=-1, random_state=999)\n",
    "\n",
    "xgbSubGridModel = GridSearchCV(estimator = xgbSubGridEstimator, \n",
    "                              param_grid = param_test_2vars,  \n",
    "                              cv = stratified_cv_object,\n",
    "                              verbose=2, \n",
    "                              n_jobs = -1,\n",
    "                              scoring=scoring,\n",
    "                              refit='F1_Score', \n",
    "                              return_train_score=True)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "xgbSubGridModel.fit(X, y=y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (xgbSubGridModel.best_params_, xgbSubGridModel.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
