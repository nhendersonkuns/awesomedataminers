{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Advantages \n",
    "- Discuss the advantages of each model for each classification task. \n",
    "- Does one type of model offer superior performance over another in terms of prediction accuracy? \n",
    "    - In terms of training time or efficiency? Explain in detail.\n",
    "    \n",
    "Both Support Vector Machine (SVM) and Logistic Regression (LR) try to classify a binary response or maximizing the probability of classifying a response variable.  In these models the team is trying to classify a response variable of subscribing to a long-term deposit.\n",
    "\n",
    "The SVM model attempts to find the maximum margin in the dimensional space.  This space is defined by the number of features that classify data points.  Points that fall on either side of this plane are classified into one of the binary responses the model is predicting.  To accurately define these margins the model uses support vectors that define the boundaries or the max margin.  These support vectors are points that lie the closest to the calculated boundary of the points.  These support vectors also define the position of the optimized plane.\n",
    "\n",
    "![alt text](https://github.com/nhendersonkuns/awesomedataminers/raw/master/ReferenceMaterial/SVM_optimal_plane.PNG \"SVM Planes\")\n",
    "\n",
    "The LR model will take the output of you model and give you a response that is between 0 and 1 using the logistic function.  In the case that the output is higher or lower than your threshold the value will be give a 1 or 0 respectively.  Within LR the method is to maximize the likelihood that a random data point is classified correctly (maximum likelihood estimation, MLE).  The LR allows the model to optimize this function by use of algorithms such as Newton’s method, conjugate gradients, modifications of Newton’s method using box constraints.  Learning and applying the different methods allow for a more accurate model.\n",
    "\n",
    "The difference between SVM and LR in terms of the Loss function is that SVM will minimize hinge loss while LR minimizes logistic loss.  What this leads to is logistic loss (LR) diverges faster than hinge loss (SVM).  The LR model is more sensitive to outliers as it tries to find the plane for classifying the points, where as the SVM model is not as sensitive to these outliers.\n",
    "\n",
    "![alt text](https://github.com/nhendersonkuns/awesomedataminers/raw/master/ReferenceMaterial/Outliers_SVM_vs_LR.PNG \"SVM vs LR Outliers\")\n",
    "\n",
    "Within the LR model your values are predicted probabilities between 0 and 1, which at this point you must decide your cut-off to give you the binary response.  The SVM model does produce a final binary response of 0 or 1.\n",
    "\n",
    "LR will perform better on smaller data sets and SVM performs better with larger data sets.  In terms of small data sets SVM as support vectors may not be a true/good representation of the decision boundaries.  Deciding the performance between SVM and LR, is relative and depends on several factors such as data set size and domain knowledge of the data.  In most cases a simple model (LR) should be attempted first to determine if the output is of desired accuracy.  In tradition LR it is found that the models may fit the training data set to well and may result in a model that is unable to make reasonably good predictions for unknown data points which is referred to as overfitting.  SVM attempts to minimize the classification error on the training set and minimize the complexity of the model.  Over all between the two methods SVM can compute more complex decision boundaries.\n",
    "\n",
    "\n",
    "In the case of the bank data set, the team believes that the SVM should provide better results due to the size of the data sets and several outlier points that were discovered during data discovery.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
