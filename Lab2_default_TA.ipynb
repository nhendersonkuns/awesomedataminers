{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# To display plots inside the iPython Notebook itself\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n",
      "\n",
      "58;\"management\";\"married\";\"tertiary\";\"no\";2143;\"yes\";\"no\";\"unknown\";5;\"may\";261;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "44;\"technician\";\"single\";\"secondary\";\"no\";29;\"yes\";\"no\";\"unknown\";5;\"may\";151;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "33;\"entrepreneur\";\"married\";\"secondary\";\"no\";2;\"yes\";\"yes\";\"unknown\";5;\"may\";76;1;-1;0;\"unknown\";\"no\"\n",
      "\n",
      "47;\"blue-collar\";\"married\";\"unknown\";\"no\";1506;\"yes\";\"no\";\"unknown\";5;\"may\";92;1;-1;0;\"unknown\";\"no\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To verify how data is orgainzed in file(to find the delimiter) and then\n",
    "# use corresponding function to open the file. eg\n",
    "# data could be in .csv. .tsv, excel format etc.\n",
    "pathOfDataFile = \"data/bank-full.csv\"\n",
    "firstFewLines = list()\n",
    "noOfLinesToView = 5\n",
    "\n",
    "with open(pathOfDataFile) as dataFile:\n",
    "    firstFewLines = [next(dataFile) for i in range(noOfLinesToView)]\n",
    "    for line in firstFewLines:\n",
    "        print(line)\n",
    "\n",
    "# Import the semi-colon delimited data file into pandas dataFrame\n",
    "bankPromo_df = pd.read_csv(pathOfDataFile, sep = \";\")\n",
    "\n",
    "# Rename the Target/Final Outcome column from \"y\" to \"Subscribed\" as based on data description.\n",
    "bankPromo_df = bankPromo_df.rename(columns={\"y\":\"Subscribed\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      "age           45211 non-null int64\n",
      "job           45211 non-null object\n",
      "marital       45211 non-null object\n",
      "education     45211 non-null object\n",
      "default       45211 non-null object\n",
      "balance       45211 non-null int64\n",
      "housing       45211 non-null object\n",
      "loan          45211 non-null object\n",
      "contact       45211 non-null object\n",
      "day           45211 non-null int64\n",
      "month         45211 non-null object\n",
      "duration      45211 non-null int64\n",
      "campaign      45211 non-null int64\n",
      "pdays         45211 non-null int64\n",
      "previous      45211 non-null int64\n",
      "poutcome      45211 non-null object\n",
      "Subscribed    45211 non-null object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "bankPromo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
      "['job', 'marital', 'education', 'housing', 'loan', 'contact', 'month', 'poutcome', 'Subscribed']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values(Levels) for categorical variables.\n",
    "# List to hold names of categorical variables\n",
    "categoricalVars = list()\n",
    "# List to hold names of numerical variables\n",
    "numericalVars = list()\n",
    "\n",
    "for colName in bankPromo_df.columns:\n",
    "    if bankPromo_df[colName].dtype == np.int64:\n",
    "        numericalVars.append(colName)\n",
    "    elif bankPromo_df[colName].dtype == np.object:\n",
    "        categoricalVars.append(colName)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# Remove Target column from final categorical Var list\n",
    "categoricalVars.remove('default')\n",
    "\n",
    "print(numericalVars)\n",
    "print(categoricalVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform One Hot Encoding for categorical variables in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of original data frame\n",
    "bankPromoModel_def_Df = bankPromo_df.copy()\n",
    "bankPromoModel_def_Df['Target'] = bankPromoModel_def_Df['default'].apply(lambda resp : 1 if resp == \"yes\" else 0)\n",
    "bankPromoModel_def_Df['Target'] = bankPromoModel_def_Df['Target'].astype(np.int)\n",
    "# Delete the original 'Subscribed' column\n",
    "del bankPromoModel_def_Df['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 43 columns):\n",
      "age                    45211 non-null int64\n",
      "balance                45211 non-null int64\n",
      "day                    45211 non-null int64\n",
      "duration               45211 non-null int64\n",
      "campaign               45211 non-null int64\n",
      "pdays                  45211 non-null int64\n",
      "previous               45211 non-null int64\n",
      "Target                 45211 non-null int32\n",
      "job_blue-collar        45211 non-null uint8\n",
      "job_entrepreneur       45211 non-null uint8\n",
      "job_housemaid          45211 non-null uint8\n",
      "job_management         45211 non-null uint8\n",
      "job_retired            45211 non-null uint8\n",
      "job_self-employed      45211 non-null uint8\n",
      "job_services           45211 non-null uint8\n",
      "job_student            45211 non-null uint8\n",
      "job_technician         45211 non-null uint8\n",
      "job_unemployed         45211 non-null uint8\n",
      "job_unknown            45211 non-null uint8\n",
      "marital_married        45211 non-null uint8\n",
      "marital_single         45211 non-null uint8\n",
      "education_secondary    45211 non-null uint8\n",
      "education_tertiary     45211 non-null uint8\n",
      "education_unknown      45211 non-null uint8\n",
      "housing_yes            45211 non-null uint8\n",
      "loan_yes               45211 non-null uint8\n",
      "contact_telephone      45211 non-null uint8\n",
      "contact_unknown        45211 non-null uint8\n",
      "month_aug              45211 non-null uint8\n",
      "month_dec              45211 non-null uint8\n",
      "month_feb              45211 non-null uint8\n",
      "month_jan              45211 non-null uint8\n",
      "month_jul              45211 non-null uint8\n",
      "month_jun              45211 non-null uint8\n",
      "month_mar              45211 non-null uint8\n",
      "month_may              45211 non-null uint8\n",
      "month_nov              45211 non-null uint8\n",
      "month_oct              45211 non-null uint8\n",
      "month_sep              45211 non-null uint8\n",
      "poutcome_other         45211 non-null uint8\n",
      "poutcome_success       45211 non-null uint8\n",
      "poutcome_unknown       45211 non-null uint8\n",
      "Subscribed_yes         45211 non-null uint8\n",
      "dtypes: int32(1), int64(7), uint8(35)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Covert all categorical variables to corresponding indicator variables\n",
    "for categoricalVar in categoricalVars:\n",
    "    tmpDf = pd.DataFrame()\n",
    "    # Remove 1st class level to avoid multicollinearity\n",
    "    tmpDf = pd.get_dummies(bankPromoModel_def_Df[categoricalVar], prefix=categoricalVar, drop_first=True)\n",
    "    bankPromoModel_def_Df = pd.concat((bankPromoModel_def_Df, tmpDf), axis=1)\n",
    "\n",
    "# Now remove the original categorical vars since indicator variables are created from them.\n",
    "bankPromoModel_def_Df.drop(categoricalVars, inplace=True, axis=1)\n",
    "bankPromoModel_def_Df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform 5 fold Cross Validation with 80/20 Split for Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=5, random_state=999, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "# Training and Test Split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "if 'Target' in bankPromoModel_def_Df:\n",
    "    y = bankPromoModel_def_Df['Target'].values # get the labels we want\n",
    "    del bankPromoModel_def_Df['Target']        # get rid of the class label\n",
    "    X = bankPromoModel_def_Df.values           # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# To use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 5\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2, random_state=999)\n",
    "                         \n",
    "print(cv_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready Additional Test Dataset(with 10% instances) for final model fitting and weights interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      "age           4521 non-null int64\n",
      "job           4521 non-null object\n",
      "marital       4521 non-null object\n",
      "education     4521 non-null object\n",
      "default       4521 non-null object\n",
      "balance       4521 non-null int64\n",
      "housing       4521 non-null object\n",
      "loan          4521 non-null object\n",
      "contact       4521 non-null object\n",
      "day           4521 non-null int64\n",
      "month         4521 non-null object\n",
      "duration      4521 non-null int64\n",
      "campaign      4521 non-null int64\n",
      "pdays         4521 non-null int64\n",
      "previous      4521 non-null int64\n",
      "poutcome      4521 non-null object\n",
      "Subscribed    4521 non-null object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 600.5+ KB\n"
     ]
    }
   ],
   "source": [
    "pathOfAdditionalDataFile = \"data/bank.csv\"\n",
    "\n",
    "# Import the semi-colon delimited data file into pandas dataFrame\n",
    "bankPromoAdditional_df = pd.read_csv(pathOfAdditionalDataFile, sep = \";\")\n",
    "\n",
    "# Rename the Target/Final Outcome column from \"y\" to \"Subscribed\" as based on data description.\n",
    "bankPromoAdditional_df = bankPromoAdditional_df.rename(columns={\"y\":\"Subscribed\"})\n",
    "\n",
    "bankPromoAdditional_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 42 columns):\n",
      "age                    4521 non-null int64\n",
      "balance                4521 non-null int64\n",
      "day                    4521 non-null int64\n",
      "duration               4521 non-null int64\n",
      "campaign               4521 non-null int64\n",
      "pdays                  4521 non-null int64\n",
      "previous               4521 non-null int64\n",
      "job_blue-collar        4521 non-null uint8\n",
      "job_entrepreneur       4521 non-null uint8\n",
      "job_housemaid          4521 non-null uint8\n",
      "job_management         4521 non-null uint8\n",
      "job_retired            4521 non-null uint8\n",
      "job_self-employed      4521 non-null uint8\n",
      "job_services           4521 non-null uint8\n",
      "job_student            4521 non-null uint8\n",
      "job_technician         4521 non-null uint8\n",
      "job_unemployed         4521 non-null uint8\n",
      "job_unknown            4521 non-null uint8\n",
      "marital_married        4521 non-null uint8\n",
      "marital_single         4521 non-null uint8\n",
      "education_secondary    4521 non-null uint8\n",
      "education_tertiary     4521 non-null uint8\n",
      "education_unknown      4521 non-null uint8\n",
      "housing_yes            4521 non-null uint8\n",
      "loan_yes               4521 non-null uint8\n",
      "contact_telephone      4521 non-null uint8\n",
      "contact_unknown        4521 non-null uint8\n",
      "month_aug              4521 non-null uint8\n",
      "month_dec              4521 non-null uint8\n",
      "month_feb              4521 non-null uint8\n",
      "month_jan              4521 non-null uint8\n",
      "month_jul              4521 non-null uint8\n",
      "month_jun              4521 non-null uint8\n",
      "month_mar              4521 non-null uint8\n",
      "month_may              4521 non-null uint8\n",
      "month_nov              4521 non-null uint8\n",
      "month_oct              4521 non-null uint8\n",
      "month_sep              4521 non-null uint8\n",
      "poutcome_other         4521 non-null uint8\n",
      "poutcome_success       4521 non-null uint8\n",
      "poutcome_unknown       4521 non-null uint8\n",
      "Subscribed_yes         4521 non-null uint8\n",
      "dtypes: int64(7), uint8(35)\n",
      "memory usage: 401.8 KB\n"
     ]
    }
   ],
   "source": [
    "bankPromoAdditional_def_df = bankPromoAdditional_df.copy()\n",
    "\n",
    "bankPromoAdditional_def_df['Target'] = bankPromoAdditional_def_df['default'].apply(lambda resp : 1 if resp == \"yes\" else 0)\n",
    "bankPromoAdditional_def_df['Target'] = bankPromoAdditional_def_df['Target'].astype(np.int)\n",
    "# Delete the original 'Subscribed' column\n",
    "del bankPromoAdditional_def_df['default']\n",
    "\n",
    "# Covert all categorical variables to corresponding indicator variables\n",
    "for categoricalVar in categoricalVars:\n",
    "    tmpDf = pd.DataFrame()\n",
    "    # Remove 1st class level to avoid multicollinearity\n",
    "    tmpDf = pd.get_dummies(bankPromoAdditional_def_df[categoricalVar], prefix=categoricalVar, drop_first=True)\n",
    "    bankPromoAdditional_def_df = pd.concat((bankPromoAdditional_def_df, tmpDf), axis=1)\n",
    "\n",
    "# Now remove the original categorical vars since indicator variables are created from them.\n",
    "bankPromoAdditional_def_df.drop(categoricalVars, inplace=True, axis=1)\n",
    "\n",
    "if 'Target' in bankPromoAdditional_def_df:\n",
    "    y_Final = bankPromoAdditional_def_df['Target'].values # get the labels we want\n",
    "    del bankPromoAdditional_def_df['Target']        # get rid of the class label\n",
    "    X_Final = bankPromoAdditional_def_df.values\n",
    "\n",
    "bankPromoAdditional_def_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "\n",
    "### Simple Logistic Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "confusion matrix\n",
      " [[8871    2]\n",
      " [ 169    1]]\n",
      "====Iteration 1  ====\n",
      "confusion matrix\n",
      " [[8863    6]\n",
      " [ 172    2]]\n",
      "====Iteration 2  ====\n",
      "confusion matrix\n",
      " [[8855    1]\n",
      " [ 182    5]]\n",
      "====Iteration 3  ====\n",
      "confusion matrix\n",
      " [[8893    6]\n",
      " [ 140    4]]\n",
      "====Iteration 4  ====\n",
      "confusion matrix\n",
      " [[8891    2]\n",
      " [ 144    6]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AuC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981090</td>\n",
       "      <td>0.502828</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.005882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980316</td>\n",
       "      <td>0.505409</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979763</td>\n",
       "      <td>0.513313</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.026738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.983855</td>\n",
       "      <td>0.513552</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983855</td>\n",
       "      <td>0.519888</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       AuC  F1 Score  Precision    Recall\n",
       "0  0.981090  0.502828  0.011561   0.333333  0.005882\n",
       "1  0.980316  0.505409  0.021978   0.250000  0.011494\n",
       "2  0.979763  0.513313  0.051813   0.833333  0.026738\n",
       "3  0.983855  0.513552  0.051948   0.400000  0.027778\n",
       "4  0.983855  0.519888  0.075949   0.750000  0.040000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Performnace Metrices \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy     0.981776\n",
       "AuC          0.510998\n",
       "F1 Score     0.042650\n",
       "Precision    0.513333\n",
       "Recall       0.022378\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run logistic regression model\n",
    "\n",
    "logisticModel = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', C=1.0, class_weight=None, random_state=999))\n",
    "\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "       \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    logisticModel.fit(X_train,y_train)  # train object\n",
    "    y_hat = logisticModel.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy,precision,recall,auc,F1 and confusion matrix for this iterations of training/testing\n",
    "    tmpDict = dict()\n",
    "    tmpDict['Accuracy'] = mt.accuracy_score(y_test,y_hat)\n",
    "    tmpDict['AuC'] = mt.roc_auc_score(y_test,y_hat)\n",
    "    tmpDict['F1 Score'] = mt.f1_score(y_test,y_hat)\n",
    "    tmpDict['Precision'] = mt.precision_score(y_test,y_hat)\n",
    "    tmpDict['Recall'] = mt.recall_score(y_test,y_hat)\n",
    "    \n",
    "    modelPerformanceMetrices = modelPerformanceMetrices.append(tmpDict, ignore_index=True)\n",
    "\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "  \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "\n",
    "display(modelPerformanceMetrices)\n",
    "print(\"Average Model Performnace Metrices \")\n",
    "display(modelPerformanceMetrices.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning The Model Hyper Parameters Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "confusion matrix\n",
      " [[8871    2]\n",
      " [ 167    3]]\n",
      "Best Estimator Model Parameters\n",
      " {'logisticregression__C': 0.5689866029018293, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n",
      "====Iteration 1  ====\n",
      "confusion matrix\n",
      " [[8861    8]\n",
      " [ 170    4]]\n",
      "Best Estimator Model Parameters\n",
      " {'logisticregression__C': 0.5689866029018293, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n",
      "====Iteration 2  ====\n",
      "confusion matrix\n",
      " [[8853    3]\n",
      " [ 181    6]]\n",
      "Best Estimator Model Parameters\n",
      " {'logisticregression__C': 0.8286427728546842, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n",
      "====Iteration 3  ====\n",
      "confusion matrix\n",
      " [[8893    6]\n",
      " [ 140    4]]\n",
      "Best Estimator Model Parameters\n",
      " {'logisticregression__C': 0.18420699693267145, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n",
      "====Iteration 4  ====\n",
      "confusion matrix\n",
      " [[8890    3]\n",
      " [ 144    6]]\n",
      "Best Estimator Model Parameters\n",
      " {'logisticregression__C': 0.3906939937054613, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AuC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981312</td>\n",
       "      <td>0.508711</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.017647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980316</td>\n",
       "      <td>0.511043</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.022989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979653</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.032086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.983855</td>\n",
       "      <td>0.513552</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983744</td>\n",
       "      <td>0.519831</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       AuC  F1 Score  Precision    Recall\n",
       "0  0.981312  0.508711  0.034286   0.600000  0.017647\n",
       "1  0.980316  0.511043  0.043011   0.333333  0.022989\n",
       "2  0.979653  0.515873  0.061224   0.666667  0.032086\n",
       "3  0.983855  0.513552  0.051948   0.400000  0.027778\n",
       "4  0.983744  0.519831  0.075472   0.666667  0.040000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Performnace Metrices \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy     0.981776\n",
       "AuC          0.513802\n",
       "F1 Score     0.053188\n",
       "Precision    0.533333\n",
       "Recall       0.028100\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "\n",
    "param_grid = {\n",
    "     'logisticregression__penalty' : ['l1', 'l2'],\n",
    "    'logisticregression__C' : np.logspace(-4, 4, 50),\n",
    "    'logisticregression__solver' : ['liblinear'],\n",
    "    'logisticregression__class_weight' : [None, 'balanced']}\n",
    "\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(make_pipeline(StandardScaler(), LogisticRegression(random_state=999)), \\\n",
    "                   param_grid = param_grid, cv = 5, verbose=False, n_jobs=-1, scoring=scoring, refit='AUC', \\\n",
    "                   return_train_score=True)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "       \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    tmpDict = dict()\n",
    "    tmpDict['Accuracy'] = mt.accuracy_score(y_test,y_hat)\n",
    "    tmpDict['AuC'] = mt.roc_auc_score(y_test,y_hat)\n",
    "    tmpDict['F1 Score'] = mt.f1_score(y_test,y_hat)\n",
    "    tmpDict['Precision'] = mt.precision_score(y_test,y_hat)\n",
    "    tmpDict['Recall'] = mt.recall_score(y_test,y_hat)\n",
    "    \n",
    "    modelPerformanceMetrices = modelPerformanceMetrices.append(tmpDict, ignore_index=True)\n",
    "\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "  \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    print(\"Best Estimator Model Parameters\\n\", clf.best_params_)\n",
    "\n",
    "display(modelPerformanceMetrices)\n",
    "print(\"Average Model Performnace Metrices \")\n",
    "display(modelPerformanceMetrices.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple SVM Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "confusion matrix\n",
      " [[7191 1682]\n",
      " [  69  101]]\n",
      "====Iteration 1  ====\n",
      "confusion matrix\n",
      " [[7190 1679]\n",
      " [  68  106]]\n",
      "====Iteration 2  ====\n",
      "confusion matrix\n",
      " [[7123 1733]\n",
      " [  66  121]]\n",
      "====Iteration 3  ====\n",
      "confusion matrix\n",
      " [[7173 1726]\n",
      " [  58   86]]\n",
      "====Iteration 4  ====\n",
      "confusion matrix\n",
      " [[7210 1683]\n",
      " [  62   88]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AuC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806370</td>\n",
       "      <td>0.702277</td>\n",
       "      <td>0.103431</td>\n",
       "      <td>0.056646</td>\n",
       "      <td>0.594118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806812</td>\n",
       "      <td>0.709942</td>\n",
       "      <td>0.108218</td>\n",
       "      <td>0.059384</td>\n",
       "      <td>0.609195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.801062</td>\n",
       "      <td>0.725686</td>\n",
       "      <td>0.118569</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.802720</td>\n",
       "      <td>0.701634</td>\n",
       "      <td>0.087935</td>\n",
       "      <td>0.047461</td>\n",
       "      <td>0.597222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.807033</td>\n",
       "      <td>0.698708</td>\n",
       "      <td>0.091619</td>\n",
       "      <td>0.049689</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       AuC  F1 Score  Precision    Recall\n",
       "0  0.806370  0.702277  0.103431   0.056646  0.594118\n",
       "1  0.806812  0.709942  0.108218   0.059384  0.609195\n",
       "2  0.801062  0.725686  0.118569   0.065264  0.647059\n",
       "3  0.802720  0.701634  0.087935   0.047461  0.597222\n",
       "4  0.807033  0.698708  0.091619   0.049689  0.586667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Performnace Metrices \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy     0.804799\n",
       "AuC          0.707649\n",
       "F1 Score     0.101954\n",
       "Precision    0.055689\n",
       "Recall       0.606852\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for Linear SVM\n",
      "0:07:53.800706\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.svm import SVC\n",
    "# Initialize an Empty Dataframe to store Model performance Stats\n",
    "modelPerformanceMetrices = pd.DataFrame(columns=['Accuracy', 'AuC', 'F1 Score', 'Precision', 'Recall'])\n",
    "\n",
    "# Standardize the features first, since standardizing the features could lead to\n",
    "# gradient desent algo to converge faster and then run SVM model\n",
    "\n",
    "start = datetime.now()\n",
    "svmModel = make_pipeline(StandardScaler(), SVC(C=1.0, kernel='rbf', degree=3 , gamma='auto', random_state=999 , class_weight='balanced'))\n",
    "\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    svmModel.fit(X_train, y_train)  # train object\n",
    "    y_hat = svmModel.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy,precision,recall,auc,F1 and confusion matrix for this iterations of training/testing\n",
    "    tmpDict = dict()\n",
    "    tmpDict['Accuracy'] = mt.accuracy_score(y_test,y_hat)\n",
    "    tmpDict['AuC'] = mt.roc_auc_score(y_test,y_hat)\n",
    "    tmpDict['F1 Score'] = mt.f1_score(y_test,y_hat)\n",
    "    tmpDict['Precision'] = mt.precision_score(y_test,y_hat)\n",
    "    tmpDict['Recall'] = mt.recall_score(y_test,y_hat)\n",
    "    \n",
    "    modelPerformanceMetrices = modelPerformanceMetrices.append(tmpDict, ignore_index=True)\n",
    "\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "  \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "\n",
    "display(modelPerformanceMetrices)\n",
    "print(\"Average Model Performnace Metrices \")\n",
    "display(modelPerformanceMetrices.mean())\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"time taken for Linear SVM\")\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
